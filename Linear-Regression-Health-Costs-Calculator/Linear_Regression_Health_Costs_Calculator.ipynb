{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9TX15KOkPBV"
      },
      "source": [
        "*Note: You are currently reading this using Google Colaboratory which is a cloud-hosted version of Jupyter Notebook. This is a document containing both text cells for documentation and runnable code cells. If you are unfamiliar with Jupyter Notebook, watch this 3-minute introduction before starting this challenge: https://www.youtube.com/watch?v=inN8seMm7UI*\n",
        "\n",
        "---\n",
        "\n",
        "In this challenge, you will predict healthcare costs using a regression algorithm.\n",
        "\n",
        "You are given a dataset that contains information about different people including their healthcare costs. Use the data to predict healthcare costs based on new data.\n",
        "\n",
        "The first two cells of this notebook import libraries and the data.\n",
        "\n",
        "Make sure to convert categorical data to numbers. Use 80% of the data as the `train_dataset` and 20% of the data as the `test_dataset`.\n",
        "\n",
        "`pop` off the \"expenses\" column from these datasets to create new datasets called `train_labels` and `test_labels`. Use these labels when training your model.\n",
        "\n",
        "Create a model and train it with the `train_dataset`. Run the final cell in this notebook to check your model. The final cell will use the unseen `test_dataset` to check how well the model generalizes.\n",
        "\n",
        "To pass the challenge, `model.evaluate` must return a Mean Absolute Error of under 3500. This means it predicts health care costs correctly within $3500.\n",
        "\n",
        "The final cell will also predict expenses using the `test_dataset` and graph the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRo8oNqZ-Rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6300673c-8cff-4d69-f993-78a6c2f7b734"
      },
      "source": [
        "# Import libraries. You may or may not use all of these.\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiX2FI4gZtTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3710013c-ca56-436d-9a12-563ab09d86dd"
      },
      "source": [
        "# Import data\n",
        "!wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-10 16:15:36--  https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.2.33, 104.26.3.33, 172.67.70.149, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.2.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50264 (49K) [text/csv]\n",
            "Saving to: ‘insurance.csv’\n",
            "\n",
            "insurance.csv       100%[===================>]  49.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-10 16:15:37 (116 MB/s) - ‘insurance.csv’ saved [50264/50264]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the .csv file into a Pandas dataframe\n",
        "dataset = pd.read_csv('insurance.csv')\n",
        "\n",
        "# Show the last 5 entries in the dataset\n",
        "dataset.tail()"
      ],
      "metadata": {
        "id": "dfLtBa38hSBR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9f0347b5-e476-4f33-dde1-b6c41c6706f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>expenses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.8</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.1</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex   bmi  children smoker     region  expenses\n",
              "1333   50    male  31.0         3     no  northwest  10600.55\n",
              "1334   18  female  31.9         0     no  northeast   2205.98\n",
              "1335   18  female  36.9         0     no  southeast   1629.83\n",
              "1336   21  female  25.8         0     no  southwest   2007.95\n",
              "1337   61  female  29.1         0    yes  northwest  29141.36"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcopvQh3X-kX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e9f3405d-4ea8-43c0-f718-e8dd7f1d71bd"
      },
      "source": [
        "# Include all categorical columns in a list\n",
        "categorical_columns = [\"sex\", \"smoker\", \"region\"]\n",
        "\n",
        "# Turn categorical values into indicator (dummy) values\n",
        "dataset = pd.get_dummies(dataset, columns=categorical_columns, drop_first=False)\n",
        "\n",
        "# Show the first 5 entries in the (new) dataset\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>expenses</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.9</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.7</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.86</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age   bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.9         0  ...                 0                 0                 1\n",
              "1   18  33.8         1  ...                 0                 1                 0\n",
              "2   28  33.0         3  ...                 0                 1                 0\n",
              "3   33  22.7         0  ...                 1                 0                 0\n",
              "4   32  28.9         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a random sample (with seed 0) which is 80% of the total entries as the training dataset\n",
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "\n",
        "# Take the remaining entries into the testing dataset\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "\n",
        "# Remove the 'expenses' column from their both datasets to get their respective labels\n",
        "train_labels = train_dataset.pop(\"expenses\")\n",
        "test_labels = test_dataset.pop(\"expenses\")"
      ],
      "metadata": {
        "id": "TLB6v9C9hasT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the statistical description of the training dataset\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats\n",
        "\n",
        "# Normalize both datasets\n",
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "metadata": {
        "id": "mtttChtIhlu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Linear Regression model using Keras\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(1, activation='relu')\n",
        "  ])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mae',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(),\n",
        "              metrics=['mae','mse'])\n",
        "\n",
        "# Show model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "IrHp8g4Fh9GL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce485be7-8479-4c02-9367-641aec499486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               1536      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,577\n",
            "Trainable params: 16,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of epochs to be 1000\n",
        "EPOCHS = 1000\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    train_labels,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=0.2,\n",
        "    verbose=1,\n",
        "    callbacks=[tf.keras.callbacks.ModelCheckpoint('./checkpoint',\n",
        "               save_best_only=True, monitor='val_loss')],\n",
        ")"
      ],
      "metadata": {
        "id": "_Uzfm7M7iBuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de556c1-6c02-4b06-98a9-683088bbe6e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 12457.3779 - mae: 12457.3779 - mse: 293365920.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 4s 73ms/step - loss: 12583.6523 - mae: 12583.6523 - mse: 298319328.0000 - val_loss: 13942.3828 - val_mae: 13942.3828 - val_mse: 348936064.0000\n",
            "Epoch 2/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 11630.5908 - mae: 11630.5908 - mse: 279460448.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 11088.4619 - mae: 11088.4619 - mse: 260877952.0000 - val_loss: 10638.4219 - val_mae: 10638.4219 - val_mse: 260760896.0000\n",
            "Epoch 3/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 8054.4927 - mae: 8054.4927 - mse: 183210368.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 7809.1411 - mae: 7809.1411 - mse: 171476576.0000 - val_loss: 7891.6519 - val_mae: 7891.6519 - val_mse: 175119216.0000\n",
            "Epoch 4/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 7117.2378 - mae: 7117.2378 - mse: 145733184.0000 - val_loss: 7959.8979 - val_mae: 7959.8979 - val_mse: 186766752.0000\n",
            "Epoch 5/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 7309.7075 - mae: 7309.7075 - mse: 157273216.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 7024.7925 - mae: 7024.7925 - mse: 147276752.0000 - val_loss: 7767.1792 - val_mae: 7767.1792 - val_mse: 181653952.0000\n",
            "Epoch 6/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 6911.8818 - mae: 6911.8818 - mse: 146301744.0000 - val_loss: 7806.3354 - val_mae: 7806.3354 - val_mse: 189683792.0000\n",
            "Epoch 7/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 6616.1123 - mae: 6616.1123 - mse: 139147456.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 6812.8481 - mae: 6812.8481 - mse: 148842976.0000 - val_loss: 7543.9341 - val_mae: 7543.9341 - val_mse: 177506016.0000\n",
            "Epoch 8/1000\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 6761.1592 - mae: 6761.1592 - mse: 150401952.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 6689.7822 - mae: 6689.7822 - mse: 147738128.0000 - val_loss: 7492.7710 - val_mae: 7492.7710 - val_mse: 186679200.0000\n",
            "Epoch 9/1000\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 6673.6064 - mae: 6673.6064 - mse: 153132784.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 6552.9561 - mae: 6552.9561 - mse: 150151104.0000 - val_loss: 7376.1123 - val_mae: 7376.1123 - val_mse: 188628960.0000\n",
            "Epoch 10/1000\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 6343.7026 - mae: 6343.7026 - mse: 147104400.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 58ms/step - loss: 6434.1670 - mae: 6434.1670 - mse: 150758480.0000 - val_loss: 7271.6250 - val_mae: 7271.6250 - val_mse: 183061728.0000\n",
            "Epoch 11/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 6650.3818 - mae: 6650.3818 - mse: 163877072.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 6350.2637 - mae: 6350.2637 - mse: 151176688.0000 - val_loss: 7217.5674 - val_mae: 7217.5674 - val_mse: 190302224.0000\n",
            "Epoch 12/1000\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 6104.8232 - mae: 6104.8232 - mse: 146674608.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 6287.3413 - mae: 6287.3413 - mse: 152950512.0000 - val_loss: 7178.5630 - val_mae: 7178.5625 - val_mse: 184586352.0000\n",
            "Epoch 13/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 6257.0366 - mae: 6257.0366 - mse: 151648016.0000 - val_loss: 7234.1099 - val_mae: 7234.1099 - val_mse: 194294080.0000\n",
            "Epoch 14/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 6077.1143 - mae: 6077.1143 - mse: 147065648.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 6235.1938 - mae: 6235.1938 - mse: 152025680.0000 - val_loss: 7113.0381 - val_mae: 7113.0381 - val_mse: 186389648.0000\n",
            "Epoch 15/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 6369.6460 - mae: 6369.6460 - mse: 155230960.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 6216.3335 - mae: 6216.3335 - mse: 150776320.0000 - val_loss: 7090.9639 - val_mae: 7090.9639 - val_mse: 186436832.0000\n",
            "Epoch 16/1000\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 6197.3042 - mae: 6197.3042 - mse: 152183296.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 49ms/step - loss: 6195.4780 - mae: 6195.4780 - mse: 150371632.0000 - val_loss: 7067.1758 - val_mae: 7067.1758 - val_mse: 184296032.0000\n",
            "Epoch 17/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 6033.1118 - mae: 6033.1118 - mse: 142760928.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 59ms/step - loss: 6168.5068 - mae: 6168.5068 - mse: 149462704.0000 - val_loss: 7044.0020 - val_mae: 7044.0020 - val_mse: 183290672.0000\n",
            "Epoch 18/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 5890.0283 - mae: 5890.0283 - mse: 140596992.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 6140.3267 - mae: 6140.3267 - mse: 149140256.0000 - val_loss: 7028.1289 - val_mae: 7028.1289 - val_mse: 185886432.0000\n",
            "Epoch 19/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 6154.9487 - mae: 6154.9487 - mse: 148102448.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 6112.3154 - mae: 6112.3154 - mse: 147856016.0000 - val_loss: 6991.7876 - val_mae: 6991.7876 - val_mse: 181520544.0000\n",
            "Epoch 20/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 6095.1318 - mae: 6095.1318 - mse: 147260928.0000 - val_loss: 7000.5303 - val_mae: 7000.5303 - val_mse: 186229056.0000\n",
            "Epoch 21/1000\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 5852.6895 - mae: 5852.6895 - mse: 138897344.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 6045.1997 - mae: 6045.1997 - mse: 145853216.0000 - val_loss: 6986.4312 - val_mae: 6986.4312 - val_mse: 175115872.0000\n",
            "Epoch 22/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 5975.6431 - mae: 5975.6431 - mse: 145652512.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 6037.5615 - mae: 6037.5615 - mse: 145133248.0000 - val_loss: 6976.1104 - val_mae: 6976.1104 - val_mse: 185869712.0000\n",
            "Epoch 23/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 5939.4863 - mae: 5939.4863 - mse: 142736240.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 6002.0010 - mae: 6002.0010 - mse: 144718784.0000 - val_loss: 6880.8252 - val_mae: 6880.8252 - val_mse: 174944176.0000\n",
            "Epoch 24/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 5977.8481 - mae: 5977.8481 - mse: 142963552.0000 - val_loss: 6958.0986 - val_mae: 6958.0986 - val_mse: 185115760.0000\n",
            "Epoch 25/1000\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 5816.9878 - mae: 5816.9878 - mse: 138938192.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 59ms/step - loss: 5957.5884 - mae: 5957.5884 - mse: 142662352.0000 - val_loss: 6804.1357 - val_mae: 6804.1357 - val_mse: 177337968.0000\n",
            "Epoch 26/1000\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 5977.4795 - mae: 5977.4795 - mse: 144273600.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 5919.9741 - mae: 5919.9741 - mse: 140890240.0000 - val_loss: 6780.9888 - val_mae: 6780.9888 - val_mse: 177987488.0000\n",
            "Epoch 27/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5892.0972 - mae: 5892.0972 - mse: 140486384.0000 - val_loss: 6788.3042 - val_mae: 6788.3042 - val_mse: 166480144.0000\n",
            "Epoch 28/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 5837.3188 - mae: 5837.3188 - mse: 138439184.0000 - val_loss: 6803.4863 - val_mae: 6803.4863 - val_mse: 179039056.0000\n",
            "Epoch 29/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 5522.8994 - mae: 5522.8994 - mse: 129072776.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 5812.1104 - mae: 5812.1104 - mse: 137614032.0000 - val_loss: 6626.3818 - val_mae: 6626.3818 - val_mse: 170209344.0000\n",
            "Epoch 30/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 5539.3818 - mae: 5539.3818 - mse: 130357968.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 5775.6460 - mae: 5775.6460 - mse: 135833728.0000 - val_loss: 6573.9565 - val_mae: 6573.9565 - val_mse: 168037072.0000\n",
            "Epoch 31/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 5673.1421 - mae: 5673.1421 - mse: 133377952.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 5723.3979 - mae: 5723.3979 - mse: 134124776.0000 - val_loss: 6549.5913 - val_mae: 6549.5913 - val_mse: 160169792.0000\n",
            "Epoch 32/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 5671.7886 - mae: 5671.7886 - mse: 132040984.0000 - val_loss: 6570.8574 - val_mae: 6570.8574 - val_mse: 154483600.0000\n",
            "Epoch 33/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 5645.4478 - mae: 5645.4478 - mse: 129238600.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 58ms/step - loss: 5607.9731 - mae: 5607.9731 - mse: 129249280.0000 - val_loss: 6403.5293 - val_mae: 6403.5293 - val_mse: 163203088.0000\n",
            "Epoch 34/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 5546.0186 - mae: 5546.0186 - mse: 126595216.0000 - val_loss: 6539.2520 - val_mae: 6539.2520 - val_mse: 166108912.0000\n",
            "Epoch 35/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 5379.6265 - mae: 5379.6265 - mse: 122209368.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 5494.5142 - mae: 5494.5142 - mse: 125369976.0000 - val_loss: 6250.3867 - val_mae: 6250.3867 - val_mse: 148573888.0000\n",
            "Epoch 36/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 5529.5923 - mae: 5529.5923 - mse: 125751360.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 5412.1196 - mae: 5412.1196 - mse: 121877248.0000 - val_loss: 6099.4312 - val_mae: 6099.4312 - val_mse: 148426736.0000\n",
            "Epoch 37/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 5272.6782 - mae: 5272.6782 - mse: 117504728.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 5342.7441 - mae: 5342.7441 - mse: 119067272.0000 - val_loss: 6006.1230 - val_mae: 6006.1230 - val_mse: 143499984.0000\n",
            "Epoch 38/1000\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 5073.7202 - mae: 5073.7202 - mse: 111025224.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 5225.7607 - mae: 5225.7607 - mse: 114637544.0000 - val_loss: 5926.3501 - val_mae: 5926.3501 - val_mse: 135570736.0000\n",
            "Epoch 39/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 5293.4351 - mae: 5293.4351 - mse: 114421296.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 5129.9814 - mae: 5129.9814 - mse: 109624448.0000 - val_loss: 5723.8911 - val_mae: 5723.8911 - val_mse: 135052208.0000\n",
            "Epoch 40/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 5058.1211 - mae: 5058.1211 - mse: 109293168.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 4979.9502 - mae: 4979.9502 - mse: 105520920.0000 - val_loss: 5543.6255 - val_mae: 5543.6255 - val_mse: 128878728.0000\n",
            "Epoch 41/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 4882.2231 - mae: 4882.2231 - mse: 99205512.0000 - val_loss: 5562.1885 - val_mae: 5562.1885 - val_mse: 127602880.0000\n",
            "Epoch 42/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 4953.4150 - mae: 4953.4150 - mse: 101021376.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 58ms/step - loss: 4712.8682 - mae: 4712.8682 - mse: 94420608.0000 - val_loss: 5299.2607 - val_mae: 5299.2607 - val_mse: 107161728.0000\n",
            "Epoch 43/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 4227.4131 - mae: 4227.4131 - mse: 82754032.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 4502.6978 - mae: 4502.6978 - mse: 87300544.0000 - val_loss: 4888.8491 - val_mae: 4888.8491 - val_mse: 102768632.0000\n",
            "Epoch 44/1000\n",
            "27/27 [==============================] - ETA: 0s - loss: 4285.7563 - mae: 4285.7563 - mse: 78148984.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 4285.7563 - mae: 4285.7563 - mse: 78148984.0000 - val_loss: 4614.7637 - val_mae: 4614.7637 - val_mse: 94293304.0000\n",
            "Epoch 45/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 4310.4756 - mae: 4310.4756 - mse: 77473480.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 4100.8682 - mae: 4100.8682 - mse: 71735552.0000 - val_loss: 4607.4351 - val_mae: 4607.4351 - val_mse: 91960080.0000\n",
            "Epoch 46/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3898.3250 - mae: 3898.3250 - mse: 64894388.0000 - val_loss: 4653.6992 - val_mae: 4653.6992 - val_mse: 70251160.0000\n",
            "Epoch 47/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 3991.4268 - mae: 3991.4268 - mse: 63523488.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 3790.4497 - mae: 3790.4497 - mse: 59269404.0000 - val_loss: 4208.0146 - val_mae: 4208.0146 - val_mse: 69126904.0000\n",
            "Epoch 48/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3687.3108 - mae: 3687.3108 - mse: 56266312.0000 - val_loss: 4480.5298 - val_mae: 4480.5298 - val_mse: 60944284.0000\n",
            "Epoch 49/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3647.3491 - mae: 3647.3491 - mse: 52652128.0000 - val_loss: 4292.9160 - val_mae: 4292.9160 - val_mse: 58198316.0000\n",
            "Epoch 50/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3584.6975 - mae: 3584.6975 - mse: 50724860.0000 - val_loss: 4222.5874 - val_mae: 4222.5874 - val_mse: 67047080.0000\n",
            "Epoch 51/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 3600.0818 - mae: 3600.0818 - mse: 50069732.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 49ms/step - loss: 3538.7107 - mae: 3538.7107 - mse: 48612692.0000 - val_loss: 4040.8750 - val_mae: 4040.8750 - val_mse: 62802432.0000\n",
            "Epoch 52/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 3567.3599 - mae: 3567.3599 - mse: 48107520.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 58ms/step - loss: 3577.8064 - mae: 3577.8064 - mse: 47344716.0000 - val_loss: 3855.6350 - val_mae: 3855.6350 - val_mse: 55555140.0000\n",
            "Epoch 53/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3522.4714 - mae: 3522.4714 - mse: 45879900.0000 - val_loss: 3961.4187 - val_mae: 3961.4187 - val_mse: 52998420.0000\n",
            "Epoch 54/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3475.4404 - mae: 3475.4404 - mse: 44214484.0000 - val_loss: 4391.0767 - val_mae: 4391.0767 - val_mse: 62789392.0000\n",
            "Epoch 55/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 3620.6179 - mae: 3620.6179 - mse: 44833852.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 3520.4509 - mae: 3520.4509 - mse: 44290380.0000 - val_loss: 3824.5312 - val_mae: 3824.5312 - val_mse: 50456236.0000\n",
            "Epoch 56/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 3442.8716 - mae: 3442.8716 - mse: 42977836.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 49ms/step - loss: 3477.3918 - mae: 3477.3918 - mse: 42773292.0000 - val_loss: 3804.4385 - val_mae: 3804.4387 - val_mse: 53171328.0000\n",
            "Epoch 57/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3426.1274 - mae: 3426.1274 - mse: 40343600.0000 - val_loss: 3950.4282 - val_mae: 3950.4282 - val_mse: 55302556.0000\n",
            "Epoch 58/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 3544.4075 - mae: 3544.4075 - mse: 42702712.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 3433.5630 - mae: 3433.5630 - mse: 41357476.0000 - val_loss: 3790.3328 - val_mae: 3790.3328 - val_mse: 46349284.0000\n",
            "Epoch 59/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 3436.9810 - mae: 3436.9810 - mse: 39915980.0000 - val_loss: 4022.1367 - val_mae: 4022.1367 - val_mse: 43485508.0000\n",
            "Epoch 60/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 3379.3491 - mae: 3379.3491 - mse: 38514520.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 3404.2717 - mae: 3404.2717 - mse: 38017648.0000 - val_loss: 3783.4863 - val_mae: 3783.4863 - val_mse: 47344844.0000\n",
            "Epoch 61/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3349.3086 - mae: 3349.3086 - mse: 36976728.0000 - val_loss: 3921.3770 - val_mae: 3921.3770 - val_mse: 41402488.0000\n",
            "Epoch 62/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3334.6150 - mae: 3334.6150 - mse: 35802848.0000 - val_loss: 4126.6914 - val_mae: 4126.6914 - val_mse: 40247872.0000\n",
            "Epoch 63/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3344.4395 - mae: 3344.4395 - mse: 35066792.0000 - val_loss: 3863.2083 - val_mae: 3863.2083 - val_mse: 39699812.0000\n",
            "Epoch 64/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 3410.1384 - mae: 3410.1384 - mse: 35557112.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 3320.8174 - mae: 3320.8174 - mse: 34645712.0000 - val_loss: 3598.9998 - val_mae: 3598.9998 - val_mse: 39279516.0000\n",
            "Epoch 65/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 3216.4971 - mae: 3216.4971 - mse: 34254536.0000 - val_loss: 3719.3318 - val_mae: 3719.3318 - val_mse: 39705508.0000\n",
            "Epoch 66/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3222.4116 - mae: 3222.4116 - mse: 34513880.0000 - val_loss: 3750.6880 - val_mae: 3750.6880 - val_mse: 39514060.0000\n",
            "Epoch 67/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3222.0837 - mae: 3222.0837 - mse: 34393932.0000 - val_loss: 3919.0085 - val_mae: 3919.0085 - val_mse: 42753580.0000\n",
            "Epoch 68/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3187.9810 - mae: 3187.9810 - mse: 35534132.0000 - val_loss: 4011.4106 - val_mae: 4011.4106 - val_mse: 44594184.0000\n",
            "Epoch 69/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3147.3672 - mae: 3147.3672 - mse: 35101040.0000 - val_loss: 3846.0896 - val_mae: 3846.0896 - val_mse: 45195680.0000\n",
            "Epoch 70/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 3210.8574 - mae: 3210.8574 - mse: 38445716.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 58ms/step - loss: 3169.4136 - mae: 3169.4136 - mse: 37054096.0000 - val_loss: 3258.8279 - val_mae: 3258.8279 - val_mse: 39828348.0000\n",
            "Epoch 71/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3140.4255 - mae: 3140.4255 - mse: 37022064.0000 - val_loss: 3514.1953 - val_mae: 3514.1953 - val_mse: 39540172.0000\n",
            "Epoch 72/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3062.1304 - mae: 3062.1304 - mse: 35326296.0000 - val_loss: 3639.7129 - val_mae: 3639.7129 - val_mse: 39051052.0000\n",
            "Epoch 73/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 3108.3523 - mae: 3108.3523 - mse: 36224928.0000 - val_loss: 3284.0061 - val_mae: 3284.0061 - val_mse: 40332280.0000\n",
            "Epoch 74/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 2902.5872 - mae: 2902.5872 - mse: 35184744.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 2979.6963 - mae: 2979.6963 - mse: 36548572.0000 - val_loss: 3185.4856 - val_mae: 3185.4856 - val_mse: 36909772.0000\n",
            "Epoch 75/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3020.1604 - mae: 3020.1604 - mse: 36186968.0000 - val_loss: 3215.9761 - val_mae: 3215.9761 - val_mse: 38126216.0000\n",
            "Epoch 76/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 3077.0215 - mae: 3077.0215 - mse: 37001808.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 3037.8140 - mae: 3037.8140 - mse: 36135072.0000 - val_loss: 3096.1655 - val_mae: 3096.1655 - val_mse: 37066068.0000\n",
            "Epoch 77/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 3060.5464 - mae: 3060.5464 - mse: 36482100.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 2976.3901 - mae: 2976.3901 - mse: 35036620.0000 - val_loss: 3001.2134 - val_mae: 3001.2134 - val_mse: 39532704.0000\n",
            "Epoch 78/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2947.2949 - mae: 2947.2949 - mse: 34754484.0000 - val_loss: 3063.0718 - val_mae: 3063.0718 - val_mse: 39619396.0000\n",
            "Epoch 79/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3033.7446 - mae: 3033.7446 - mse: 36581272.0000 - val_loss: 3010.5701 - val_mae: 3010.5701 - val_mse: 36412664.0000\n",
            "Epoch 80/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2899.9199 - mae: 2899.9199 - mse: 34585784.0000 - val_loss: 3172.7900 - val_mae: 3172.7900 - val_mse: 38075808.0000\n",
            "Epoch 81/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2954.4446 - mae: 2954.4446 - mse: 34865432.0000 - val_loss: 3267.0081 - val_mae: 3267.0081 - val_mse: 38657624.0000\n",
            "Epoch 82/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2928.0195 - mae: 2928.0195 - mse: 35204380.0000 - val_loss: 3247.7898 - val_mae: 3247.7898 - val_mse: 35200420.0000\n",
            "Epoch 83/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 2897.8191 - mae: 2897.8191 - mse: 33621892.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 2878.1953 - mae: 2878.1953 - mse: 33587988.0000 - val_loss: 2981.3494 - val_mae: 2981.3494 - val_mse: 36265196.0000\n",
            "Epoch 84/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2941.6489 - mae: 2941.6489 - mse: 35120200.0000 - val_loss: 3223.4456 - val_mae: 3223.4456 - val_mse: 37297432.0000\n",
            "Epoch 85/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 2858.9668 - mae: 2858.9668 - mse: 33577336.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 2882.7097 - mae: 2882.7097 - mse: 33835776.0000 - val_loss: 2849.2393 - val_mae: 2849.2393 - val_mse: 34161996.0000\n",
            "Epoch 86/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 2892.4390 - mae: 2892.4390 - mse: 34510316.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 57ms/step - loss: 2862.5789 - mae: 2862.5789 - mse: 34461276.0000 - val_loss: 2800.9761 - val_mae: 2800.9761 - val_mse: 34916840.0000\n",
            "Epoch 87/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2851.8259 - mae: 2851.8259 - mse: 34099984.0000 - val_loss: 3139.4312 - val_mae: 3139.4312 - val_mse: 35750476.0000\n",
            "Epoch 88/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2895.3015 - mae: 2895.3015 - mse: 33997332.0000 - val_loss: 3046.3093 - val_mae: 3046.3093 - val_mse: 33214424.0000\n",
            "Epoch 89/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2857.0430 - mae: 2857.0430 - mse: 33543864.0000 - val_loss: 2889.5359 - val_mae: 2889.5359 - val_mse: 33524496.0000\n",
            "Epoch 90/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2801.4685 - mae: 2801.4685 - mse: 32742960.0000 - val_loss: 3546.7529 - val_mae: 3546.7529 - val_mse: 34587996.0000\n",
            "Epoch 91/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2791.8765 - mae: 2791.8765 - mse: 32847174.0000 - val_loss: 2907.5688 - val_mae: 2907.5688 - val_mse: 34046828.0000\n",
            "Epoch 92/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 2580.4487 - mae: 2580.4487 - mse: 29498358.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 2831.0476 - mae: 2831.0476 - mse: 33271530.0000 - val_loss: 2780.3271 - val_mae: 2780.3271 - val_mse: 31953214.0000\n",
            "Epoch 93/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2801.2178 - mae: 2801.2178 - mse: 32244208.0000 - val_loss: 3133.6270 - val_mae: 3133.6270 - val_mse: 35829744.0000\n",
            "Epoch 94/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2783.0017 - mae: 2783.0017 - mse: 32591728.0000 - val_loss: 3159.4521 - val_mae: 3159.4521 - val_mse: 32970370.0000\n",
            "Epoch 95/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2782.0569 - mae: 2782.0569 - mse: 31626816.0000 - val_loss: 2941.1738 - val_mae: 2941.1738 - val_mse: 35906816.0000\n",
            "Epoch 96/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2768.2737 - mae: 2768.2737 - mse: 32287746.0000 - val_loss: 3102.6284 - val_mae: 3102.6284 - val_mse: 31738096.0000\n",
            "Epoch 97/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2758.5808 - mae: 2758.5808 - mse: 31490902.0000 - val_loss: 3107.8181 - val_mae: 3107.8181 - val_mse: 33968160.0000\n",
            "Epoch 98/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2744.0129 - mae: 2744.0129 - mse: 31726458.0000 - val_loss: 3053.7327 - val_mae: 3053.7327 - val_mse: 32327452.0000\n",
            "Epoch 99/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2771.3079 - mae: 2771.3079 - mse: 31721780.0000 - val_loss: 2809.9634 - val_mae: 2809.9634 - val_mse: 31171954.0000\n",
            "Epoch 100/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2764.0583 - mae: 2764.0583 - mse: 31890794.0000 - val_loss: 2922.7441 - val_mae: 2922.7441 - val_mse: 31913766.0000\n",
            "Epoch 101/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 2775.6462 - mae: 2775.6462 - mse: 32444548.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 2684.8914 - mae: 2684.8914 - mse: 30774386.0000 - val_loss: 2734.8726 - val_mae: 2734.8726 - val_mse: 31188326.0000\n",
            "Epoch 102/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 2676.3179 - mae: 2676.3179 - mse: 31536774.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 2703.2395 - mae: 2703.2395 - mse: 31096806.0000 - val_loss: 2678.8159 - val_mae: 2678.8159 - val_mse: 30404900.0000\n",
            "Epoch 103/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2721.0913 - mae: 2721.0913 - mse: 31302512.0000 - val_loss: 2762.0894 - val_mae: 2762.0894 - val_mse: 30984338.0000\n",
            "Epoch 104/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2673.3586 - mae: 2673.3586 - mse: 31417640.0000 - val_loss: 2829.0913 - val_mae: 2829.0913 - val_mse: 30316140.0000\n",
            "Epoch 105/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2740.3545 - mae: 2740.3545 - mse: 30678990.0000 - val_loss: 3081.5874 - val_mae: 3081.5874 - val_mse: 32155188.0000\n",
            "Epoch 106/1000\n",
            "27/27 [==============================] - ETA: 0s - loss: 2716.4619 - mae: 2716.4619 - mse: 30959386.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 53ms/step - loss: 2716.4619 - mae: 2716.4619 - mse: 30959386.0000 - val_loss: 2566.1360 - val_mae: 2566.1360 - val_mse: 29269752.0000\n",
            "Epoch 107/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2620.6572 - mae: 2620.6572 - mse: 30362738.0000 - val_loss: 2585.2559 - val_mae: 2585.2559 - val_mse: 29066376.0000\n",
            "Epoch 108/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 2733.5461 - mae: 2733.5461 - mse: 32382286.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 2665.1841 - mae: 2665.1841 - mse: 31036378.0000 - val_loss: 2544.0044 - val_mae: 2544.0044 - val_mse: 28589930.0000\n",
            "Epoch 109/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2631.1074 - mae: 2631.1074 - mse: 30525492.0000 - val_loss: 2787.7156 - val_mae: 2787.7156 - val_mse: 29609700.0000\n",
            "Epoch 110/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2623.0881 - mae: 2623.0881 - mse: 30266840.0000 - val_loss: 2631.5488 - val_mae: 2631.5488 - val_mse: 28980004.0000\n",
            "Epoch 111/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2591.7800 - mae: 2591.7800 - mse: 29511152.0000 - val_loss: 2703.5857 - val_mae: 2703.5857 - val_mse: 29162598.0000\n",
            "Epoch 112/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2593.8008 - mae: 2593.8008 - mse: 29709106.0000 - val_loss: 2636.3843 - val_mae: 2636.3843 - val_mse: 28780802.0000\n",
            "Epoch 113/1000\n",
            "27/27 [==============================] - ETA: 0s - loss: 2610.5950 - mae: 2610.5950 - mse: 29963796.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 60ms/step - loss: 2610.5950 - mae: 2610.5950 - mse: 29963796.0000 - val_loss: 2507.6233 - val_mae: 2507.6233 - val_mse: 27973490.0000\n",
            "Epoch 114/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2606.3049 - mae: 2606.3049 - mse: 29948052.0000 - val_loss: 2678.5479 - val_mae: 2678.5479 - val_mse: 27759552.0000\n",
            "Epoch 115/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2560.8330 - mae: 2560.8330 - mse: 29585184.0000 - val_loss: 2547.6875 - val_mae: 2547.6875 - val_mse: 27532714.0000\n",
            "Epoch 116/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2568.4836 - mae: 2568.4836 - mse: 29008032.0000 - val_loss: 2897.2705 - val_mae: 2897.2705 - val_mse: 29381238.0000\n",
            "Epoch 117/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2554.2515 - mae: 2554.2515 - mse: 29280142.0000 - val_loss: 2811.0168 - val_mae: 2811.0168 - val_mse: 27569056.0000\n",
            "Epoch 118/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 2514.4707 - mae: 2514.4707 - mse: 28228720.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 2572.4170 - mae: 2572.4170 - mse: 29287542.0000 - val_loss: 2457.8230 - val_mae: 2457.8230 - val_mse: 27257324.0000\n",
            "Epoch 119/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 2302.4561 - mae: 2302.4561 - mse: 25754020.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 2518.7678 - mae: 2518.7678 - mse: 28900798.0000 - val_loss: 2374.8032 - val_mae: 2374.8032 - val_mse: 27524696.0000\n",
            "Epoch 120/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2563.9841 - mae: 2563.9841 - mse: 29217080.0000 - val_loss: 2430.8472 - val_mae: 2430.8472 - val_mse: 27970714.0000\n",
            "Epoch 121/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2523.8342 - mae: 2523.8342 - mse: 29248816.0000 - val_loss: 2694.1562 - val_mae: 2694.1562 - val_mse: 28827878.0000\n",
            "Epoch 122/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 2497.2844 - mae: 2497.2844 - mse: 27411062.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 2523.2185 - mae: 2523.2185 - mse: 28797146.0000 - val_loss: 2339.4597 - val_mae: 2339.4597 - val_mse: 27015512.0000\n",
            "Epoch 123/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2474.2163 - mae: 2474.2163 - mse: 28538256.0000 - val_loss: 2395.9092 - val_mae: 2395.9092 - val_mse: 26920970.0000\n",
            "Epoch 124/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2469.5776 - mae: 2469.5776 - mse: 28291840.0000 - val_loss: 2760.6826 - val_mae: 2760.6826 - val_mse: 27677232.0000\n",
            "Epoch 125/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2560.5002 - mae: 2560.5002 - mse: 29349594.0000 - val_loss: 2700.3271 - val_mae: 2700.3271 - val_mse: 28214506.0000\n",
            "Epoch 126/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2523.6104 - mae: 2523.6104 - mse: 28774178.0000 - val_loss: 2549.5481 - val_mae: 2549.5481 - val_mse: 28142788.0000\n",
            "Epoch 127/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2483.7632 - mae: 2483.7632 - mse: 28514960.0000 - val_loss: 2469.9153 - val_mae: 2469.9153 - val_mse: 26636150.0000\n",
            "Epoch 128/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2456.5361 - mae: 2456.5361 - mse: 28197278.0000 - val_loss: 3051.2175 - val_mae: 3051.2175 - val_mse: 30134330.0000\n",
            "Epoch 129/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 2535.2302 - mae: 2535.2302 - mse: 30034398.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 2490.2083 - mae: 2490.2083 - mse: 28592162.0000 - val_loss: 2307.2942 - val_mae: 2307.2942 - val_mse: 26865766.0000\n",
            "Epoch 130/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2463.9802 - mae: 2463.9802 - mse: 28138166.0000 - val_loss: 2357.5532 - val_mae: 2357.5532 - val_mse: 26342216.0000\n",
            "Epoch 131/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2440.2610 - mae: 2440.2610 - mse: 28386616.0000 - val_loss: 2421.3508 - val_mae: 2421.3508 - val_mse: 25801926.0000\n",
            "Epoch 132/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 2583.6104 - mae: 2583.6104 - mse: 30049980.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 61ms/step - loss: 2446.5596 - mae: 2446.5596 - mse: 27988070.0000 - val_loss: 2293.6147 - val_mae: 2293.6147 - val_mse: 26127798.0000\n",
            "Epoch 133/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2373.8440 - mae: 2373.8440 - mse: 27257342.0000 - val_loss: 2766.5659 - val_mae: 2766.5659 - val_mse: 27898256.0000\n",
            "Epoch 134/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2400.5310 - mae: 2400.5310 - mse: 27464814.0000 - val_loss: 2699.6672 - val_mae: 2699.6672 - val_mse: 28261806.0000\n",
            "Epoch 135/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2462.1006 - mae: 2462.1006 - mse: 27994538.0000 - val_loss: 2350.1072 - val_mae: 2350.1072 - val_mse: 26613038.0000\n",
            "Epoch 136/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2342.4299 - mae: 2342.4299 - mse: 27127434.0000 - val_loss: 2857.6208 - val_mae: 2857.6208 - val_mse: 27262280.0000\n",
            "Epoch 137/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2420.6506 - mae: 2420.6506 - mse: 27601334.0000 - val_loss: 2573.2546 - val_mae: 2573.2546 - val_mse: 27383140.0000\n",
            "Epoch 138/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2372.4600 - mae: 2372.4600 - mse: 27109096.0000 - val_loss: 2581.6370 - val_mae: 2581.6370 - val_mse: 28177142.0000\n",
            "Epoch 139/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2456.6721 - mae: 2456.6721 - mse: 27956824.0000 - val_loss: 2302.2793 - val_mae: 2302.2793 - val_mse: 25442386.0000\n",
            "Epoch 140/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2356.0034 - mae: 2356.0034 - mse: 27000342.0000 - val_loss: 2583.1833 - val_mae: 2583.1833 - val_mse: 27190154.0000\n",
            "Epoch 141/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2387.8835 - mae: 2387.8835 - mse: 27427278.0000 - val_loss: 2442.7341 - val_mae: 2442.7341 - val_mse: 26713318.0000\n",
            "Epoch 142/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2385.6157 - mae: 2385.6157 - mse: 27346322.0000 - val_loss: 2363.3438 - val_mae: 2363.3438 - val_mse: 26361928.0000\n",
            "Epoch 143/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2340.3252 - mae: 2340.3252 - mse: 26502176.0000 - val_loss: 2630.6521 - val_mae: 2630.6521 - val_mse: 27262196.0000\n",
            "Epoch 144/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 2379.7993 - mae: 2379.7993 - mse: 27552362.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 2366.0198 - mae: 2366.0198 - mse: 26973692.0000 - val_loss: 2271.7974 - val_mae: 2271.7974 - val_mse: 26233166.0000\n",
            "Epoch 145/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2354.7954 - mae: 2354.7954 - mse: 27119698.0000 - val_loss: 2337.5889 - val_mae: 2337.5889 - val_mse: 25677650.0000\n",
            "Epoch 146/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2359.8755 - mae: 2359.8755 - mse: 26619388.0000 - val_loss: 2346.0439 - val_mae: 2346.0439 - val_mse: 25873986.0000\n",
            "Epoch 147/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2296.9861 - mae: 2296.9861 - mse: 25992032.0000 - val_loss: 2292.8140 - val_mae: 2292.8140 - val_mse: 25779020.0000\n",
            "Epoch 148/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2362.8955 - mae: 2362.8955 - mse: 26913998.0000 - val_loss: 2459.3418 - val_mae: 2459.3418 - val_mse: 25055014.0000\n",
            "Epoch 149/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2341.4290 - mae: 2341.4290 - mse: 26823782.0000 - val_loss: 2480.2722 - val_mae: 2480.2722 - val_mse: 26767282.0000\n",
            "Epoch 150/1000\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 2241.5010 - mae: 2241.5010 - mse: 24225144.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 2321.7300 - mae: 2321.7300 - mse: 25932120.0000 - val_loss: 2264.9541 - val_mae: 2264.9541 - val_mse: 25509792.0000\n",
            "Epoch 151/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2359.5305 - mae: 2359.5305 - mse: 26829602.0000 - val_loss: 2583.5547 - val_mae: 2583.5547 - val_mse: 27082280.0000\n",
            "Epoch 152/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2285.3313 - mae: 2285.3313 - mse: 26230452.0000 - val_loss: 2524.5935 - val_mae: 2524.5935 - val_mse: 26757094.0000\n",
            "Epoch 153/1000\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 2350.4082 - mae: 2350.4082 - mse: 27075490.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 53ms/step - loss: 2332.6277 - mae: 2332.6277 - mse: 26817710.0000 - val_loss: 2241.7534 - val_mae: 2241.7534 - val_mse: 25578888.0000\n",
            "Epoch 154/1000\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 2261.3865 - mae: 2261.3865 - mse: 25832024.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 2284.0813 - mae: 2284.0813 - mse: 26134284.0000 - val_loss: 2202.7532 - val_mae: 2202.7532 - val_mse: 25526466.0000\n",
            "Epoch 155/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2262.3730 - mae: 2262.3730 - mse: 25571848.0000 - val_loss: 2245.9087 - val_mae: 2245.9087 - val_mse: 25214208.0000\n",
            "Epoch 156/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 2286.4541 - mae: 2286.4541 - mse: 25810888.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 2278.2976 - mae: 2278.2976 - mse: 26018914.0000 - val_loss: 2182.5007 - val_mae: 2182.5007 - val_mse: 25413932.0000\n",
            "Epoch 157/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2278.8926 - mae: 2278.8926 - mse: 25914088.0000 - val_loss: 2196.9307 - val_mae: 2196.9307 - val_mse: 24851976.0000\n",
            "Epoch 158/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2277.6025 - mae: 2277.6025 - mse: 25919184.0000 - val_loss: 2542.2935 - val_mae: 2542.2935 - val_mse: 26667216.0000\n",
            "Epoch 159/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2309.4163 - mae: 2309.4163 - mse: 26305258.0000 - val_loss: 2522.2810 - val_mae: 2522.2810 - val_mse: 26662290.0000\n",
            "Epoch 160/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2301.0857 - mae: 2301.0857 - mse: 26398364.0000 - val_loss: 2253.6965 - val_mae: 2253.6965 - val_mse: 25397394.0000\n",
            "Epoch 161/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2248.9180 - mae: 2248.9180 - mse: 25643620.0000 - val_loss: 2240.5923 - val_mae: 2240.5923 - val_mse: 24850178.0000\n",
            "Epoch 162/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2242.7896 - mae: 2242.7896 - mse: 25708344.0000 - val_loss: 2289.1189 - val_mae: 2289.1189 - val_mse: 24465656.0000\n",
            "Epoch 163/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2281.7100 - mae: 2281.7100 - mse: 25668160.0000 - val_loss: 2224.6306 - val_mae: 2224.6306 - val_mse: 24255118.0000\n",
            "Epoch 164/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 2153.5620 - mae: 2153.5620 - mse: 25073510.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 2205.4385 - mae: 2205.4385 - mse: 25504088.0000 - val_loss: 2141.8748 - val_mae: 2141.8748 - val_mse: 25032000.0000\n",
            "Epoch 165/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2270.7942 - mae: 2270.7942 - mse: 25727154.0000 - val_loss: 2466.0923 - val_mae: 2466.0923 - val_mse: 26132960.0000\n",
            "Epoch 166/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2257.3264 - mae: 2257.3264 - mse: 25270214.0000 - val_loss: 2216.2617 - val_mae: 2216.2617 - val_mse: 24019692.0000\n",
            "Epoch 167/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2217.0237 - mae: 2217.0237 - mse: 25733342.0000 - val_loss: 2405.9180 - val_mae: 2405.9180 - val_mse: 25941188.0000\n",
            "Epoch 168/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2247.7839 - mae: 2247.7839 - mse: 25578610.0000 - val_loss: 2412.0530 - val_mae: 2412.0530 - val_mse: 25793192.0000\n",
            "Epoch 169/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2238.0928 - mae: 2238.0928 - mse: 25640712.0000 - val_loss: 2203.3196 - val_mae: 2203.3196 - val_mse: 24364932.0000\n",
            "Epoch 170/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2222.6111 - mae: 2222.6111 - mse: 25274616.0000 - val_loss: 2161.8164 - val_mae: 2161.8164 - val_mse: 24220400.0000\n",
            "Epoch 171/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2219.1643 - mae: 2219.1643 - mse: 25080588.0000 - val_loss: 2211.7622 - val_mae: 2211.7622 - val_mse: 24913436.0000\n",
            "Epoch 172/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2225.1665 - mae: 2225.1665 - mse: 25439692.0000 - val_loss: 2199.4204 - val_mae: 2199.4204 - val_mse: 23924906.0000\n",
            "Epoch 173/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2210.8865 - mae: 2210.8865 - mse: 25352912.0000 - val_loss: 2761.2505 - val_mae: 2761.2505 - val_mse: 27860044.0000\n",
            "Epoch 174/1000\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 2169.7395 - mae: 2169.7395 - mse: 24195292.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 61ms/step - loss: 2168.9043 - mae: 2168.9043 - mse: 24439270.0000 - val_loss: 2106.9333 - val_mae: 2106.9333 - val_mse: 24363066.0000\n",
            "Epoch 175/1000\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 2135.9727 - mae: 2135.9727 - mse: 23783534.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 2228.2158 - mae: 2228.2158 - mse: 25089726.0000 - val_loss: 2082.2954 - val_mae: 2082.2954 - val_mse: 24233788.0000\n",
            "Epoch 176/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2204.5500 - mae: 2204.5500 - mse: 25271538.0000 - val_loss: 2378.1343 - val_mae: 2378.1343 - val_mse: 25036340.0000\n",
            "Epoch 177/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2251.8191 - mae: 2251.8191 - mse: 25280290.0000 - val_loss: 2233.9033 - val_mae: 2233.9033 - val_mse: 24770312.0000\n",
            "Epoch 178/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2208.1230 - mae: 2208.1230 - mse: 25235846.0000 - val_loss: 2379.5037 - val_mae: 2379.5037 - val_mse: 25552160.0000\n",
            "Epoch 179/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2248.2671 - mae: 2248.2671 - mse: 25306554.0000 - val_loss: 2228.5479 - val_mae: 2228.5479 - val_mse: 24662682.0000\n",
            "Epoch 180/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2171.8809 - mae: 2171.8809 - mse: 25026734.0000 - val_loss: 2198.7139 - val_mae: 2198.7139 - val_mse: 23421978.0000\n",
            "Epoch 181/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2187.6460 - mae: 2187.6460 - mse: 24842748.0000 - val_loss: 2116.2671 - val_mae: 2116.2671 - val_mse: 24055172.0000\n",
            "Epoch 182/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 2185.7009 - mae: 2185.7009 - mse: 24563772.0000 - val_loss: 2721.9961 - val_mae: 2721.9961 - val_mse: 26901684.0000\n",
            "Epoch 183/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2161.1995 - mae: 2161.1995 - mse: 24877592.0000 - val_loss: 2794.2505 - val_mae: 2794.2505 - val_mse: 26417874.0000\n",
            "Epoch 184/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2189.4534 - mae: 2189.4534 - mse: 24171280.0000 - val_loss: 2791.1494 - val_mae: 2791.1494 - val_mse: 28979354.0000\n",
            "Epoch 185/1000\n",
            "27/27 [==============================] - ETA: 0s - loss: 2188.1372 - mae: 2188.1372 - mse: 24654070.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 2188.1372 - mae: 2188.1372 - mse: 24654070.0000 - val_loss: 2069.0942 - val_mae: 2069.0942 - val_mse: 23807940.0000\n",
            "Epoch 186/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2140.2019 - mae: 2140.2019 - mse: 24825396.0000 - val_loss: 2489.7524 - val_mae: 2489.7524 - val_mse: 26930192.0000\n",
            "Epoch 187/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2218.2703 - mae: 2218.2703 - mse: 24920532.0000 - val_loss: 2110.1772 - val_mae: 2110.1772 - val_mse: 24024244.0000\n",
            "Epoch 188/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2197.7102 - mae: 2197.7102 - mse: 24911810.0000 - val_loss: 2219.4492 - val_mae: 2219.4492 - val_mse: 24363422.0000\n",
            "Epoch 189/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2175.3586 - mae: 2175.3586 - mse: 24915810.0000 - val_loss: 2191.4729 - val_mae: 2191.4729 - val_mse: 24226638.0000\n",
            "Epoch 190/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2147.9524 - mae: 2147.9524 - mse: 24517680.0000 - val_loss: 2355.0342 - val_mae: 2355.0342 - val_mse: 24975238.0000\n",
            "Epoch 191/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2175.0889 - mae: 2175.0889 - mse: 24674386.0000 - val_loss: 2523.9749 - val_mae: 2523.9749 - val_mse: 25460630.0000\n",
            "Epoch 192/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2178.2422 - mae: 2178.2422 - mse: 24586530.0000 - val_loss: 2184.9800 - val_mae: 2184.9800 - val_mse: 24181798.0000\n",
            "Epoch 193/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2134.2546 - mae: 2134.2546 - mse: 23830890.0000 - val_loss: 2220.9983 - val_mae: 2220.9983 - val_mse: 23794484.0000\n",
            "Epoch 194/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2142.8477 - mae: 2142.8477 - mse: 23982108.0000 - val_loss: 2414.9067 - val_mae: 2414.9067 - val_mse: 24471470.0000\n",
            "Epoch 195/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2160.4797 - mae: 2160.4800 - mse: 24113564.0000 - val_loss: 2439.6846 - val_mae: 2439.6846 - val_mse: 25133446.0000\n",
            "Epoch 196/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2127.4087 - mae: 2127.4087 - mse: 23846618.0000 - val_loss: 2257.5859 - val_mae: 2257.5859 - val_mse: 24889242.0000\n",
            "Epoch 197/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2154.3315 - mae: 2154.3315 - mse: 23893172.0000 - val_loss: 2321.0249 - val_mae: 2321.0249 - val_mse: 24766850.0000\n",
            "Epoch 198/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2150.2273 - mae: 2150.2273 - mse: 24162068.0000 - val_loss: 2173.1108 - val_mae: 2173.1108 - val_mse: 23044000.0000\n",
            "Epoch 199/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2149.6318 - mae: 2149.6318 - mse: 24080272.0000 - val_loss: 2271.9409 - val_mae: 2271.9409 - val_mse: 25265820.0000\n",
            "Epoch 200/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2159.0779 - mae: 2159.0779 - mse: 23874684.0000 - val_loss: 2074.2554 - val_mae: 2074.2554 - val_mse: 23821152.0000\n",
            "Epoch 201/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2142.4854 - mae: 2142.4854 - mse: 24060372.0000 - val_loss: 2438.6252 - val_mae: 2438.6252 - val_mse: 25482142.0000\n",
            "Epoch 202/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2146.6204 - mae: 2146.6204 - mse: 23930394.0000 - val_loss: 2252.2170 - val_mae: 2252.2170 - val_mse: 24143132.0000\n",
            "Epoch 203/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2106.6484 - mae: 2106.6484 - mse: 23579424.0000 - val_loss: 2512.1833 - val_mae: 2512.1833 - val_mse: 25758500.0000\n",
            "Epoch 204/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2154.3499 - mae: 2154.3499 - mse: 24534076.0000 - val_loss: 2289.4705 - val_mae: 2289.4705 - val_mse: 24210710.0000\n",
            "Epoch 205/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2115.2241 - mae: 2115.2241 - mse: 24013078.0000 - val_loss: 2213.3701 - val_mae: 2213.3701 - val_mse: 24091876.0000\n",
            "Epoch 206/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2106.0376 - mae: 2106.0376 - mse: 23702940.0000 - val_loss: 2412.8962 - val_mae: 2412.8962 - val_mse: 25126228.0000\n",
            "Epoch 207/1000\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 2088.8015 - mae: 2088.8015 - mse: 23814096.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 2096.8687 - mae: 2096.8687 - mse: 23544274.0000 - val_loss: 2033.2108 - val_mae: 2033.2108 - val_mse: 23255384.0000\n",
            "Epoch 208/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2124.0671 - mae: 2124.0671 - mse: 23673158.0000 - val_loss: 2362.2983 - val_mae: 2362.2983 - val_mse: 22946324.0000\n",
            "Epoch 209/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2100.3521 - mae: 2100.3521 - mse: 23614696.0000 - val_loss: 2199.0254 - val_mae: 2199.0254 - val_mse: 23004054.0000\n",
            "Epoch 210/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2085.8828 - mae: 2085.8828 - mse: 23237460.0000 - val_loss: 2337.3030 - val_mae: 2337.3030 - val_mse: 22971570.0000\n",
            "Epoch 211/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2105.7725 - mae: 2105.7725 - mse: 23368754.0000 - val_loss: 2390.0635 - val_mae: 2390.0635 - val_mse: 24876792.0000\n",
            "Epoch 212/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2154.9377 - mae: 2154.9377 - mse: 24006340.0000 - val_loss: 2144.7195 - val_mae: 2144.7195 - val_mse: 22445654.0000\n",
            "Epoch 213/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2091.9219 - mae: 2091.9219 - mse: 23390878.0000 - val_loss: 2175.6445 - val_mae: 2175.6445 - val_mse: 22430790.0000\n",
            "Epoch 214/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2105.2285 - mae: 2105.2285 - mse: 23409550.0000 - val_loss: 2275.0720 - val_mae: 2275.0720 - val_mse: 23709144.0000\n",
            "Epoch 215/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2090.6780 - mae: 2090.6780 - mse: 23781128.0000 - val_loss: 2134.5059 - val_mae: 2134.5059 - val_mse: 23780580.0000\n",
            "Epoch 216/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2138.3123 - mae: 2138.3123 - mse: 23593382.0000 - val_loss: 2037.1643 - val_mae: 2037.1643 - val_mse: 22992818.0000\n",
            "Epoch 217/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2079.5623 - mae: 2079.5623 - mse: 23420320.0000 - val_loss: 2164.6863 - val_mae: 2164.6863 - val_mse: 22849434.0000\n",
            "Epoch 218/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2094.5054 - mae: 2094.5054 - mse: 23514656.0000 - val_loss: 2078.7424 - val_mae: 2078.7424 - val_mse: 23703590.0000\n",
            "Epoch 219/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2083.2844 - mae: 2083.2844 - mse: 23266196.0000 - val_loss: 2351.4058 - val_mae: 2351.4058 - val_mse: 25266348.0000\n",
            "Epoch 220/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2031.5817 - mae: 2031.5817 - mse: 22784272.0000 - val_loss: 2282.2200 - val_mae: 2282.2200 - val_mse: 24584794.0000\n",
            "Epoch 221/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2100.1919 - mae: 2100.1919 - mse: 23531988.0000 - val_loss: 2240.9641 - val_mae: 2240.9641 - val_mse: 22682814.0000\n",
            "Epoch 222/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2071.3350 - mae: 2071.3350 - mse: 23102424.0000 - val_loss: 2806.2681 - val_mae: 2806.2681 - val_mse: 26994538.0000\n",
            "Epoch 223/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2106.5994 - mae: 2106.5994 - mse: 23567346.0000 - val_loss: 2092.1597 - val_mae: 2092.1597 - val_mse: 22301614.0000\n",
            "Epoch 224/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2093.5891 - mae: 2093.5891 - mse: 23601696.0000 - val_loss: 2242.1709 - val_mae: 2242.1709 - val_mse: 23793440.0000\n",
            "Epoch 225/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2076.6387 - mae: 2076.6387 - mse: 23473166.0000 - val_loss: 2053.5405 - val_mae: 2053.5405 - val_mse: 23155958.0000\n",
            "Epoch 226/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2074.1895 - mae: 2074.1895 - mse: 23152206.0000 - val_loss: 2177.7781 - val_mae: 2177.7781 - val_mse: 24914834.0000\n",
            "Epoch 227/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 2129.8455 - mae: 2129.8455 - mse: 23609930.0000 - val_loss: 2038.4178 - val_mae: 2038.4178 - val_mse: 23120764.0000\n",
            "Epoch 228/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2039.0665 - mae: 2039.0665 - mse: 22827560.0000 - val_loss: 2122.7622 - val_mae: 2122.7622 - val_mse: 22099830.0000\n",
            "Epoch 229/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2068.0063 - mae: 2068.0063 - mse: 23119368.0000 - val_loss: 2233.5254 - val_mae: 2233.5256 - val_mse: 25424706.0000\n",
            "Epoch 230/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2067.7261 - mae: 2067.7261 - mse: 23172036.0000 - val_loss: 2578.1350 - val_mae: 2578.1350 - val_mse: 28298440.0000\n",
            "Epoch 231/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2066.3096 - mae: 2066.3096 - mse: 23138464.0000 - val_loss: 2388.6536 - val_mae: 2388.6536 - val_mse: 26136346.0000\n",
            "Epoch 232/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2116.0857 - mae: 2116.0857 - mse: 23351044.0000 - val_loss: 2236.9790 - val_mae: 2236.9790 - val_mse: 24092476.0000\n",
            "Epoch 233/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2029.5314 - mae: 2029.5314 - mse: 22953104.0000 - val_loss: 2214.6594 - val_mae: 2214.6594 - val_mse: 22665310.0000\n",
            "Epoch 234/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2066.2498 - mae: 2066.2498 - mse: 22967218.0000 - val_loss: 2082.5552 - val_mae: 2082.5552 - val_mse: 23729800.0000\n",
            "Epoch 235/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2061.8442 - mae: 2061.8442 - mse: 23051846.0000 - val_loss: 2268.8491 - val_mae: 2268.8491 - val_mse: 21765266.0000\n",
            "Epoch 236/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2111.8625 - mae: 2111.8625 - mse: 23387624.0000 - val_loss: 2303.9592 - val_mae: 2303.9592 - val_mse: 23733798.0000\n",
            "Epoch 237/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2046.1732 - mae: 2046.1732 - mse: 22789412.0000 - val_loss: 2307.6147 - val_mae: 2307.6147 - val_mse: 22477436.0000\n",
            "Epoch 238/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2061.5693 - mae: 2061.5693 - mse: 23131406.0000 - val_loss: 2273.4170 - val_mae: 2273.4170 - val_mse: 23759704.0000\n",
            "Epoch 239/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2083.4517 - mae: 2083.4517 - mse: 23333950.0000 - val_loss: 2296.3875 - val_mae: 2296.3875 - val_mse: 22913246.0000\n",
            "Epoch 240/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2031.0848 - mae: 2031.0848 - mse: 22527792.0000 - val_loss: 2131.2727 - val_mae: 2131.2727 - val_mse: 22012576.0000\n",
            "Epoch 241/1000\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1940.8914 - mae: 1940.8914 - mse: 20262420.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 50ms/step - loss: 2054.9370 - mae: 2054.9370 - mse: 22615248.0000 - val_loss: 2014.6869 - val_mae: 2014.6869 - val_mse: 22359658.0000\n",
            "Epoch 242/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2077.0552 - mae: 2077.0552 - mse: 22913168.0000 - val_loss: 2065.8569 - val_mae: 2065.8569 - val_mse: 22734108.0000\n",
            "Epoch 243/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1999.4385 - mae: 1999.4385 - mse: 22640688.0000 - val_loss: 2120.1653 - val_mae: 2120.1653 - val_mse: 21828034.0000\n",
            "Epoch 244/1000\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 2032.7756 - mae: 2032.7756 - mse: 22748952.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 2041.2881 - mae: 2041.2881 - mse: 22948356.0000 - val_loss: 1995.1304 - val_mae: 1995.1304 - val_mse: 22678274.0000\n",
            "Epoch 245/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2025.1991 - mae: 2025.1991 - mse: 22723082.0000 - val_loss: 2151.7190 - val_mae: 2151.7190 - val_mse: 24238978.0000\n",
            "Epoch 246/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2064.2021 - mae: 2064.2021 - mse: 22754238.0000 - val_loss: 2003.8629 - val_mae: 2003.8629 - val_mse: 22794998.0000\n",
            "Epoch 247/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2039.1531 - mae: 2039.1531 - mse: 22870452.0000 - val_loss: 2042.2882 - val_mae: 2042.2882 - val_mse: 22620156.0000\n",
            "Epoch 248/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2073.7222 - mae: 2073.7222 - mse: 23249208.0000 - val_loss: 2356.9998 - val_mae: 2356.9998 - val_mse: 26011006.0000\n",
            "Epoch 249/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2042.1168 - mae: 2042.1168 - mse: 22658924.0000 - val_loss: 2169.0081 - val_mae: 2169.0081 - val_mse: 24026320.0000\n",
            "Epoch 250/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2048.9368 - mae: 2048.9368 - mse: 22932362.0000 - val_loss: 2060.0010 - val_mae: 2060.0010 - val_mse: 23456620.0000\n",
            "Epoch 251/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2069.6472 - mae: 2069.6472 - mse: 22901246.0000 - val_loss: 2107.3337 - val_mae: 2107.3337 - val_mse: 21723634.0000\n",
            "Epoch 252/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2030.5259 - mae: 2030.5259 - mse: 22650274.0000 - val_loss: 2133.3179 - val_mae: 2133.3179 - val_mse: 23339312.0000\n",
            "Epoch 253/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1981.8796 - mae: 1981.8796 - mse: 22520658.0000 - val_loss: 2013.2017 - val_mae: 2013.2017 - val_mse: 22129074.0000\n",
            "Epoch 254/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2040.1027 - mae: 2040.1027 - mse: 23007186.0000 - val_loss: 2144.9104 - val_mae: 2144.9104 - val_mse: 22013278.0000\n",
            "Epoch 255/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2021.8176 - mae: 2021.8176 - mse: 22363854.0000 - val_loss: 2165.4753 - val_mae: 2165.4753 - val_mse: 22296190.0000\n",
            "Epoch 256/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2024.6104 - mae: 2024.6104 - mse: 22440556.0000 - val_loss: 2104.1760 - val_mae: 2104.1760 - val_mse: 23270994.0000\n",
            "Epoch 257/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2017.6970 - mae: 2017.6970 - mse: 22725854.0000 - val_loss: 2296.3931 - val_mae: 2296.3931 - val_mse: 22462854.0000\n",
            "Epoch 258/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2043.9116 - mae: 2043.9116 - mse: 22684442.0000 - val_loss: 2136.8186 - val_mae: 2136.8186 - val_mse: 23026648.0000\n",
            "Epoch 259/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2003.9484 - mae: 2003.9484 - mse: 22140284.0000 - val_loss: 2320.0237 - val_mae: 2320.0237 - val_mse: 25374454.0000\n",
            "Epoch 260/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2010.5027 - mae: 2010.5027 - mse: 22476090.0000 - val_loss: 2005.0698 - val_mae: 2005.0698 - val_mse: 21833350.0000\n",
            "Epoch 261/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 2025.1813 - mae: 2025.1813 - mse: 22716244.0000 - val_loss: 2223.5828 - val_mae: 2223.5828 - val_mse: 23556232.0000\n",
            "Epoch 262/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2053.3799 - mae: 2053.3799 - mse: 23005262.0000 - val_loss: 2069.0459 - val_mae: 2069.0459 - val_mse: 21955072.0000\n",
            "Epoch 263/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2036.7043 - mae: 2036.7043 - mse: 22549946.0000 - val_loss: 2189.5925 - val_mae: 2189.5925 - val_mse: 24003104.0000\n",
            "Epoch 264/1000\n",
            "27/27 [==============================] - ETA: 0s - loss: 1991.1483 - mae: 1991.1483 - mse: 22039334.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 61ms/step - loss: 1991.1483 - mae: 1991.1483 - mse: 22039334.0000 - val_loss: 1960.3845 - val_mae: 1960.3845 - val_mse: 21949644.0000\n",
            "Epoch 265/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1988.9781 - mae: 1988.9781 - mse: 22063190.0000 - val_loss: 2143.4275 - val_mae: 2143.4275 - val_mse: 24200342.0000\n",
            "Epoch 266/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2035.4521 - mae: 2035.4521 - mse: 22760194.0000 - val_loss: 2033.4324 - val_mae: 2033.4324 - val_mse: 22682736.0000\n",
            "Epoch 267/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2015.9532 - mae: 2015.9532 - mse: 22425388.0000 - val_loss: 1977.2694 - val_mae: 1977.2694 - val_mse: 22015138.0000\n",
            "Epoch 268/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1989.6082 - mae: 1989.6082 - mse: 22102548.0000 - val_loss: 2177.8062 - val_mae: 2177.8062 - val_mse: 23228244.0000\n",
            "Epoch 269/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2004.9086 - mae: 2004.9086 - mse: 22704396.0000 - val_loss: 2360.1216 - val_mae: 2360.1216 - val_mse: 24564518.0000\n",
            "Epoch 270/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2034.8622 - mae: 2034.8622 - mse: 22571350.0000 - val_loss: 2161.6914 - val_mae: 2161.6914 - val_mse: 21096474.0000\n",
            "Epoch 271/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2016.3907 - mae: 2016.3907 - mse: 22432338.0000 - val_loss: 2078.7568 - val_mae: 2078.7568 - val_mse: 23040062.0000\n",
            "Epoch 272/1000\n",
            "27/27 [==============================] - ETA: 0s - loss: 1990.8031 - mae: 1990.8031 - mse: 22411932.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 1990.8031 - mae: 1990.8031 - mse: 22411932.0000 - val_loss: 1956.3640 - val_mae: 1956.3640 - val_mse: 21821232.0000\n",
            "Epoch 273/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2004.6024 - mae: 2004.6024 - mse: 22490128.0000 - val_loss: 1979.2655 - val_mae: 1979.2655 - val_mse: 21883004.0000\n",
            "Epoch 274/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2026.2815 - mae: 2026.2815 - mse: 22620784.0000 - val_loss: 2353.7737 - val_mae: 2353.7737 - val_mse: 26283980.0000\n",
            "Epoch 275/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1995.2938 - mae: 1995.2938 - mse: 22025786.0000 - val_loss: 2125.1611 - val_mae: 2125.1611 - val_mse: 23049556.0000\n",
            "Epoch 276/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1992.9309 - mae: 1992.9309 - mse: 22083350.0000 - val_loss: 2022.3087 - val_mae: 2022.3087 - val_mse: 21376492.0000\n",
            "Epoch 277/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2022.8112 - mae: 2022.8112 - mse: 22733668.0000 - val_loss: 2095.6387 - val_mae: 2095.6387 - val_mse: 21344484.0000\n",
            "Epoch 278/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2000.1936 - mae: 2000.1936 - mse: 22021282.0000 - val_loss: 2230.2473 - val_mae: 2230.2473 - val_mse: 21747610.0000\n",
            "Epoch 279/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1980.3496 - mae: 1980.3496 - mse: 22574418.0000 - val_loss: 2006.8641 - val_mae: 2006.8641 - val_mse: 21955570.0000\n",
            "Epoch 280/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2043.0570 - mae: 2043.0570 - mse: 22778928.0000 - val_loss: 1990.3578 - val_mae: 1990.3578 - val_mse: 21969692.0000\n",
            "Epoch 281/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1983.2250 - mae: 1983.2250 - mse: 22088642.0000 - val_loss: 2385.4500 - val_mae: 2385.4500 - val_mse: 24843646.0000\n",
            "Epoch 282/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2002.1364 - mae: 2002.1364 - mse: 22265004.0000 - val_loss: 2051.3987 - val_mae: 2051.3987 - val_mse: 22342666.0000\n",
            "Epoch 283/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2041.2054 - mae: 2041.2054 - mse: 22825682.0000 - val_loss: 2361.5168 - val_mae: 2361.5168 - val_mse: 22139116.0000\n",
            "Epoch 284/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2041.4084 - mae: 2041.4084 - mse: 22738984.0000 - val_loss: 1992.3907 - val_mae: 1992.3907 - val_mse: 22103158.0000\n",
            "Epoch 285/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1966.2529 - mae: 1966.2529 - mse: 22038078.0000 - val_loss: 2061.7588 - val_mae: 2061.7588 - val_mse: 23145226.0000\n",
            "Epoch 286/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1981.6329 - mae: 1981.6329 - mse: 22119366.0000 - val_loss: 2008.6180 - val_mae: 2008.6180 - val_mse: 21840380.0000\n",
            "Epoch 287/1000\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 2048.4216 - mae: 2048.4216 - mse: 23058888.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 2015.3750 - mae: 2015.3750 - mse: 22503450.0000 - val_loss: 1929.6111 - val_mae: 1929.6111 - val_mse: 21653682.0000\n",
            "Epoch 288/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2022.5005 - mae: 2022.5005 - mse: 22169876.0000 - val_loss: 2524.9021 - val_mae: 2524.9021 - val_mse: 27130760.0000\n",
            "Epoch 289/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1961.2261 - mae: 1961.2261 - mse: 22174802.0000 - val_loss: 2369.5154 - val_mae: 2369.5154 - val_mse: 22511420.0000\n",
            "Epoch 290/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2010.5812 - mae: 2010.5812 - mse: 22406280.0000 - val_loss: 2238.8118 - val_mae: 2238.8118 - val_mse: 25198544.0000\n",
            "Epoch 291/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1985.5571 - mae: 1985.5571 - mse: 22148428.0000 - val_loss: 2574.1606 - val_mae: 2574.1606 - val_mse: 23417158.0000\n",
            "Epoch 292/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1965.8600 - mae: 1965.8600 - mse: 22328294.0000 - val_loss: 2133.0317 - val_mae: 2133.0317 - val_mse: 23238006.0000\n",
            "Epoch 293/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 2015.1249 - mae: 2015.1249 - mse: 22446750.0000 - val_loss: 2092.4585 - val_mae: 2092.4585 - val_mse: 22464132.0000\n",
            "Epoch 294/1000\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1981.9641 - mae: 1981.9641 - mse: 22169346.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 54ms/step - loss: 1997.7886 - mae: 1997.7886 - mse: 22207610.0000 - val_loss: 1924.1580 - val_mae: 1924.1580 - val_mse: 21899084.0000\n",
            "Epoch 295/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1990.0978 - mae: 1990.0978 - mse: 22273718.0000 - val_loss: 2038.9663 - val_mae: 2038.9663 - val_mse: 22215714.0000\n",
            "Epoch 296/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1973.5239 - mae: 1973.5239 - mse: 22115110.0000 - val_loss: 2062.6987 - val_mae: 2062.6987 - val_mse: 22564616.0000\n",
            "Epoch 297/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2014.9828 - mae: 2014.9828 - mse: 22660914.0000 - val_loss: 2123.1597 - val_mae: 2123.1597 - val_mse: 22614682.0000\n",
            "Epoch 298/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1947.9946 - mae: 1947.9946 - mse: 21680674.0000 - val_loss: 2451.0447 - val_mae: 2451.0447 - val_mse: 24819716.0000\n",
            "Epoch 299/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2000.7010 - mae: 2000.7010 - mse: 22377622.0000 - val_loss: 2092.6475 - val_mae: 2092.6475 - val_mse: 20930612.0000\n",
            "Epoch 300/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1999.0902 - mae: 1999.0902 - mse: 22189962.0000 - val_loss: 2254.3579 - val_mae: 2254.3579 - val_mse: 22761414.0000\n",
            "Epoch 301/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1969.1222 - mae: 1969.1222 - mse: 21805838.0000 - val_loss: 2062.2566 - val_mae: 2062.2566 - val_mse: 23086174.0000\n",
            "Epoch 302/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1988.2137 - mae: 1988.2137 - mse: 21861658.0000 - val_loss: 2278.4744 - val_mae: 2278.4744 - val_mse: 21367194.0000\n",
            "Epoch 303/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1958.5469 - mae: 1958.5469 - mse: 21978006.0000 - val_loss: 1939.4760 - val_mae: 1939.4760 - val_mse: 21768090.0000\n",
            "Epoch 304/1000\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 2008.2705 - mae: 2008.2705 - mse: 22098304.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 1997.2128 - mae: 1997.2128 - mse: 22102452.0000 - val_loss: 1919.9955 - val_mae: 1919.9955 - val_mse: 21761958.0000\n",
            "Epoch 305/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1951.2977 - mae: 1951.2977 - mse: 21652468.0000 - val_loss: 2132.9221 - val_mae: 2132.9221 - val_mse: 22376220.0000\n",
            "Epoch 306/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1955.6476 - mae: 1955.6476 - mse: 22162612.0000 - val_loss: 2078.3523 - val_mae: 2078.3523 - val_mse: 20962478.0000\n",
            "Epoch 307/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1994.7788 - mae: 1994.7788 - mse: 22041712.0000 - val_loss: 2057.6538 - val_mae: 2057.6538 - val_mse: 21899496.0000\n",
            "Epoch 308/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2000.1787 - mae: 2000.1787 - mse: 22163336.0000 - val_loss: 2111.7307 - val_mae: 2111.7307 - val_mse: 21899530.0000\n",
            "Epoch 309/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1948.5099 - mae: 1948.5099 - mse: 21861790.0000 - val_loss: 1977.6035 - val_mae: 1977.6035 - val_mse: 21008794.0000\n",
            "Epoch 310/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1954.0623 - mae: 1954.0623 - mse: 21608630.0000 - val_loss: 2110.9905 - val_mae: 2110.9905 - val_mse: 21896130.0000\n",
            "Epoch 311/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1993.8499 - mae: 1993.8499 - mse: 21836436.0000 - val_loss: 2202.2737 - val_mae: 2202.2737 - val_mse: 24951440.0000\n",
            "Epoch 312/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1999.0214 - mae: 1999.0214 - mse: 22218668.0000 - val_loss: 2065.9990 - val_mae: 2065.9990 - val_mse: 23356316.0000\n",
            "Epoch 313/1000\n",
            "27/27 [==============================] - ETA: 0s - loss: 1961.9335 - mae: 1961.9335 - mse: 21862060.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 53ms/step - loss: 1961.9335 - mae: 1961.9335 - mse: 21862060.0000 - val_loss: 1905.2783 - val_mae: 1905.2783 - val_mse: 21564464.0000\n",
            "Epoch 314/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1945.9459 - mae: 1945.9459 - mse: 21933066.0000 - val_loss: 2106.4973 - val_mae: 2106.4973 - val_mse: 21008678.0000\n",
            "Epoch 315/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1944.3899 - mae: 1944.3899 - mse: 21578358.0000 - val_loss: 2225.0298 - val_mae: 2225.0298 - val_mse: 22428158.0000\n",
            "Epoch 316/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1955.9495 - mae: 1955.9495 - mse: 21666878.0000 - val_loss: 2003.1707 - val_mae: 2003.1707 - val_mse: 21394300.0000\n",
            "Epoch 317/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1986.4861 - mae: 1986.4861 - mse: 22214380.0000 - val_loss: 2021.6791 - val_mae: 2021.6791 - val_mse: 21745928.0000\n",
            "Epoch 318/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1982.6046 - mae: 1982.6046 - mse: 22048028.0000 - val_loss: 2045.2017 - val_mae: 2045.2017 - val_mse: 20810662.0000\n",
            "Epoch 319/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1948.9735 - mae: 1948.9735 - mse: 21692338.0000 - val_loss: 1962.5222 - val_mae: 1962.5222 - val_mse: 21628330.0000\n",
            "Epoch 320/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1954.1560 - mae: 1954.1560 - mse: 21887260.0000 - val_loss: 2241.2532 - val_mae: 2241.2532 - val_mse: 21810940.0000\n",
            "Epoch 321/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1997.1281 - mae: 1997.1281 - mse: 22120102.0000 - val_loss: 2202.2378 - val_mae: 2202.2378 - val_mse: 20959700.0000\n",
            "Epoch 322/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1947.7574 - mae: 1947.7574 - mse: 21620018.0000 - val_loss: 2112.0317 - val_mae: 2112.0317 - val_mse: 20800036.0000\n",
            "Epoch 323/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1958.9940 - mae: 1958.9940 - mse: 21874288.0000 - val_loss: 1923.9634 - val_mae: 1923.9633 - val_mse: 21413022.0000\n",
            "Epoch 324/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1975.5360 - mae: 1975.5360 - mse: 22049656.0000 - val_loss: 2065.4834 - val_mae: 2065.4834 - val_mse: 20607808.0000\n",
            "Epoch 325/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1971.7512 - mae: 1971.7512 - mse: 21808346.0000 - val_loss: 2111.4055 - val_mae: 2111.4055 - val_mse: 20584348.0000\n",
            "Epoch 326/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1971.5907 - mae: 1971.5907 - mse: 22053366.0000 - val_loss: 1930.9204 - val_mae: 1930.9204 - val_mse: 21247684.0000\n",
            "Epoch 327/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1923.6113 - mae: 1923.6113 - mse: 21637234.0000 - val_loss: 1984.2817 - val_mae: 1984.2817 - val_mse: 22696256.0000\n",
            "Epoch 328/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1983.0952 - mae: 1983.0952 - mse: 22187718.0000 - val_loss: 2290.6926 - val_mae: 2290.6926 - val_mse: 24267438.0000\n",
            "Epoch 329/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1951.6168 - mae: 1951.6168 - mse: 21671614.0000 - val_loss: 2239.3403 - val_mae: 2239.3403 - val_mse: 21686374.0000\n",
            "Epoch 330/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1960.7078 - mae: 1960.7078 - mse: 21945432.0000 - val_loss: 2357.7261 - val_mae: 2357.7261 - val_mse: 22234950.0000\n",
            "Epoch 331/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1953.3658 - mae: 1953.3658 - mse: 21408514.0000 - val_loss: 1965.1621 - val_mae: 1965.1621 - val_mse: 21059364.0000\n",
            "Epoch 332/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1955.6780 - mae: 1955.6780 - mse: 21830416.0000 - val_loss: 2035.7766 - val_mae: 2035.7766 - val_mse: 22369010.0000\n",
            "Epoch 333/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1950.2784 - mae: 1950.2784 - mse: 21958006.0000 - val_loss: 1947.3531 - val_mae: 1947.3531 - val_mse: 22317762.0000\n",
            "Epoch 334/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1965.6022 - mae: 1965.6022 - mse: 21893718.0000 - val_loss: 1991.1013 - val_mae: 1991.1013 - val_mse: 21813678.0000\n",
            "Epoch 335/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1961.9047 - mae: 1961.9047 - mse: 21646344.0000 - val_loss: 2025.7039 - val_mae: 2025.7039 - val_mse: 22201122.0000\n",
            "Epoch 336/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1963.1310 - mae: 1963.1310 - mse: 22000504.0000 - val_loss: 1916.2395 - val_mae: 1916.2395 - val_mse: 20963046.0000\n",
            "Epoch 337/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1960.6433 - mae: 1960.6433 - mse: 21840632.0000 - val_loss: 1928.4235 - val_mae: 1928.4235 - val_mse: 21667726.0000\n",
            "Epoch 338/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1924.5768 - mae: 1924.5768 - mse: 21832248.0000 - val_loss: 2155.9883 - val_mae: 2155.9883 - val_mse: 20679022.0000\n",
            "Epoch 339/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1970.3839 - mae: 1970.3839 - mse: 21748448.0000 - val_loss: 1941.0935 - val_mae: 1941.0935 - val_mse: 21789444.0000\n",
            "Epoch 340/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1954.1190 - mae: 1954.1190 - mse: 22006432.0000 - val_loss: 1959.5693 - val_mae: 1959.5693 - val_mse: 22641434.0000\n",
            "Epoch 341/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1921.8527 - mae: 1921.8527 - mse: 21786638.0000 - val_loss: 2006.0906 - val_mae: 2006.0906 - val_mse: 22378346.0000\n",
            "Epoch 342/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1962.7726 - mae: 1962.7726 - mse: 21817672.0000 - val_loss: 1934.8531 - val_mae: 1934.8531 - val_mse: 20628546.0000\n",
            "Epoch 343/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1946.1018 - mae: 1946.1018 - mse: 21445486.0000 - val_loss: 1959.2164 - val_mae: 1959.2163 - val_mse: 21283780.0000\n",
            "Epoch 344/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1971.0430 - mae: 1971.0430 - mse: 22283506.0000 - val_loss: 1927.6934 - val_mae: 1927.6934 - val_mse: 21216684.0000\n",
            "Epoch 345/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1955.8582 - mae: 1955.8582 - mse: 21992536.0000 - val_loss: 2104.1780 - val_mae: 2104.1780 - val_mse: 20822882.0000\n",
            "Epoch 346/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1973.9666 - mae: 1973.9666 - mse: 21773118.0000 - val_loss: 2311.2385 - val_mae: 2311.2385 - val_mse: 24026084.0000\n",
            "Epoch 347/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1943.8893 - mae: 1943.8893 - mse: 21790516.0000 - val_loss: 2107.2446 - val_mae: 2107.2446 - val_mse: 20940750.0000\n",
            "Epoch 348/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1956.3831 - mae: 1956.3831 - mse: 21759246.0000 - val_loss: 2161.3618 - val_mae: 2161.3618 - val_mse: 24204930.0000\n",
            "Epoch 349/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1944.4868 - mae: 1944.4868 - mse: 21907442.0000 - val_loss: 1932.8840 - val_mae: 1932.8840 - val_mse: 20861066.0000\n",
            "Epoch 350/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1951.6077 - mae: 1951.6077 - mse: 21928446.0000 - val_loss: 2235.8425 - val_mae: 2235.8425 - val_mse: 22685134.0000\n",
            "Epoch 351/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2016.4521 - mae: 2016.4521 - mse: 22244820.0000 - val_loss: 2074.1060 - val_mae: 2074.1060 - val_mse: 21724296.0000\n",
            "Epoch 352/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1926.4169 - mae: 1926.4169 - mse: 21614994.0000 - val_loss: 1972.5460 - val_mae: 1972.5460 - val_mse: 22016718.0000\n",
            "Epoch 353/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1932.1086 - mae: 1932.1086 - mse: 21663614.0000 - val_loss: 2199.3455 - val_mae: 2199.3455 - val_mse: 24093006.0000\n",
            "Epoch 354/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1931.2498 - mae: 1931.2498 - mse: 21831022.0000 - val_loss: 1983.8721 - val_mae: 1983.8721 - val_mse: 21080456.0000\n",
            "Epoch 355/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1943.5653 - mae: 1943.5653 - mse: 21733144.0000 - val_loss: 1911.9323 - val_mae: 1911.9323 - val_mse: 21023438.0000\n",
            "Epoch 356/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1921.6049 - mae: 1921.6049 - mse: 21463332.0000 - val_loss: 2310.5913 - val_mae: 2310.5913 - val_mse: 22096584.0000\n",
            "Epoch 357/1000\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1968.3646 - mae: 1968.3646 - mse: 22265340.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 62ms/step - loss: 1951.9360 - mae: 1951.9360 - mse: 21790460.0000 - val_loss: 1868.9700 - val_mae: 1868.9700 - val_mse: 21195728.0000\n",
            "Epoch 358/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1911.1650 - mae: 1911.1650 - mse: 21511232.0000 - val_loss: 1953.7930 - val_mae: 1953.7930 - val_mse: 21800166.0000\n",
            "Epoch 359/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1979.8748 - mae: 1979.8748 - mse: 21959380.0000 - val_loss: 2104.7212 - val_mae: 2104.7212 - val_mse: 22537712.0000\n",
            "Epoch 360/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1912.2722 - mae: 1912.2722 - mse: 21439716.0000 - val_loss: 2121.9451 - val_mae: 2121.9451 - val_mse: 21385354.0000\n",
            "Epoch 361/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1961.8447 - mae: 1961.8447 - mse: 21747476.0000 - val_loss: 1976.2030 - val_mae: 1976.2030 - val_mse: 20873346.0000\n",
            "Epoch 362/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1934.9491 - mae: 1934.9491 - mse: 21766142.0000 - val_loss: 1930.7737 - val_mae: 1930.7737 - val_mse: 20921132.0000\n",
            "Epoch 363/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1943.3817 - mae: 1943.3817 - mse: 21998412.0000 - val_loss: 2126.3440 - val_mae: 2126.3440 - val_mse: 20408550.0000\n",
            "Epoch 364/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1962.6935 - mae: 1962.6935 - mse: 21739724.0000 - val_loss: 1988.6558 - val_mae: 1988.6558 - val_mse: 22751956.0000\n",
            "Epoch 365/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1929.6992 - mae: 1929.6992 - mse: 21514058.0000 - val_loss: 2053.3269 - val_mae: 2053.3269 - val_mse: 20652728.0000\n",
            "Epoch 366/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1958.0551 - mae: 1958.0551 - mse: 21853752.0000 - val_loss: 1957.6714 - val_mae: 1957.6716 - val_mse: 20508082.0000\n",
            "Epoch 367/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1940.0760 - mae: 1940.0760 - mse: 21756498.0000 - val_loss: 2095.1907 - val_mae: 2095.1907 - val_mse: 22175772.0000\n",
            "Epoch 368/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1962.0637 - mae: 1962.0637 - mse: 22063770.0000 - val_loss: 1966.3656 - val_mae: 1966.3656 - val_mse: 21366908.0000\n",
            "Epoch 369/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1929.7043 - mae: 1929.7043 - mse: 21487920.0000 - val_loss: 1873.1005 - val_mae: 1873.1005 - val_mse: 21279820.0000\n",
            "Epoch 370/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1930.1394 - mae: 1930.1394 - mse: 21600732.0000 - val_loss: 2038.8817 - val_mae: 2038.8817 - val_mse: 21366526.0000\n",
            "Epoch 371/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1972.0734 - mae: 1972.0734 - mse: 21836966.0000 - val_loss: 1917.5511 - val_mae: 1917.5511 - val_mse: 21307736.0000\n",
            "Epoch 372/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1970.1326 - mae: 1970.1326 - mse: 22251752.0000 - val_loss: 1999.9712 - val_mae: 1999.9712 - val_mse: 21730296.0000\n",
            "Epoch 373/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1931.1390 - mae: 1931.1390 - mse: 21643608.0000 - val_loss: 2022.9281 - val_mae: 2022.9281 - val_mse: 21619262.0000\n",
            "Epoch 374/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1926.1844 - mae: 1926.1844 - mse: 21678578.0000 - val_loss: 1949.7997 - val_mae: 1949.7997 - val_mse: 21757098.0000\n",
            "Epoch 375/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1909.7395 - mae: 1909.7395 - mse: 21238804.0000 - val_loss: 2354.3406 - val_mae: 2354.3406 - val_mse: 22155364.0000\n",
            "Epoch 376/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1940.5907 - mae: 1940.5907 - mse: 21832336.0000 - val_loss: 1983.7097 - val_mae: 1983.7097 - val_mse: 20291364.0000\n",
            "Epoch 377/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1891.8521 - mae: 1891.8521 - mse: 21696020.0000 - val_loss: 1966.0322 - val_mae: 1966.0322 - val_mse: 20402744.0000\n",
            "Epoch 378/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1962.3528 - mae: 1962.3528 - mse: 21890244.0000 - val_loss: 1896.5209 - val_mae: 1896.5209 - val_mse: 22005980.0000\n",
            "Epoch 379/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1899.1256 - mae: 1899.1256 - mse: 21221148.0000 - val_loss: 2114.4319 - val_mae: 2114.4319 - val_mse: 22076576.0000\n",
            "Epoch 380/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1958.6862 - mae: 1958.6862 - mse: 21680474.0000 - val_loss: 2013.4746 - val_mae: 2013.4746 - val_mse: 21554210.0000\n",
            "Epoch 381/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1948.8058 - mae: 1948.8058 - mse: 21968068.0000 - val_loss: 1993.7500 - val_mae: 1993.7500 - val_mse: 21015760.0000\n",
            "Epoch 382/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1949.8728 - mae: 1949.8728 - mse: 21719300.0000 - val_loss: 2198.5393 - val_mae: 2198.5393 - val_mse: 20491750.0000\n",
            "Epoch 383/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1918.1338 - mae: 1918.1338 - mse: 21752384.0000 - val_loss: 2049.3755 - val_mae: 2049.3755 - val_mse: 21465908.0000\n",
            "Epoch 384/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1923.3877 - mae: 1923.3877 - mse: 21245174.0000 - val_loss: 2023.9692 - val_mae: 2023.9692 - val_mse: 20391696.0000\n",
            "Epoch 385/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1942.3406 - mae: 1942.3406 - mse: 21695296.0000 - val_loss: 1926.5909 - val_mae: 1926.5909 - val_mse: 20497980.0000\n",
            "Epoch 386/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1959.4399 - mae: 1959.4399 - mse: 21779076.0000 - val_loss: 1937.0171 - val_mae: 1937.0171 - val_mse: 21048426.0000\n",
            "Epoch 387/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1934.4633 - mae: 1934.4633 - mse: 21725114.0000 - val_loss: 2194.5730 - val_mae: 2194.5730 - val_mse: 24788158.0000\n",
            "Epoch 388/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1896.8073 - mae: 1896.8073 - mse: 21340498.0000 - val_loss: 1940.0081 - val_mae: 1940.0081 - val_mse: 20718394.0000\n",
            "Epoch 389/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1943.7784 - mae: 1943.7784 - mse: 21555436.0000 - val_loss: 1963.0590 - val_mae: 1963.0590 - val_mse: 20747274.0000\n",
            "Epoch 390/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1936.5200 - mae: 1936.5200 - mse: 21962542.0000 - val_loss: 1984.8156 - val_mae: 1984.8156 - val_mse: 20763366.0000\n",
            "Epoch 391/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1903.9519 - mae: 1903.9519 - mse: 21457140.0000 - val_loss: 2073.7041 - val_mae: 2073.7041 - val_mse: 23185338.0000\n",
            "Epoch 392/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1957.5317 - mae: 1957.5317 - mse: 21801574.0000 - val_loss: 2023.4247 - val_mae: 2023.4247 - val_mse: 20835512.0000\n",
            "Epoch 393/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1902.4001 - mae: 1902.4001 - mse: 21449024.0000 - val_loss: 2341.1238 - val_mae: 2341.1238 - val_mse: 22662206.0000\n",
            "Epoch 394/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1932.8436 - mae: 1932.8436 - mse: 21668068.0000 - val_loss: 1928.4753 - val_mae: 1928.4753 - val_mse: 20293426.0000\n",
            "Epoch 395/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1973.4728 - mae: 1973.4728 - mse: 22058376.0000 - val_loss: 1945.8295 - val_mae: 1945.8295 - val_mse: 21111708.0000\n",
            "Epoch 396/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1954.1007 - mae: 1954.1007 - mse: 21844956.0000 - val_loss: 2160.8970 - val_mae: 2160.8970 - val_mse: 20719578.0000\n",
            "Epoch 397/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1903.1349 - mae: 1903.1349 - mse: 21505436.0000 - val_loss: 1904.0021 - val_mae: 1904.0021 - val_mse: 20846304.0000\n",
            "Epoch 398/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1934.2938 - mae: 1934.2938 - mse: 21851030.0000 - val_loss: 2079.3826 - val_mae: 2079.3826 - val_mse: 22735190.0000\n",
            "Epoch 399/1000\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1950.5724 - mae: 1950.5724 - mse: 22164926.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 53ms/step - loss: 1939.9810 - mae: 1939.9810 - mse: 21965492.0000 - val_loss: 1840.9930 - val_mae: 1840.9930 - val_mse: 20551574.0000\n",
            "Epoch 400/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1939.7678 - mae: 1939.7678 - mse: 22074302.0000 - val_loss: 1877.8698 - val_mae: 1877.8698 - val_mse: 20636736.0000\n",
            "Epoch 401/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1928.8365 - mae: 1928.8365 - mse: 21445206.0000 - val_loss: 2137.6846 - val_mae: 2137.6846 - val_mse: 22296856.0000\n",
            "Epoch 402/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1955.9181 - mae: 1955.9181 - mse: 22037868.0000 - val_loss: 2091.1218 - val_mae: 2091.1218 - val_mse: 21921646.0000\n",
            "Epoch 403/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1911.4708 - mae: 1911.4708 - mse: 21470316.0000 - val_loss: 1856.2579 - val_mae: 1856.2579 - val_mse: 20921574.0000\n",
            "Epoch 404/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1930.0500 - mae: 1930.0500 - mse: 21976566.0000 - val_loss: 1865.8187 - val_mae: 1865.8187 - val_mse: 20521644.0000\n",
            "Epoch 405/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1922.2693 - mae: 1922.2693 - mse: 21612810.0000 - val_loss: 2004.1259 - val_mae: 2004.1259 - val_mse: 21419602.0000\n",
            "Epoch 406/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1918.1735 - mae: 1918.1735 - mse: 21522598.0000 - val_loss: 1896.4995 - val_mae: 1896.4995 - val_mse: 21569838.0000\n",
            "Epoch 407/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1927.5352 - mae: 1927.5352 - mse: 21416816.0000 - val_loss: 1929.5168 - val_mae: 1929.5168 - val_mse: 21254440.0000\n",
            "Epoch 408/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1901.2830 - mae: 1901.2830 - mse: 21496646.0000 - val_loss: 2169.9976 - val_mae: 2169.9976 - val_mse: 24211256.0000\n",
            "Epoch 409/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1943.1176 - mae: 1943.1176 - mse: 21879908.0000 - val_loss: 2290.7539 - val_mae: 2290.7542 - val_mse: 20694488.0000\n",
            "Epoch 410/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1933.4187 - mae: 1933.4187 - mse: 21873522.0000 - val_loss: 2015.0587 - val_mae: 2015.0587 - val_mse: 21355638.0000\n",
            "Epoch 411/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1943.4176 - mae: 1943.4176 - mse: 21772642.0000 - val_loss: 1927.2684 - val_mae: 1927.2684 - val_mse: 22038186.0000\n",
            "Epoch 412/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1902.7992 - mae: 1902.7992 - mse: 21286640.0000 - val_loss: 1915.7371 - val_mae: 1915.7371 - val_mse: 20461268.0000\n",
            "Epoch 413/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1928.6694 - mae: 1928.6694 - mse: 21618854.0000 - val_loss: 1954.7349 - val_mae: 1954.7349 - val_mse: 20888294.0000\n",
            "Epoch 414/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1918.6558 - mae: 1918.6558 - mse: 21510812.0000 - val_loss: 1961.5143 - val_mae: 1961.5143 - val_mse: 21027518.0000\n",
            "Epoch 415/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1922.3339 - mae: 1922.3339 - mse: 21597560.0000 - val_loss: 1944.0566 - val_mae: 1944.0566 - val_mse: 20418704.0000\n",
            "Epoch 416/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1910.8616 - mae: 1910.8616 - mse: 21595656.0000 - val_loss: 1873.9054 - val_mae: 1873.9054 - val_mse: 20682154.0000\n",
            "Epoch 417/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1927.5171 - mae: 1927.5171 - mse: 21621624.0000 - val_loss: 2402.6204 - val_mae: 2402.6204 - val_mse: 23877190.0000\n",
            "Epoch 418/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1885.5887 - mae: 1885.5887 - mse: 21222466.0000 - val_loss: 1992.6500 - val_mae: 1992.6500 - val_mse: 21918346.0000\n",
            "Epoch 419/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1941.1907 - mae: 1941.1907 - mse: 21597444.0000 - val_loss: 1865.5088 - val_mae: 1865.5088 - val_mse: 21330322.0000\n",
            "Epoch 420/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1905.9331 - mae: 1905.9331 - mse: 21367646.0000 - val_loss: 1923.5446 - val_mae: 1923.5446 - val_mse: 21764746.0000\n",
            "Epoch 421/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1926.8132 - mae: 1926.8132 - mse: 21726778.0000 - val_loss: 1978.4856 - val_mae: 1978.4856 - val_mse: 20250030.0000\n",
            "Epoch 422/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1930.0990 - mae: 1930.0990 - mse: 21939216.0000 - val_loss: 2001.2430 - val_mae: 2001.2430 - val_mse: 20761230.0000\n",
            "Epoch 423/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1874.6136 - mae: 1874.6136 - mse: 21341026.0000 - val_loss: 2000.4921 - val_mae: 2000.4921 - val_mse: 23254738.0000\n",
            "Epoch 424/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1903.5968 - mae: 1903.5968 - mse: 21270238.0000 - val_loss: 2010.7968 - val_mae: 2010.7968 - val_mse: 21062804.0000\n",
            "Epoch 425/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1959.0430 - mae: 1959.0430 - mse: 21481608.0000 - val_loss: 2015.5743 - val_mae: 2015.5743 - val_mse: 20222588.0000\n",
            "Epoch 426/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1926.2401 - mae: 1926.2401 - mse: 21696772.0000 - val_loss: 1906.6244 - val_mae: 1906.6244 - val_mse: 21860410.0000\n",
            "Epoch 427/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1913.3779 - mae: 1913.3779 - mse: 21632820.0000 - val_loss: 1858.5142 - val_mae: 1858.5142 - val_mse: 20532592.0000\n",
            "Epoch 428/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1944.8936 - mae: 1944.8936 - mse: 21669526.0000 - val_loss: 1946.3651 - val_mae: 1946.3651 - val_mse: 21542432.0000\n",
            "Epoch 429/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1893.0929 - mae: 1893.0929 - mse: 21301650.0000 - val_loss: 1870.3153 - val_mae: 1870.3153 - val_mse: 20995622.0000\n",
            "Epoch 430/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1928.2594 - mae: 1928.2594 - mse: 21509280.0000 - val_loss: 2007.6996 - val_mae: 2007.6996 - val_mse: 22963516.0000\n",
            "Epoch 431/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1900.3123 - mae: 1900.3123 - mse: 21536656.0000 - val_loss: 2123.6528 - val_mae: 2123.6528 - val_mse: 22343080.0000\n",
            "Epoch 432/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1890.9911 - mae: 1890.9911 - mse: 21243964.0000 - val_loss: 1900.8246 - val_mae: 1900.8246 - val_mse: 20572728.0000\n",
            "Epoch 433/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1937.2747 - mae: 1937.2747 - mse: 21438392.0000 - val_loss: 1915.3252 - val_mae: 1915.3252 - val_mse: 22342476.0000\n",
            "Epoch 434/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1893.8290 - mae: 1893.8290 - mse: 21389346.0000 - val_loss: 1911.5371 - val_mae: 1911.5371 - val_mse: 20334936.0000\n",
            "Epoch 435/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1911.2357 - mae: 1911.2357 - mse: 21821912.0000 - val_loss: 1883.6241 - val_mae: 1883.6241 - val_mse: 21066260.0000\n",
            "Epoch 436/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1899.9004 - mae: 1899.9004 - mse: 21526236.0000 - val_loss: 2074.0557 - val_mae: 2074.0557 - val_mse: 22848066.0000\n",
            "Epoch 437/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1910.9485 - mae: 1910.9485 - mse: 21499090.0000 - val_loss: 1920.5719 - val_mae: 1920.5719 - val_mse: 20787424.0000\n",
            "Epoch 438/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1920.5797 - mae: 1920.5797 - mse: 21424418.0000 - val_loss: 1886.5225 - val_mae: 1886.5225 - val_mse: 20699664.0000\n",
            "Epoch 439/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1873.0122 - mae: 1873.0122 - mse: 21142500.0000 - val_loss: 1985.9993 - val_mae: 1985.9993 - val_mse: 23359110.0000\n",
            "Epoch 440/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1891.5187 - mae: 1891.5187 - mse: 21290496.0000 - val_loss: 2393.6292 - val_mae: 2393.6292 - val_mse: 23518236.0000\n",
            "Epoch 441/1000\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1911.4663 - mae: 1911.4663 - mse: 21681390.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 1922.7887 - mae: 1922.7887 - mse: 21753662.0000 - val_loss: 1835.5364 - val_mae: 1835.5364 - val_mse: 20791516.0000\n",
            "Epoch 442/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1861.5635 - mae: 1861.5635 - mse: 21289956.0000 - val_loss: 1985.2880 - val_mae: 1985.2880 - val_mse: 21024192.0000\n",
            "Epoch 443/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1902.3641 - mae: 1902.3641 - mse: 21713754.0000 - val_loss: 2219.3643 - val_mae: 2219.3643 - val_mse: 20407148.0000\n",
            "Epoch 444/1000\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1800.2856 - mae: 1800.2856 - mse: 20243890.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 1884.4270 - mae: 1884.4270 - mse: 21408118.0000 - val_loss: 1830.3988 - val_mae: 1830.3988 - val_mse: 20735032.0000\n",
            "Epoch 445/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1905.0154 - mae: 1905.0154 - mse: 21549378.0000 - val_loss: 2052.6416 - val_mae: 2052.6416 - val_mse: 21660346.0000\n",
            "Epoch 446/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1925.3887 - mae: 1925.3887 - mse: 21510878.0000 - val_loss: 2012.6592 - val_mae: 2012.6592 - val_mse: 21957408.0000\n",
            "Epoch 447/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1884.5531 - mae: 1884.5531 - mse: 21221580.0000 - val_loss: 1830.4954 - val_mae: 1830.4954 - val_mse: 20501272.0000\n",
            "Epoch 448/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1907.2465 - mae: 1907.2465 - mse: 21326942.0000 - val_loss: 1900.6733 - val_mae: 1900.6733 - val_mse: 20318352.0000\n",
            "Epoch 449/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1907.3817 - mae: 1907.3817 - mse: 21308894.0000 - val_loss: 2084.2542 - val_mae: 2084.2542 - val_mse: 21849000.0000\n",
            "Epoch 450/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1890.8483 - mae: 1890.8483 - mse: 21169386.0000 - val_loss: 2045.7579 - val_mae: 2045.7579 - val_mse: 20494410.0000\n",
            "Epoch 451/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1938.3383 - mae: 1938.3383 - mse: 21131942.0000 - val_loss: 1855.7811 - val_mae: 1855.7811 - val_mse: 20861912.0000\n",
            "Epoch 452/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1909.4926 - mae: 1909.4926 - mse: 21499744.0000 - val_loss: 1878.1615 - val_mae: 1878.1615 - val_mse: 20466306.0000\n",
            "Epoch 453/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1895.5529 - mae: 1895.5529 - mse: 21431274.0000 - val_loss: 2111.7600 - val_mae: 2111.7600 - val_mse: 24184976.0000\n",
            "Epoch 454/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1918.6832 - mae: 1918.6832 - mse: 21514932.0000 - val_loss: 1974.6189 - val_mae: 1974.6189 - val_mse: 21479452.0000\n",
            "Epoch 455/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1909.7620 - mae: 1909.7620 - mse: 21344138.0000 - val_loss: 2186.3552 - val_mae: 2186.3552 - val_mse: 24169596.0000\n",
            "Epoch 456/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1942.5181 - mae: 1942.5181 - mse: 22158994.0000 - val_loss: 1932.2657 - val_mae: 1932.2657 - val_mse: 20321918.0000\n",
            "Epoch 457/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1887.0426 - mae: 1887.0426 - mse: 21323230.0000 - val_loss: 1961.9905 - val_mae: 1961.9905 - val_mse: 21092116.0000\n",
            "Epoch 458/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1882.7568 - mae: 1882.7568 - mse: 21315780.0000 - val_loss: 2028.2324 - val_mae: 2028.2324 - val_mse: 22280438.0000\n",
            "Epoch 459/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1909.7937 - mae: 1909.7937 - mse: 21932616.0000 - val_loss: 1895.3610 - val_mae: 1895.3610 - val_mse: 20679794.0000\n",
            "Epoch 460/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1915.3517 - mae: 1915.3517 - mse: 21650110.0000 - val_loss: 2071.5095 - val_mae: 2071.5095 - val_mse: 21848928.0000\n",
            "Epoch 461/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1881.2211 - mae: 1881.2211 - mse: 21393104.0000 - val_loss: 1966.4734 - val_mae: 1966.4734 - val_mse: 21015542.0000\n",
            "Epoch 462/1000\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1896.9735 - mae: 1896.9735 - mse: 21249550.0000 - val_loss: 2256.2119 - val_mae: 2256.2119 - val_mse: 24379050.0000\n",
            "Epoch 463/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1906.9070 - mae: 1906.9070 - mse: 21448504.0000 - val_loss: 1850.4965 - val_mae: 1850.4965 - val_mse: 20743090.0000\n",
            "Epoch 464/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1879.3411 - mae: 1879.3411 - mse: 21325890.0000 - val_loss: 2096.2200 - val_mae: 2096.2200 - val_mse: 20752762.0000\n",
            "Epoch 465/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1901.8378 - mae: 1901.8378 - mse: 21178256.0000 - val_loss: 2299.8198 - val_mae: 2299.8198 - val_mse: 21719294.0000\n",
            "Epoch 466/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1902.8326 - mae: 1902.8326 - mse: 21418852.0000 - val_loss: 2110.5730 - val_mae: 2110.5730 - val_mse: 20017594.0000\n",
            "Epoch 467/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1888.1755 - mae: 1888.1755 - mse: 21322874.0000 - val_loss: 1901.6476 - val_mae: 1901.6476 - val_mse: 21893060.0000\n",
            "Epoch 468/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1907.8660 - mae: 1907.8660 - mse: 21546128.0000 - val_loss: 1903.7747 - val_mae: 1903.7747 - val_mse: 21075410.0000\n",
            "Epoch 469/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1886.7921 - mae: 1886.7921 - mse: 21076354.0000 - val_loss: 2000.4901 - val_mae: 2000.4901 - val_mse: 20452782.0000\n",
            "Epoch 470/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1908.4874 - mae: 1908.4874 - mse: 21686162.0000 - val_loss: 1873.2708 - val_mae: 1873.2708 - val_mse: 20811068.0000\n",
            "Epoch 471/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1899.6772 - mae: 1899.6772 - mse: 21266992.0000 - val_loss: 2174.7432 - val_mae: 2174.7432 - val_mse: 22429560.0000\n",
            "Epoch 472/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1882.4060 - mae: 1882.4060 - mse: 21431608.0000 - val_loss: 1836.0392 - val_mae: 1836.0392 - val_mse: 20570218.0000\n",
            "Epoch 473/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1903.8422 - mae: 1903.8422 - mse: 21404026.0000 - val_loss: 2026.0809 - val_mae: 2026.0809 - val_mse: 20489288.0000\n",
            "Epoch 474/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1872.7263 - mae: 1872.7263 - mse: 21379040.0000 - val_loss: 1940.4336 - val_mae: 1940.4336 - val_mse: 20805630.0000\n",
            "Epoch 475/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1930.8976 - mae: 1930.8976 - mse: 21534808.0000 - val_loss: 1978.9280 - val_mae: 1978.9280 - val_mse: 21864000.0000\n",
            "Epoch 476/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1884.2189 - mae: 1884.2189 - mse: 21365276.0000 - val_loss: 1956.6149 - val_mae: 1956.6149 - val_mse: 20789294.0000\n",
            "Epoch 477/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1892.9954 - mae: 1892.9954 - mse: 21352404.0000 - val_loss: 2163.7505 - val_mae: 2163.7505 - val_mse: 20341738.0000\n",
            "Epoch 478/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1912.1412 - mae: 1912.1412 - mse: 21544228.0000 - val_loss: 1945.6862 - val_mae: 1945.6862 - val_mse: 20736690.0000\n",
            "Epoch 479/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1895.9714 - mae: 1895.9714 - mse: 21760208.0000 - val_loss: 2515.3398 - val_mae: 2515.3398 - val_mse: 22932042.0000\n",
            "Epoch 480/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1914.0834 - mae: 1914.0834 - mse: 21552066.0000 - val_loss: 1897.4197 - val_mae: 1897.4197 - val_mse: 21015586.0000\n",
            "Epoch 481/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1891.4404 - mae: 1891.4404 - mse: 21281720.0000 - val_loss: 2200.1533 - val_mae: 2200.1533 - val_mse: 21328446.0000\n",
            "Epoch 482/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1917.0902 - mae: 1917.0902 - mse: 21323700.0000 - val_loss: 1839.9730 - val_mae: 1839.9730 - val_mse: 20300254.0000\n",
            "Epoch 483/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1864.4390 - mae: 1864.4390 - mse: 21407310.0000 - val_loss: 1855.6539 - val_mae: 1855.6539 - val_mse: 20387318.0000\n",
            "Epoch 484/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1903.9329 - mae: 1903.9329 - mse: 21449282.0000 - val_loss: 1834.8123 - val_mae: 1834.8123 - val_mse: 20931320.0000\n",
            "Epoch 485/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1876.7321 - mae: 1876.7321 - mse: 21046904.0000 - val_loss: 1918.5074 - val_mae: 1918.5074 - val_mse: 20816470.0000\n",
            "Epoch 486/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1897.1689 - mae: 1897.1689 - mse: 21397806.0000 - val_loss: 1914.2589 - val_mae: 1914.2589 - val_mse: 20101690.0000\n",
            "Epoch 487/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1866.5946 - mae: 1866.5946 - mse: 21191118.0000 - val_loss: 1913.2928 - val_mae: 1913.2928 - val_mse: 22171164.0000\n",
            "Epoch 488/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1908.3707 - mae: 1908.3707 - mse: 21376078.0000 - val_loss: 1846.6188 - val_mae: 1846.6188 - val_mse: 20677044.0000\n",
            "Epoch 489/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1885.0663 - mae: 1885.0663 - mse: 21308888.0000 - val_loss: 2226.8853 - val_mae: 2226.8853 - val_mse: 21016918.0000\n",
            "Epoch 490/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1889.5344 - mae: 1889.5344 - mse: 21109012.0000 - val_loss: 1928.1920 - val_mae: 1928.1920 - val_mse: 20228380.0000\n",
            "Epoch 491/1000\n",
            "27/27 [==============================] - ETA: 0s - loss: 1886.9093 - mae: 1886.9093 - mse: 21155840.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 53ms/step - loss: 1886.9093 - mae: 1886.9093 - mse: 21155840.0000 - val_loss: 1826.7605 - val_mae: 1826.7605 - val_mse: 20536784.0000\n",
            "Epoch 492/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1863.2328 - mae: 1863.2328 - mse: 21105300.0000 - val_loss: 2188.8396 - val_mae: 2188.8396 - val_mse: 25069286.0000\n",
            "Epoch 493/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1917.1168 - mae: 1917.1168 - mse: 21439990.0000 - val_loss: 2015.1185 - val_mae: 2015.1185 - val_mse: 19982590.0000\n",
            "Epoch 494/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1870.8348 - mae: 1870.8348 - mse: 21130652.0000 - val_loss: 1844.5581 - val_mae: 1844.5581 - val_mse: 20693918.0000\n",
            "Epoch 495/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1882.0385 - mae: 1882.0385 - mse: 21241144.0000 - val_loss: 1895.3368 - val_mae: 1895.3368 - val_mse: 20374640.0000\n",
            "Epoch 496/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1848.4731 - mae: 1848.4731 - mse: 20850856.0000 - val_loss: 2213.5513 - val_mae: 2213.5515 - val_mse: 24460982.0000\n",
            "Epoch 497/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1887.2603 - mae: 1887.2603 - mse: 21335312.0000 - val_loss: 2235.5840 - val_mae: 2235.5840 - val_mse: 20734146.0000\n",
            "Epoch 498/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1903.7662 - mae: 1903.7662 - mse: 21328164.0000 - val_loss: 1864.4313 - val_mae: 1864.4313 - val_mse: 20259546.0000\n",
            "Epoch 499/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1936.4474 - mae: 1936.4474 - mse: 21305786.0000 - val_loss: 2051.4363 - val_mae: 2051.4363 - val_mse: 23314744.0000\n",
            "Epoch 500/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1836.6906 - mae: 1836.6906 - mse: 20774536.0000 - val_loss: 1916.8103 - val_mae: 1916.8103 - val_mse: 21282610.0000\n",
            "Epoch 501/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1905.3091 - mae: 1905.3091 - mse: 21054938.0000 - val_loss: 2357.0803 - val_mae: 2357.0803 - val_mse: 23324090.0000\n",
            "Epoch 502/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1887.5452 - mae: 1887.5452 - mse: 21462728.0000 - val_loss: 2023.2589 - val_mae: 2023.2589 - val_mse: 22428332.0000\n",
            "Epoch 503/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1886.6100 - mae: 1886.6100 - mse: 21329192.0000 - val_loss: 2231.0703 - val_mae: 2231.0703 - val_mse: 21511020.0000\n",
            "Epoch 504/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1900.8680 - mae: 1900.8680 - mse: 21335964.0000 - val_loss: 1951.6498 - val_mae: 1951.6498 - val_mse: 20842842.0000\n",
            "Epoch 505/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1879.8125 - mae: 1879.8125 - mse: 21432172.0000 - val_loss: 1927.5210 - val_mae: 1927.5210 - val_mse: 20869408.0000\n",
            "Epoch 506/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1870.8698 - mae: 1870.8698 - mse: 21087886.0000 - val_loss: 1951.5604 - val_mae: 1951.5604 - val_mse: 21451330.0000\n",
            "Epoch 507/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1885.8104 - mae: 1885.8104 - mse: 21544976.0000 - val_loss: 1927.9789 - val_mae: 1927.9789 - val_mse: 20800426.0000\n",
            "Epoch 508/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1905.9835 - mae: 1905.9835 - mse: 21254118.0000 - val_loss: 1984.8560 - val_mae: 1984.8560 - val_mse: 20142764.0000\n",
            "Epoch 509/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1886.2174 - mae: 1886.2174 - mse: 21363872.0000 - val_loss: 1878.9650 - val_mae: 1878.9650 - val_mse: 21432408.0000\n",
            "Epoch 510/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1925.3636 - mae: 1925.3636 - mse: 21834456.0000 - val_loss: 2165.0059 - val_mae: 2165.0059 - val_mse: 20796698.0000\n",
            "Epoch 511/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1886.0288 - mae: 1886.0288 - mse: 21501960.0000 - val_loss: 2030.7521 - val_mae: 2030.7521 - val_mse: 20401830.0000\n",
            "Epoch 512/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1881.9100 - mae: 1881.9100 - mse: 21350434.0000 - val_loss: 2065.1782 - val_mae: 2065.1782 - val_mse: 20366018.0000\n",
            "Epoch 513/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1874.6825 - mae: 1874.6825 - mse: 21214144.0000 - val_loss: 1861.0305 - val_mae: 1861.0305 - val_mse: 20202900.0000\n",
            "Epoch 514/1000\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1878.1680 - mae: 1878.1680 - mse: 21691594.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 53ms/step - loss: 1923.3705 - mae: 1923.3705 - mse: 21670398.0000 - val_loss: 1806.7306 - val_mae: 1806.7306 - val_mse: 20623800.0000\n",
            "Epoch 515/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1887.0685 - mae: 1887.0685 - mse: 21264906.0000 - val_loss: 2101.7810 - val_mae: 2101.7810 - val_mse: 23041890.0000\n",
            "Epoch 516/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1891.4674 - mae: 1891.4674 - mse: 21324956.0000 - val_loss: 1942.0321 - val_mae: 1942.0321 - val_mse: 20565054.0000\n",
            "Epoch 517/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1889.5834 - mae: 1889.5834 - mse: 21320440.0000 - val_loss: 1910.9551 - val_mae: 1910.9551 - val_mse: 21100176.0000\n",
            "Epoch 518/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1876.2224 - mae: 1876.2224 - mse: 21284424.0000 - val_loss: 1837.2031 - val_mae: 1837.2031 - val_mse: 21398914.0000\n",
            "Epoch 519/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1882.4449 - mae: 1882.4449 - mse: 21298398.0000 - val_loss: 1931.4406 - val_mae: 1931.4406 - val_mse: 20810042.0000\n",
            "Epoch 520/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1867.0635 - mae: 1867.0635 - mse: 21353024.0000 - val_loss: 1949.0292 - val_mae: 1949.0292 - val_mse: 20487800.0000\n",
            "Epoch 521/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1872.2679 - mae: 1872.2679 - mse: 21317532.0000 - val_loss: 1905.3745 - val_mae: 1905.3745 - val_mse: 21270694.0000\n",
            "Epoch 522/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1891.0332 - mae: 1891.0332 - mse: 21243514.0000 - val_loss: 1913.2892 - val_mae: 1913.2892 - val_mse: 20070008.0000\n",
            "Epoch 523/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1842.6608 - mae: 1842.6608 - mse: 20810092.0000 - val_loss: 2117.3149 - val_mae: 2117.3149 - val_mse: 20335054.0000\n",
            "Epoch 524/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1876.4264 - mae: 1876.4264 - mse: 21191712.0000 - val_loss: 2078.2146 - val_mae: 2078.2146 - val_mse: 21378484.0000\n",
            "Epoch 525/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1842.6029 - mae: 1842.6029 - mse: 21205786.0000 - val_loss: 1977.1495 - val_mae: 1977.1494 - val_mse: 19989640.0000\n",
            "Epoch 526/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1874.1116 - mae: 1874.1116 - mse: 21371450.0000 - val_loss: 1824.5972 - val_mae: 1824.5972 - val_mse: 20646364.0000\n",
            "Epoch 527/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1850.7841 - mae: 1850.7841 - mse: 21004324.0000 - val_loss: 1879.3922 - val_mae: 1879.3922 - val_mse: 20388912.0000\n",
            "Epoch 528/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1873.2461 - mae: 1873.2461 - mse: 21062664.0000 - val_loss: 1923.8885 - val_mae: 1923.8885 - val_mse: 20894844.0000\n",
            "Epoch 529/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1911.3558 - mae: 1911.3558 - mse: 21599686.0000 - val_loss: 2126.3496 - val_mae: 2126.3496 - val_mse: 20514874.0000\n",
            "Epoch 530/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1845.1539 - mae: 1845.1539 - mse: 20844150.0000 - val_loss: 2067.6289 - val_mae: 2067.6289 - val_mse: 21669194.0000\n",
            "Epoch 531/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1879.2800 - mae: 1879.2800 - mse: 21284820.0000 - val_loss: 2023.1240 - val_mae: 2023.1240 - val_mse: 20353314.0000\n",
            "Epoch 532/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1884.6560 - mae: 1884.6560 - mse: 21628844.0000 - val_loss: 1915.4293 - val_mae: 1915.4293 - val_mse: 20582342.0000\n",
            "Epoch 533/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1902.6371 - mae: 1902.6371 - mse: 21337824.0000 - val_loss: 1991.7828 - val_mae: 1991.7828 - val_mse: 20852284.0000\n",
            "Epoch 534/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1871.9009 - mae: 1871.9009 - mse: 21443596.0000 - val_loss: 1815.5140 - val_mae: 1815.5140 - val_mse: 20946898.0000\n",
            "Epoch 535/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1869.3770 - mae: 1869.3770 - mse: 21105358.0000 - val_loss: 1888.4685 - val_mae: 1888.4685 - val_mse: 20525024.0000\n",
            "Epoch 536/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1843.6996 - mae: 1843.6996 - mse: 21005374.0000 - val_loss: 1819.8146 - val_mae: 1819.8146 - val_mse: 20726516.0000\n",
            "Epoch 537/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1821.0612 - mae: 1821.0612 - mse: 20779064.0000 - val_loss: 1993.4352 - val_mae: 1993.4352 - val_mse: 20148236.0000\n",
            "Epoch 538/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1860.5508 - mae: 1860.5508 - mse: 20996096.0000 - val_loss: 1964.0908 - val_mae: 1964.0908 - val_mse: 20872894.0000\n",
            "Epoch 539/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1875.0380 - mae: 1875.0380 - mse: 21469064.0000 - val_loss: 1843.4360 - val_mae: 1843.4360 - val_mse: 20835076.0000\n",
            "Epoch 540/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1861.9730 - mae: 1861.9730 - mse: 21090740.0000 - val_loss: 1916.1875 - val_mae: 1916.1875 - val_mse: 22018588.0000\n",
            "Epoch 541/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1897.1523 - mae: 1897.1523 - mse: 21377154.0000 - val_loss: 1864.0497 - val_mae: 1864.0497 - val_mse: 21123118.0000\n",
            "Epoch 542/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1869.6620 - mae: 1869.6620 - mse: 21098102.0000 - val_loss: 1993.9459 - val_mae: 1993.9459 - val_mse: 21134690.0000\n",
            "Epoch 543/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1812.0238 - mae: 1812.0238 - mse: 20700158.0000 - val_loss: 2038.9851 - val_mae: 2038.9851 - val_mse: 21073990.0000\n",
            "Epoch 544/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1856.9440 - mae: 1856.9440 - mse: 21218206.0000 - val_loss: 1983.9108 - val_mae: 1983.9108 - val_mse: 23291952.0000\n",
            "Epoch 545/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1832.3551 - mae: 1832.3551 - mse: 21018328.0000 - val_loss: 1894.2784 - val_mae: 1894.2784 - val_mse: 21814804.0000\n",
            "Epoch 546/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1910.4287 - mae: 1910.4287 - mse: 21521578.0000 - val_loss: 1893.5363 - val_mae: 1893.5363 - val_mse: 21121852.0000\n",
            "Epoch 547/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1849.0884 - mae: 1849.0884 - mse: 21082732.0000 - val_loss: 1875.4867 - val_mae: 1875.4867 - val_mse: 20571936.0000\n",
            "Epoch 548/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1873.8875 - mae: 1873.8875 - mse: 21193322.0000 - val_loss: 1962.5585 - val_mae: 1962.5585 - val_mse: 20860302.0000\n",
            "Epoch 549/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1865.3567 - mae: 1865.3567 - mse: 21190326.0000 - val_loss: 1840.7584 - val_mae: 1840.7584 - val_mse: 20460314.0000\n",
            "Epoch 550/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1875.4332 - mae: 1875.4332 - mse: 21411440.0000 - val_loss: 1945.1300 - val_mae: 1945.1300 - val_mse: 21011248.0000\n",
            "Epoch 551/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1865.3409 - mae: 1865.3409 - mse: 21397568.0000 - val_loss: 1868.0239 - val_mae: 1868.0239 - val_mse: 20482738.0000\n",
            "Epoch 552/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1848.4058 - mae: 1848.4058 - mse: 20895708.0000 - val_loss: 1852.7061 - val_mae: 1852.7061 - val_mse: 20489668.0000\n",
            "Epoch 553/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1888.0353 - mae: 1888.0353 - mse: 21475978.0000 - val_loss: 1911.5292 - val_mae: 1911.5292 - val_mse: 20719502.0000\n",
            "Epoch 554/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1823.6583 - mae: 1823.6583 - mse: 20854382.0000 - val_loss: 1919.7090 - val_mae: 1919.7090 - val_mse: 20042156.0000\n",
            "Epoch 555/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1846.7948 - mae: 1846.7948 - mse: 21184224.0000 - val_loss: 1840.8918 - val_mae: 1840.8918 - val_mse: 20607490.0000\n",
            "Epoch 556/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1869.7588 - mae: 1869.7588 - mse: 21213510.0000 - val_loss: 1999.8640 - val_mae: 1999.8640 - val_mse: 19941020.0000\n",
            "Epoch 557/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1778.3484 - mae: 1778.3484 - mse: 19317842.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 61ms/step - loss: 1870.2399 - mae: 1870.2399 - mse: 21210706.0000 - val_loss: 1802.4082 - val_mae: 1802.4082 - val_mse: 20442102.0000\n",
            "Epoch 558/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1853.2776 - mae: 1853.2776 - mse: 21074532.0000 - val_loss: 1935.2314 - val_mae: 1935.2314 - val_mse: 21305694.0000\n",
            "Epoch 559/1000\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1850.3589 - mae: 1850.3589 - mse: 20549076.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 51ms/step - loss: 1870.4026 - mae: 1870.4026 - mse: 21183688.0000 - val_loss: 1781.8406 - val_mae: 1781.8406 - val_mse: 20252280.0000\n",
            "Epoch 560/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1863.7457 - mae: 1863.7457 - mse: 21355042.0000 - val_loss: 2243.4524 - val_mae: 2243.4524 - val_mse: 21104912.0000\n",
            "Epoch 561/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1872.5990 - mae: 1872.5990 - mse: 21127140.0000 - val_loss: 1895.4083 - val_mae: 1895.4083 - val_mse: 21968396.0000\n",
            "Epoch 562/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1867.5406 - mae: 1867.5406 - mse: 20858134.0000 - val_loss: 1818.1005 - val_mae: 1818.1005 - val_mse: 20730854.0000\n",
            "Epoch 563/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1882.2517 - mae: 1882.2517 - mse: 21043398.0000 - val_loss: 1916.1974 - val_mae: 1916.1974 - val_mse: 20375750.0000\n",
            "Epoch 564/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1843.8987 - mae: 1843.8987 - mse: 21230682.0000 - val_loss: 1812.8378 - val_mae: 1812.8378 - val_mse: 20103014.0000\n",
            "Epoch 565/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1870.9525 - mae: 1870.9525 - mse: 21350168.0000 - val_loss: 2101.3491 - val_mae: 2101.3491 - val_mse: 20074496.0000\n",
            "Epoch 566/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1870.9508 - mae: 1870.9508 - mse: 21218478.0000 - val_loss: 2017.5476 - val_mae: 2017.5476 - val_mse: 20187450.0000\n",
            "Epoch 567/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1898.6505 - mae: 1898.6505 - mse: 21399492.0000 - val_loss: 2038.8485 - val_mae: 2038.8485 - val_mse: 21675706.0000\n",
            "Epoch 568/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1875.5483 - mae: 1875.5483 - mse: 21103084.0000 - val_loss: 1910.6832 - val_mae: 1910.6832 - val_mse: 20999190.0000\n",
            "Epoch 569/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1865.2339 - mae: 1865.2339 - mse: 21048274.0000 - val_loss: 1812.9316 - val_mae: 1812.9316 - val_mse: 20402810.0000\n",
            "Epoch 570/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1833.7098 - mae: 1833.7098 - mse: 20897922.0000 - val_loss: 2154.8269 - val_mae: 2154.8269 - val_mse: 23424196.0000\n",
            "Epoch 571/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1821.4695 - mae: 1821.4695 - mse: 20660552.0000 - val_loss: 1899.2911 - val_mae: 1899.2911 - val_mse: 20187738.0000\n",
            "Epoch 572/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1867.4370 - mae: 1867.4370 - mse: 21141270.0000 - val_loss: 1934.7017 - val_mae: 1934.7017 - val_mse: 20143200.0000\n",
            "Epoch 573/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1838.0259 - mae: 1838.0259 - mse: 21107832.0000 - val_loss: 2097.3833 - val_mae: 2097.3833 - val_mse: 22443044.0000\n",
            "Epoch 574/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1855.8358 - mae: 1855.8358 - mse: 21142368.0000 - val_loss: 1800.1505 - val_mae: 1800.1505 - val_mse: 20507102.0000\n",
            "Epoch 575/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1822.9227 - mae: 1822.9227 - mse: 20489728.0000 - val_loss: 2074.1697 - val_mae: 2074.1697 - val_mse: 20828880.0000\n",
            "Epoch 576/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1849.4203 - mae: 1849.4203 - mse: 21066166.0000 - val_loss: 2137.3042 - val_mae: 2137.3042 - val_mse: 23254496.0000\n",
            "Epoch 577/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1865.7806 - mae: 1865.7806 - mse: 20915168.0000 - val_loss: 2097.2258 - val_mae: 2097.2258 - val_mse: 20934302.0000\n",
            "Epoch 578/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1857.2263 - mae: 1857.2263 - mse: 21299726.0000 - val_loss: 1982.1627 - val_mae: 1982.1627 - val_mse: 20277502.0000\n",
            "Epoch 579/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1861.1791 - mae: 1861.1791 - mse: 21206544.0000 - val_loss: 1989.1831 - val_mae: 1989.1831 - val_mse: 19988808.0000\n",
            "Epoch 580/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1830.6250 - mae: 1830.6250 - mse: 20868060.0000 - val_loss: 1939.2661 - val_mae: 1939.2661 - val_mse: 22100314.0000\n",
            "Epoch 581/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1862.6592 - mae: 1862.6592 - mse: 21334990.0000 - val_loss: 1875.1565 - val_mae: 1875.1565 - val_mse: 20840696.0000\n",
            "Epoch 582/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1847.3741 - mae: 1847.3741 - mse: 21311978.0000 - val_loss: 1871.5649 - val_mae: 1871.5649 - val_mse: 19998050.0000\n",
            "Epoch 583/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1847.8013 - mae: 1847.8013 - mse: 21050116.0000 - val_loss: 2218.5437 - val_mae: 2218.5437 - val_mse: 24000052.0000\n",
            "Epoch 584/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1830.7054 - mae: 1830.7054 - mse: 21062312.0000 - val_loss: 1879.8085 - val_mae: 1879.8085 - val_mse: 20574524.0000\n",
            "Epoch 585/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1842.1915 - mae: 1842.1915 - mse: 20706058.0000 - val_loss: 2033.6315 - val_mae: 2033.6315 - val_mse: 22356034.0000\n",
            "Epoch 586/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1844.1638 - mae: 1844.1638 - mse: 21067396.0000 - val_loss: 1858.2642 - val_mae: 1858.2642 - val_mse: 20480816.0000\n",
            "Epoch 587/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1834.8358 - mae: 1834.8358 - mse: 21053940.0000 - val_loss: 1924.9806 - val_mae: 1924.9806 - val_mse: 20059862.0000\n",
            "Epoch 588/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1826.1362 - mae: 1826.1362 - mse: 20548864.0000 - val_loss: 1817.9031 - val_mae: 1817.9031 - val_mse: 20747732.0000\n",
            "Epoch 589/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1850.3771 - mae: 1850.3771 - mse: 20795490.0000 - val_loss: 1871.2701 - val_mae: 1871.2701 - val_mse: 19894716.0000\n",
            "Epoch 590/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1843.4966 - mae: 1843.4966 - mse: 21248760.0000 - val_loss: 1957.5165 - val_mae: 1957.5165 - val_mse: 21528198.0000\n",
            "Epoch 591/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1862.3567 - mae: 1862.3567 - mse: 21209236.0000 - val_loss: 1813.7126 - val_mae: 1813.7126 - val_mse: 20356384.0000\n",
            "Epoch 592/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1831.4292 - mae: 1831.4292 - mse: 20980830.0000 - val_loss: 1987.5635 - val_mae: 1987.5635 - val_mse: 20857468.0000\n",
            "Epoch 593/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1844.4796 - mae: 1844.4796 - mse: 21085162.0000 - val_loss: 1873.5394 - val_mae: 1873.5394 - val_mse: 20208278.0000\n",
            "Epoch 594/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1858.2673 - mae: 1858.2673 - mse: 21099190.0000 - val_loss: 1800.5321 - val_mae: 1800.5321 - val_mse: 20543842.0000\n",
            "Epoch 595/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1845.6450 - mae: 1845.6450 - mse: 20999888.0000 - val_loss: 1816.0348 - val_mae: 1816.0348 - val_mse: 20639406.0000\n",
            "Epoch 596/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1861.8077 - mae: 1861.8077 - mse: 21215612.0000 - val_loss: 1889.2948 - val_mae: 1889.2948 - val_mse: 20091756.0000\n",
            "Epoch 597/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1830.3997 - mae: 1830.3997 - mse: 20767062.0000 - val_loss: 1840.8102 - val_mae: 1840.8102 - val_mse: 20456438.0000\n",
            "Epoch 598/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1863.8319 - mae: 1863.8319 - mse: 21241078.0000 - val_loss: 2009.6099 - val_mae: 2009.6099 - val_mse: 20050988.0000\n",
            "Epoch 599/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1821.8386 - mae: 1821.8386 - mse: 20892126.0000 - val_loss: 1835.7566 - val_mae: 1835.7566 - val_mse: 19943972.0000\n",
            "Epoch 600/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1862.5262 - mae: 1862.5262 - mse: 21357974.0000 - val_loss: 1809.9723 - val_mae: 1809.9723 - val_mse: 20075164.0000\n",
            "Epoch 601/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1867.7887 - mae: 1867.7887 - mse: 21147408.0000 - val_loss: 1974.5101 - val_mae: 1974.5101 - val_mse: 21582580.0000\n",
            "Epoch 602/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1827.8177 - mae: 1827.8177 - mse: 20754576.0000 - val_loss: 1828.7535 - val_mae: 1828.7535 - val_mse: 20745522.0000\n",
            "Epoch 603/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1861.5933 - mae: 1861.5933 - mse: 21020160.0000 - val_loss: 1872.1747 - val_mae: 1872.1747 - val_mse: 21293302.0000\n",
            "Epoch 604/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1825.5913 - mae: 1825.5913 - mse: 20863734.0000 - val_loss: 1882.0793 - val_mae: 1882.0793 - val_mse: 20032658.0000\n",
            "Epoch 605/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1820.2998 - mae: 1820.2998 - mse: 20888974.0000 - val_loss: 1818.1675 - val_mae: 1818.1675 - val_mse: 20180650.0000\n",
            "Epoch 606/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1812.6720 - mae: 1812.6720 - mse: 20768648.0000 - val_loss: 1880.9905 - val_mae: 1880.9905 - val_mse: 20879894.0000\n",
            "Epoch 607/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1857.6949 - mae: 1857.6949 - mse: 21297884.0000 - val_loss: 1934.1576 - val_mae: 1934.1576 - val_mse: 20247036.0000\n",
            "Epoch 608/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1836.6755 - mae: 1836.6755 - mse: 20637548.0000 - val_loss: 1890.6772 - val_mae: 1890.6772 - val_mse: 22328596.0000\n",
            "Epoch 609/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1820.8599 - mae: 1820.8599 - mse: 20947970.0000 - val_loss: 2044.3993 - val_mae: 2044.3993 - val_mse: 22206700.0000\n",
            "Epoch 610/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1846.0228 - mae: 1846.0228 - mse: 21252850.0000 - val_loss: 2070.8325 - val_mae: 2070.8325 - val_mse: 19766636.0000\n",
            "Epoch 611/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1812.3990 - mae: 1812.3990 - mse: 20715240.0000 - val_loss: 2001.2101 - val_mae: 2001.2101 - val_mse: 19986544.0000\n",
            "Epoch 612/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1820.6656 - mae: 1820.6656 - mse: 20841164.0000 - val_loss: 1850.8629 - val_mae: 1850.8629 - val_mse: 21341196.0000\n",
            "Epoch 613/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1825.8231 - mae: 1825.8231 - mse: 20957926.0000 - val_loss: 1816.5848 - val_mae: 1816.5848 - val_mse: 20010060.0000\n",
            "Epoch 614/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1837.8082 - mae: 1837.8082 - mse: 21075030.0000 - val_loss: 2255.5808 - val_mae: 2255.5808 - val_mse: 20682382.0000\n",
            "Epoch 615/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1816.2701 - mae: 1816.2701 - mse: 20973994.0000 - val_loss: 2103.7927 - val_mae: 2103.7927 - val_mse: 20252062.0000\n",
            "Epoch 616/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1811.8453 - mae: 1811.8453 - mse: 20763682.0000 - val_loss: 1948.5602 - val_mae: 1948.5602 - val_mse: 20743776.0000\n",
            "Epoch 617/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1808.9686 - mae: 1808.9686 - mse: 20653484.0000 - val_loss: 2013.9685 - val_mae: 2013.9685 - val_mse: 21748944.0000\n",
            "Epoch 618/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1832.8344 - mae: 1832.8344 - mse: 21217108.0000 - val_loss: 1833.9214 - val_mae: 1833.9214 - val_mse: 20371160.0000\n",
            "Epoch 619/1000\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1742.8693 - mae: 1742.8693 - mse: 19475466.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 53ms/step - loss: 1825.9878 - mae: 1825.9878 - mse: 20975338.0000 - val_loss: 1767.3044 - val_mae: 1767.3044 - val_mse: 20301658.0000\n",
            "Epoch 620/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1816.7354 - mae: 1816.7354 - mse: 20555228.0000 - val_loss: 1942.4644 - val_mae: 1942.4644 - val_mse: 21664992.0000\n",
            "Epoch 621/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1837.0992 - mae: 1837.0992 - mse: 20996012.0000 - val_loss: 1843.3187 - val_mae: 1843.3187 - val_mse: 21771078.0000\n",
            "Epoch 622/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1817.6980 - mae: 1817.6980 - mse: 20735094.0000 - val_loss: 1870.6884 - val_mae: 1870.6884 - val_mse: 20107236.0000\n",
            "Epoch 623/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1797.9149 - mae: 1797.9149 - mse: 20656458.0000 - val_loss: 1982.8669 - val_mae: 1982.8669 - val_mse: 21790574.0000\n",
            "Epoch 624/1000\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1879.5350 - mae: 1879.5350 - mse: 21639492.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 54ms/step - loss: 1837.4060 - mae: 1837.4060 - mse: 21037674.0000 - val_loss: 1765.5199 - val_mae: 1765.5199 - val_mse: 20283026.0000\n",
            "Epoch 625/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1792.2821 - mae: 1792.2821 - mse: 20461692.0000 - val_loss: 1810.2476 - val_mae: 1810.2476 - val_mse: 20195816.0000\n",
            "Epoch 626/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1805.9316 - mae: 1805.9316 - mse: 20557890.0000 - val_loss: 1944.9004 - val_mae: 1944.9004 - val_mse: 20897380.0000\n",
            "Epoch 627/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1800.9663 - mae: 1800.9663 - mse: 20534348.0000 - val_loss: 1870.5782 - val_mae: 1870.5782 - val_mse: 21782198.0000\n",
            "Epoch 628/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1836.7568 - mae: 1836.7568 - mse: 20710046.0000 - val_loss: 2056.9661 - val_mae: 2056.9661 - val_mse: 21939794.0000\n",
            "Epoch 629/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1824.1213 - mae: 1824.1213 - mse: 20757226.0000 - val_loss: 1801.1687 - val_mae: 1801.1687 - val_mse: 20268602.0000\n",
            "Epoch 630/1000\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1831.0494 - mae: 1831.0494 - mse: 20939502.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 54ms/step - loss: 1835.4991 - mae: 1835.4991 - mse: 20949468.0000 - val_loss: 1761.3433 - val_mae: 1761.3433 - val_mse: 20090880.0000\n",
            "Epoch 631/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1833.0612 - mae: 1833.0612 - mse: 20917042.0000 - val_loss: 1905.3016 - val_mae: 1905.3016 - val_mse: 20834526.0000\n",
            "Epoch 632/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1782.4664 - mae: 1782.4664 - mse: 20750398.0000 - val_loss: 1944.7836 - val_mae: 1944.7836 - val_mse: 19643826.0000\n",
            "Epoch 633/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1838.7788 - mae: 1838.7788 - mse: 21210762.0000 - val_loss: 2176.3723 - val_mae: 2176.3723 - val_mse: 22958728.0000\n",
            "Epoch 634/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1836.7834 - mae: 1836.7834 - mse: 21209556.0000 - val_loss: 1886.4314 - val_mae: 1886.4314 - val_mse: 20319026.0000\n",
            "Epoch 635/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1781.3373 - mae: 1781.3373 - mse: 20585992.0000 - val_loss: 2159.4775 - val_mae: 2159.4775 - val_mse: 23006898.0000\n",
            "Epoch 636/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1816.3864 - mae: 1816.3864 - mse: 20875976.0000 - val_loss: 1967.6454 - val_mae: 1967.6454 - val_mse: 20077192.0000\n",
            "Epoch 637/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1814.7106 - mae: 1814.7106 - mse: 20822700.0000 - val_loss: 1783.7040 - val_mae: 1783.7040 - val_mse: 20206374.0000\n",
            "Epoch 638/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1809.1702 - mae: 1809.1702 - mse: 20717564.0000 - val_loss: 1845.1488 - val_mae: 1845.1488 - val_mse: 20150092.0000\n",
            "Epoch 639/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1819.0869 - mae: 1819.0869 - mse: 20924722.0000 - val_loss: 1846.0332 - val_mae: 1846.0332 - val_mse: 20966708.0000\n",
            "Epoch 640/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1826.1422 - mae: 1826.1422 - mse: 20928868.0000 - val_loss: 1793.4437 - val_mae: 1793.4437 - val_mse: 20245562.0000\n",
            "Epoch 641/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1811.5676 - mae: 1811.5676 - mse: 20670444.0000 - val_loss: 1855.7783 - val_mae: 1855.7783 - val_mse: 20086358.0000\n",
            "Epoch 642/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1789.2390 - mae: 1789.2390 - mse: 20714464.0000 - val_loss: 1789.4836 - val_mae: 1789.4836 - val_mse: 20631030.0000\n",
            "Epoch 643/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1814.6726 - mae: 1814.6726 - mse: 20799734.0000 - val_loss: 2165.0957 - val_mae: 2165.0957 - val_mse: 23051138.0000\n",
            "Epoch 644/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1809.9465 - mae: 1809.9465 - mse: 20788556.0000 - val_loss: 2060.9348 - val_mae: 2060.9348 - val_mse: 20008358.0000\n",
            "Epoch 645/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1812.1761 - mae: 1812.1761 - mse: 20709386.0000 - val_loss: 2002.0536 - val_mae: 2002.0536 - val_mse: 22372754.0000\n",
            "Epoch 646/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1817.4053 - mae: 1817.4053 - mse: 21122726.0000 - val_loss: 1800.0841 - val_mae: 1800.0841 - val_mse: 20451916.0000\n",
            "Epoch 647/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1840.4199 - mae: 1840.4199 - mse: 21141848.0000 - val_loss: 1777.8074 - val_mae: 1777.8074 - val_mse: 20465976.0000\n",
            "Epoch 648/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1779.6161 - mae: 1779.6161 - mse: 20719782.0000 - val_loss: 1968.6687 - val_mae: 1968.6687 - val_mse: 19956990.0000\n",
            "Epoch 649/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1825.5332 - mae: 1825.5332 - mse: 20785468.0000 - val_loss: 1787.4559 - val_mae: 1787.4559 - val_mse: 20074852.0000\n",
            "Epoch 650/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1806.6650 - mae: 1806.6650 - mse: 20870898.0000 - val_loss: 1824.8406 - val_mae: 1824.8406 - val_mse: 19982542.0000\n",
            "Epoch 651/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1788.7205 - mae: 1788.7205 - mse: 20913210.0000 - val_loss: 2071.4521 - val_mae: 2071.4521 - val_mse: 20215670.0000\n",
            "Epoch 652/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1788.5751 - mae: 1788.5751 - mse: 20475878.0000 - val_loss: 1898.8096 - val_mae: 1898.8096 - val_mse: 21727754.0000\n",
            "Epoch 653/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1788.7621 - mae: 1788.7621 - mse: 20668444.0000 - val_loss: 2148.0840 - val_mae: 2148.0840 - val_mse: 23101078.0000\n",
            "Epoch 654/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1847.2711 - mae: 1847.2711 - mse: 21042504.0000 - val_loss: 1870.7527 - val_mae: 1870.7527 - val_mse: 20994940.0000\n",
            "Epoch 655/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1782.7939 - mae: 1782.7939 - mse: 20874318.0000 - val_loss: 1797.9336 - val_mae: 1797.9336 - val_mse: 20279080.0000\n",
            "Epoch 656/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1777.4790 - mae: 1777.4790 - mse: 20696040.0000 - val_loss: 1804.0061 - val_mae: 1804.0061 - val_mse: 20416244.0000\n",
            "Epoch 657/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1801.5002 - mae: 1801.5002 - mse: 20750478.0000 - val_loss: 1920.9858 - val_mae: 1920.9858 - val_mse: 21653282.0000\n",
            "Epoch 658/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1790.3755 - mae: 1790.3755 - mse: 20735160.0000 - val_loss: 1834.2249 - val_mae: 1834.2249 - val_mse: 21475924.0000\n",
            "Epoch 659/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1790.2839 - mae: 1790.2839 - mse: 20977600.0000 - val_loss: 1800.1813 - val_mae: 1800.1813 - val_mse: 20258332.0000\n",
            "Epoch 660/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1777.8273 - mae: 1777.8273 - mse: 20712684.0000 - val_loss: 1766.7395 - val_mae: 1766.7395 - val_mse: 20497096.0000\n",
            "Epoch 661/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1751.9717 - mae: 1751.9717 - mse: 20495434.0000 - val_loss: 1865.7570 - val_mae: 1865.7570 - val_mse: 20537650.0000\n",
            "Epoch 662/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1798.9259 - mae: 1798.9259 - mse: 20659332.0000 - val_loss: 1915.5864 - val_mae: 1915.5864 - val_mse: 20245958.0000\n",
            "Epoch 663/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1797.2411 - mae: 1797.2411 - mse: 20868960.0000 - val_loss: 1960.0389 - val_mae: 1960.0389 - val_mse: 19712100.0000\n",
            "Epoch 664/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1778.3723 - mae: 1778.3723 - mse: 20641674.0000 - val_loss: 1864.0673 - val_mae: 1864.0671 - val_mse: 19879818.0000\n",
            "Epoch 665/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1778.8037 - mae: 1778.8037 - mse: 20496698.0000 - val_loss: 1783.3760 - val_mae: 1783.3760 - val_mse: 21128242.0000\n",
            "Epoch 666/1000\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1810.4684 - mae: 1810.4684 - mse: 20682696.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 1814.5610 - mae: 1814.5610 - mse: 21129388.0000 - val_loss: 1761.2924 - val_mae: 1761.2924 - val_mse: 20162708.0000\n",
            "Epoch 667/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1807.0995 - mae: 1807.0995 - mse: 20684458.0000 - val_loss: 1855.2230 - val_mae: 1855.2230 - val_mse: 20072370.0000\n",
            "Epoch 668/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1785.2147 - mae: 1785.2147 - mse: 20482548.0000 - val_loss: 1852.5087 - val_mae: 1852.5087 - val_mse: 21131336.0000\n",
            "Epoch 669/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1789.8649 - mae: 1789.8649 - mse: 20516920.0000 - val_loss: 1964.4777 - val_mae: 1964.4777 - val_mse: 22207528.0000\n",
            "Epoch 670/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1775.0127 - mae: 1775.0127 - mse: 20872262.0000 - val_loss: 1854.9152 - val_mae: 1854.9152 - val_mse: 19856018.0000\n",
            "Epoch 671/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1769.6776 - mae: 1769.6776 - mse: 20581262.0000 - val_loss: 2053.3330 - val_mae: 2053.3330 - val_mse: 22217058.0000\n",
            "Epoch 672/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1793.4791 - mae: 1793.4791 - mse: 20494546.0000 - val_loss: 1964.1798 - val_mae: 1964.1798 - val_mse: 21140954.0000\n",
            "Epoch 673/1000\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1791.4360 - mae: 1791.4360 - mse: 20682080.0000 - val_loss: 1961.4465 - val_mae: 1961.4465 - val_mse: 21901432.0000\n",
            "Epoch 674/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1749.9979 - mae: 1749.9979 - mse: 20484454.0000 - val_loss: 2113.8865 - val_mae: 2113.8865 - val_mse: 20112642.0000\n",
            "Epoch 675/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1779.8375 - mae: 1779.8375 - mse: 20449976.0000 - val_loss: 2010.0757 - val_mae: 2010.0757 - val_mse: 21096638.0000\n",
            "Epoch 676/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1771.1226 - mae: 1771.1226 - mse: 20439054.0000 - val_loss: 1763.2491 - val_mae: 1763.2491 - val_mse: 20445002.0000\n",
            "Epoch 677/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1799.7037 - mae: 1799.7037 - mse: 20773434.0000 - val_loss: 1848.6274 - val_mae: 1848.6274 - val_mse: 20900606.0000\n",
            "Epoch 678/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1772.4816 - mae: 1772.4816 - mse: 20552330.0000 - val_loss: 1886.9553 - val_mae: 1886.9553 - val_mse: 21210756.0000\n",
            "Epoch 679/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1790.9028 - mae: 1790.9028 - mse: 20776920.0000 - val_loss: 1871.1759 - val_mae: 1871.1759 - val_mse: 19865430.0000\n",
            "Epoch 680/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1777.8007 - mae: 1777.8007 - mse: 20696880.0000 - val_loss: 2048.6189 - val_mae: 2048.6189 - val_mse: 20663552.0000\n",
            "Epoch 681/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1768.7106 - mae: 1768.7106 - mse: 20483868.0000 - val_loss: 2044.7029 - val_mae: 2044.7029 - val_mse: 22756252.0000\n",
            "Epoch 682/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1766.4373 - mae: 1766.4373 - mse: 20706722.0000 - val_loss: 1809.7789 - val_mae: 1809.7789 - val_mse: 20794712.0000\n",
            "Epoch 683/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1780.1714 - mae: 1780.1714 - mse: 20423870.0000 - val_loss: 1900.6870 - val_mae: 1900.6870 - val_mse: 21440752.0000\n",
            "Epoch 684/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1783.7133 - mae: 1783.7133 - mse: 20675012.0000 - val_loss: 2072.4963 - val_mae: 2072.4963 - val_mse: 20665246.0000\n",
            "Epoch 685/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1765.0110 - mae: 1765.0110 - mse: 20475708.0000 - val_loss: 1939.1337 - val_mae: 1939.1337 - val_mse: 21617638.0000\n",
            "Epoch 686/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1752.1024 - mae: 1752.1024 - mse: 20534952.0000 - val_loss: 1916.4681 - val_mae: 1916.4681 - val_mse: 19907598.0000\n",
            "Epoch 687/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1759.1986 - mae: 1759.1986 - mse: 20196336.0000 - val_loss: 1887.4902 - val_mae: 1887.4902 - val_mse: 20584970.0000\n",
            "Epoch 688/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1746.6104 - mae: 1746.6104 - mse: 20205610.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 56ms/step - loss: 1749.5822 - mae: 1749.5822 - mse: 20366588.0000 - val_loss: 1731.8173 - val_mae: 1731.8173 - val_mse: 19986918.0000\n",
            "Epoch 689/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1782.5371 - mae: 1782.5371 - mse: 20481584.0000 - val_loss: 1778.8789 - val_mae: 1778.8789 - val_mse: 20526308.0000\n",
            "Epoch 690/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1735.4440 - mae: 1735.4440 - mse: 20481454.0000 - val_loss: 1963.9395 - val_mae: 1963.9395 - val_mse: 19568230.0000\n",
            "Epoch 691/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1799.0885 - mae: 1799.0885 - mse: 20711362.0000 - val_loss: 1964.1198 - val_mae: 1964.1198 - val_mse: 21959654.0000\n",
            "Epoch 692/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1803.1996 - mae: 1803.1996 - mse: 20608894.0000 - val_loss: 1785.1318 - val_mae: 1785.1318 - val_mse: 20244508.0000\n",
            "Epoch 693/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1725.8186 - mae: 1725.8186 - mse: 20254386.0000 - val_loss: 1790.9325 - val_mae: 1790.9325 - val_mse: 20960334.0000\n",
            "Epoch 694/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1758.7517 - mae: 1758.7517 - mse: 20453112.0000 - val_loss: 1791.7142 - val_mae: 1791.7142 - val_mse: 20219900.0000\n",
            "Epoch 695/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1753.9121 - mae: 1753.9121 - mse: 20247374.0000 - val_loss: 1890.7189 - val_mae: 1890.7189 - val_mse: 20626600.0000\n",
            "Epoch 696/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1754.8556 - mae: 1754.8556 - mse: 20383646.0000 - val_loss: 1992.9065 - val_mae: 1992.9065 - val_mse: 22091494.0000\n",
            "Epoch 697/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1785.4626 - mae: 1785.4626 - mse: 20297794.0000 - val_loss: 1765.9777 - val_mae: 1765.9777 - val_mse: 21012904.0000\n",
            "Epoch 698/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1755.0027 - mae: 1755.0027 - mse: 20515342.0000 - val_loss: 1953.0868 - val_mae: 1953.0868 - val_mse: 19732366.0000\n",
            "Epoch 699/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1742.2528 - mae: 1742.2528 - mse: 20142568.0000 - val_loss: 1884.9644 - val_mae: 1884.9644 - val_mse: 20797030.0000\n",
            "Epoch 700/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1722.9211 - mae: 1722.9211 - mse: 20304082.0000 - val_loss: 1868.0920 - val_mae: 1868.0920 - val_mse: 20717376.0000\n",
            "Epoch 701/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1782.1079 - mae: 1782.1079 - mse: 20540114.0000 - val_loss: 1834.6741 - val_mae: 1834.6741 - val_mse: 21182286.0000\n",
            "Epoch 702/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1647.1377 - mae: 1647.1377 - mse: 20022100.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 63ms/step - loss: 1733.2081 - mae: 1733.2081 - mse: 20352082.0000 - val_loss: 1728.6230 - val_mae: 1728.6230 - val_mse: 20270280.0000\n",
            "Epoch 703/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1777.5647 - mae: 1777.5647 - mse: 20698438.0000 - val_loss: 1982.1987 - val_mae: 1982.1987 - val_mse: 21632098.0000\n",
            "Epoch 704/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1730.0020 - mae: 1730.0020 - mse: 20180012.0000 - val_loss: 1758.0366 - val_mae: 1758.0366 - val_mse: 20310248.0000\n",
            "Epoch 705/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1804.5698 - mae: 1804.5698 - mse: 20803062.0000 - val_loss: 1770.4969 - val_mae: 1770.4969 - val_mse: 20960096.0000\n",
            "Epoch 706/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1736.1066 - mae: 1736.1066 - mse: 20328264.0000 - val_loss: 1757.4240 - val_mae: 1757.4240 - val_mse: 20220890.0000\n",
            "Epoch 707/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1745.0425 - mae: 1745.0425 - mse: 20227780.0000 - val_loss: 1785.0552 - val_mae: 1785.0552 - val_mse: 20331712.0000\n",
            "Epoch 708/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1740.7296 - mae: 1740.7296 - mse: 20203610.0000 - val_loss: 1918.0815 - val_mae: 1918.0815 - val_mse: 21137900.0000\n",
            "Epoch 709/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1779.9949 - mae: 1779.9949 - mse: 20660594.0000 - val_loss: 2151.6282 - val_mae: 2151.6282 - val_mse: 20391842.0000\n",
            "Epoch 710/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1753.2228 - mae: 1753.2228 - mse: 20479218.0000 - val_loss: 1822.3973 - val_mae: 1822.3973 - val_mse: 20041266.0000\n",
            "Epoch 711/1000\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1756.1375 - mae: 1756.1375 - mse: 20709580.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 54ms/step - loss: 1747.6431 - mae: 1747.6431 - mse: 20681550.0000 - val_loss: 1726.2510 - val_mae: 1726.2510 - val_mse: 20444372.0000\n",
            "Epoch 712/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1765.0865 - mae: 1765.0865 - mse: 20424556.0000 - val_loss: 1751.5734 - val_mae: 1751.5734 - val_mse: 21005132.0000\n",
            "Epoch 713/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1740.1154 - mae: 1740.1154 - mse: 20264336.0000 - val_loss: 1865.9403 - val_mae: 1865.9403 - val_mse: 19715372.0000\n",
            "Epoch 714/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1732.6333 - mae: 1732.6333 - mse: 20204706.0000 - val_loss: 1831.9969 - val_mae: 1831.9969 - val_mse: 19667658.0000\n",
            "Epoch 715/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1739.1000 - mae: 1739.1000 - mse: 20426314.0000 - val_loss: 1852.3832 - val_mae: 1852.3832 - val_mse: 20556790.0000\n",
            "Epoch 716/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1730.8707 - mae: 1730.8707 - mse: 20215042.0000 - val_loss: 1805.6202 - val_mae: 1805.6202 - val_mse: 19691354.0000\n",
            "Epoch 717/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1750.8202 - mae: 1750.8202 - mse: 20405092.0000 - val_loss: 1795.5424 - val_mae: 1795.5424 - val_mse: 20864078.0000\n",
            "Epoch 718/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1703.4138 - mae: 1703.4138 - mse: 20206688.0000 - val_loss: 1848.3467 - val_mae: 1848.3467 - val_mse: 19694746.0000\n",
            "Epoch 719/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1725.1277 - mae: 1725.1277 - mse: 20064026.0000 - val_loss: 2005.0989 - val_mae: 2005.0989 - val_mse: 19761282.0000\n",
            "Epoch 720/1000\n",
            "27/27 [==============================] - ETA: 0s - loss: 1763.5258 - mae: 1763.5258 - mse: 20299434.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 56ms/step - loss: 1763.5258 - mae: 1763.5258 - mse: 20299434.0000 - val_loss: 1698.3379 - val_mae: 1698.3379 - val_mse: 20439750.0000\n",
            "Epoch 721/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1721.7710 - mae: 1721.7710 - mse: 20099388.0000 - val_loss: 1915.5105 - val_mae: 1915.5105 - val_mse: 22874840.0000\n",
            "Epoch 722/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1732.8967 - mae: 1732.8967 - mse: 20211092.0000 - val_loss: 1758.9613 - val_mae: 1758.9613 - val_mse: 20653222.0000\n",
            "Epoch 723/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1752.5328 - mae: 1752.5328 - mse: 20470664.0000 - val_loss: 1929.4387 - val_mae: 1929.4387 - val_mse: 19539580.0000\n",
            "Epoch 724/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1713.5734 - mae: 1713.5734 - mse: 20049868.0000 - val_loss: 1755.7395 - val_mae: 1755.7395 - val_mse: 20681840.0000\n",
            "Epoch 725/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1730.0032 - mae: 1730.0032 - mse: 20140176.0000 - val_loss: 1764.2743 - val_mae: 1764.2743 - val_mse: 19764816.0000\n",
            "Epoch 726/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1710.8942 - mae: 1710.8942 - mse: 20297428.0000 - val_loss: 1899.0463 - val_mae: 1899.0463 - val_mse: 19596582.0000\n",
            "Epoch 727/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1717.5815 - mae: 1717.5815 - mse: 20184920.0000 - val_loss: 1976.9608 - val_mae: 1976.9608 - val_mse: 19570282.0000\n",
            "Epoch 728/1000\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1747.7472 - mae: 1747.7472 - mse: 20301178.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 55ms/step - loss: 1710.8116 - mae: 1710.8116 - mse: 20062766.0000 - val_loss: 1682.8353 - val_mae: 1682.8353 - val_mse: 20042010.0000\n",
            "Epoch 729/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1716.1039 - mae: 1716.1039 - mse: 20149438.0000 - val_loss: 1944.1117 - val_mae: 1944.1117 - val_mse: 21790206.0000\n",
            "Epoch 730/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1719.8177 - mae: 1719.8177 - mse: 20050674.0000 - val_loss: 1704.2281 - val_mae: 1704.2281 - val_mse: 20212236.0000\n",
            "Epoch 731/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1707.2267 - mae: 1707.2267 - mse: 20130744.0000 - val_loss: 1847.5341 - val_mae: 1847.5341 - val_mse: 21507132.0000\n",
            "Epoch 732/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1694.8547 - mae: 1694.8547 - mse: 19929194.0000 - val_loss: 1712.2401 - val_mae: 1712.2401 - val_mse: 20220388.0000\n",
            "Epoch 733/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1748.3313 - mae: 1748.3313 - mse: 20432114.0000 - val_loss: 1711.9690 - val_mae: 1711.9690 - val_mse: 20593636.0000\n",
            "Epoch 734/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1689.8164 - mae: 1689.8164 - mse: 20036394.0000 - val_loss: 1735.1074 - val_mae: 1735.1074 - val_mse: 20224812.0000\n",
            "Epoch 735/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1703.9121 - mae: 1703.9121 - mse: 19942042.0000 - val_loss: 1689.6747 - val_mae: 1689.6747 - val_mse: 20089478.0000\n",
            "Epoch 736/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1714.1818 - mae: 1714.1818 - mse: 20107900.0000 - val_loss: 1843.5168 - val_mae: 1843.5168 - val_mse: 19516654.0000\n",
            "Epoch 737/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1737.3546 - mae: 1737.3546 - mse: 20290044.0000 - val_loss: 1699.4508 - val_mae: 1699.4508 - val_mse: 20168196.0000\n",
            "Epoch 738/1000\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1621.8966 - mae: 1621.8966 - mse: 18900506.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 55ms/step - loss: 1710.9984 - mae: 1710.9984 - mse: 20305026.0000 - val_loss: 1676.5190 - val_mae: 1676.5190 - val_mse: 20158342.0000\n",
            "Epoch 739/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1679.9362 - mae: 1679.9362 - mse: 19979814.0000 - val_loss: 1876.8851 - val_mae: 1876.8851 - val_mse: 19690028.0000\n",
            "Epoch 740/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1732.7322 - mae: 1732.7322 - mse: 20163660.0000 - val_loss: 1686.2455 - val_mae: 1686.2455 - val_mse: 20523902.0000\n",
            "Epoch 741/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1716.1248 - mae: 1716.1248 - mse: 20375840.0000 - val_loss: 1831.7397 - val_mae: 1831.7397 - val_mse: 20042504.0000\n",
            "Epoch 742/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1696.0984 - mae: 1696.0984 - mse: 20257488.0000 - val_loss: 1839.8311 - val_mae: 1839.8311 - val_mse: 19529644.0000\n",
            "Epoch 743/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1686.1456 - mae: 1686.1456 - mse: 20284258.0000 - val_loss: 1801.2274 - val_mae: 1801.2274 - val_mse: 19793630.0000\n",
            "Epoch 744/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1723.4656 - mae: 1723.4656 - mse: 20341646.0000 - val_loss: 1725.4806 - val_mae: 1725.4806 - val_mse: 19764404.0000\n",
            "Epoch 745/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1694.7755 - mae: 1694.7755 - mse: 20168190.0000 - val_loss: 1708.4556 - val_mae: 1708.4556 - val_mse: 19877824.0000\n",
            "Epoch 746/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1704.1351 - mae: 1704.1351 - mse: 20089534.0000 - val_loss: 1924.3373 - val_mae: 1924.3373 - val_mse: 19543326.0000\n",
            "Epoch 747/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1683.8245 - mae: 1683.8245 - mse: 20023778.0000 - val_loss: 1880.1698 - val_mae: 1880.1698 - val_mse: 21462870.0000\n",
            "Epoch 748/1000\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1685.5662 - mae: 1685.5662 - mse: 20096486.0000 - val_loss: 1793.0157 - val_mae: 1793.0157 - val_mse: 19728594.0000\n",
            "Epoch 749/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1672.1294 - mae: 1672.1294 - mse: 19961490.0000 - val_loss: 1862.8845 - val_mae: 1862.8845 - val_mse: 22237376.0000\n",
            "Epoch 750/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1691.4683 - mae: 1691.4683 - mse: 19992832.0000 - val_loss: 1715.9287 - val_mae: 1715.9287 - val_mse: 20084606.0000\n",
            "Epoch 751/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1723.5925 - mae: 1723.5925 - mse: 20668226.0000 - val_loss: 1773.4707 - val_mae: 1773.4707 - val_mse: 20989950.0000\n",
            "Epoch 752/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1693.3312 - mae: 1693.3312 - mse: 20117702.0000 - val_loss: 1686.2911 - val_mae: 1686.2911 - val_mse: 20152230.0000\n",
            "Epoch 753/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1670.0415 - mae: 1670.0415 - mse: 19886426.0000 - val_loss: 2078.3438 - val_mae: 2078.3438 - val_mse: 21033948.0000\n",
            "Epoch 754/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1698.8281 - mae: 1698.8281 - mse: 19996234.0000 - val_loss: 1772.7477 - val_mae: 1772.7477 - val_mse: 19944392.0000\n",
            "Epoch 755/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1690.0460 - mae: 1690.0460 - mse: 20142276.0000 - val_loss: 1713.0950 - val_mae: 1713.0950 - val_mse: 20043524.0000\n",
            "Epoch 756/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1662.5330 - mae: 1662.5330 - mse: 19737946.0000 - val_loss: 1760.2487 - val_mae: 1760.2487 - val_mse: 20087210.0000\n",
            "Epoch 757/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1687.7203 - mae: 1687.7203 - mse: 20320096.0000 - val_loss: 1711.7291 - val_mae: 1711.7291 - val_mse: 20835898.0000\n",
            "Epoch 758/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1672.3566 - mae: 1672.3566 - mse: 19840498.0000 - val_loss: 1906.4808 - val_mae: 1906.4808 - val_mse: 21906094.0000\n",
            "Epoch 759/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1688.3191 - mae: 1688.3191 - mse: 19960306.0000 - val_loss: 2168.5112 - val_mae: 2168.5112 - val_mse: 24137484.0000\n",
            "Epoch 760/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1688.3450 - mae: 1688.3450 - mse: 20071798.0000 - val_loss: 1794.1274 - val_mae: 1794.1274 - val_mse: 20859104.0000\n",
            "Epoch 761/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1683.8154 - mae: 1683.8154 - mse: 20114990.0000 - val_loss: 1704.0662 - val_mae: 1704.0662 - val_mse: 19560714.0000\n",
            "Epoch 762/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1669.3722 - mae: 1669.3722 - mse: 20033190.0000 - val_loss: 1950.2015 - val_mae: 1950.2015 - val_mse: 19530240.0000\n",
            "Epoch 763/1000\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1740.9044 - mae: 1740.9044 - mse: 20692190.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 56ms/step - loss: 1681.6185 - mae: 1681.6185 - mse: 19772370.0000 - val_loss: 1671.7568 - val_mae: 1671.7568 - val_mse: 20245030.0000\n",
            "Epoch 764/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1670.8696 - mae: 1670.8696 - mse: 19971266.0000 - val_loss: 1772.2725 - val_mae: 1772.2725 - val_mse: 21419678.0000\n",
            "Epoch 765/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1652.5726 - mae: 1652.5726 - mse: 19974624.0000 - val_loss: 1699.9912 - val_mae: 1699.9912 - val_mse: 20636890.0000\n",
            "Epoch 766/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1656.2628 - mae: 1656.2628 - mse: 19832554.0000 - val_loss: 1887.7488 - val_mae: 1887.7488 - val_mse: 19414196.0000\n",
            "Epoch 767/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1678.9653 - mae: 1678.9653 - mse: 19829622.0000 - val_loss: 1700.0747 - val_mae: 1700.0747 - val_mse: 20500626.0000\n",
            "Epoch 768/1000\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1648.4141 - mae: 1648.4141 - mse: 19775358.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 64ms/step - loss: 1664.2887 - mae: 1664.2887 - mse: 19885930.0000 - val_loss: 1659.0416 - val_mae: 1659.0416 - val_mse: 19881696.0000\n",
            "Epoch 769/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1675.6027 - mae: 1675.6027 - mse: 20087238.0000 - val_loss: 1754.4476 - val_mae: 1754.4476 - val_mse: 21026126.0000\n",
            "Epoch 770/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1674.8068 - mae: 1674.8068 - mse: 20035288.0000 - val_loss: 1736.9777 - val_mae: 1736.9777 - val_mse: 19936738.0000\n",
            "Epoch 771/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1652.3951 - mae: 1652.3951 - mse: 19667532.0000 - val_loss: 1950.6469 - val_mae: 1950.6469 - val_mse: 19903322.0000\n",
            "Epoch 772/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1656.9448 - mae: 1656.9448 - mse: 19915824.0000 - val_loss: 1878.8986 - val_mae: 1878.8986 - val_mse: 20016312.0000\n",
            "Epoch 773/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1645.0171 - mae: 1645.0171 - mse: 19655792.0000 - val_loss: 1727.8507 - val_mae: 1727.8507 - val_mse: 20846492.0000\n",
            "Epoch 774/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1677.4636 - mae: 1677.4636 - mse: 19824216.0000 - val_loss: 1705.9526 - val_mae: 1705.9526 - val_mse: 19921738.0000\n",
            "Epoch 775/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1661.0073 - mae: 1661.0073 - mse: 19723330.0000 - val_loss: 1849.1606 - val_mae: 1849.1606 - val_mse: 20060108.0000\n",
            "Epoch 776/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1640.3120 - mae: 1640.3120 - mse: 19646782.0000 - val_loss: 1742.2875 - val_mae: 1742.2875 - val_mse: 21081634.0000\n",
            "Epoch 777/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1662.7516 - mae: 1662.7516 - mse: 19986958.0000 - val_loss: 1827.7515 - val_mae: 1827.7515 - val_mse: 21187092.0000\n",
            "Epoch 778/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1636.4797 - mae: 1636.4797 - mse: 19676310.0000 - val_loss: 1979.5520 - val_mae: 1979.5520 - val_mse: 22593814.0000\n",
            "Epoch 779/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1680.8296 - mae: 1680.8296 - mse: 20014998.0000 - val_loss: 1835.6764 - val_mae: 1835.6764 - val_mse: 20690276.0000\n",
            "Epoch 780/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1629.6071 - mae: 1629.6071 - mse: 19614018.0000 - val_loss: 2043.9071 - val_mae: 2043.9071 - val_mse: 22873120.0000\n",
            "Epoch 781/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1678.6393 - mae: 1678.6393 - mse: 20009196.0000 - val_loss: 1753.5824 - val_mae: 1753.5824 - val_mse: 19845366.0000\n",
            "Epoch 782/1000\n",
            "27/27 [==============================] - ETA: 0s - loss: 1625.2092 - mae: 1625.2092 - mse: 19517600.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 54ms/step - loss: 1625.2092 - mae: 1625.2092 - mse: 19517600.0000 - val_loss: 1622.7396 - val_mae: 1622.7396 - val_mse: 19417968.0000\n",
            "Epoch 783/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1641.6243 - mae: 1641.6243 - mse: 19700334.0000 - val_loss: 1841.0258 - val_mae: 1841.0258 - val_mse: 21633008.0000\n",
            "Epoch 784/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1645.6877 - mae: 1645.6877 - mse: 19874716.0000 - val_loss: 2088.9834 - val_mae: 2088.9834 - val_mse: 19961724.0000\n",
            "Epoch 785/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1624.1678 - mae: 1624.1678 - mse: 19517332.0000 - val_loss: 1690.4995 - val_mae: 1690.4995 - val_mse: 20121344.0000\n",
            "Epoch 786/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1609.5219 - mae: 1609.5219 - mse: 19253400.0000 - val_loss: 1888.4800 - val_mae: 1888.4800 - val_mse: 21348720.0000\n",
            "Epoch 787/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1672.1389 - mae: 1672.1389 - mse: 19760072.0000 - val_loss: 1884.6010 - val_mae: 1884.6010 - val_mse: 21604672.0000\n",
            "Epoch 788/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1674.3998 - mae: 1674.3998 - mse: 19883822.0000 - val_loss: 1839.6438 - val_mae: 1839.6438 - val_mse: 20271160.0000\n",
            "Epoch 789/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1620.2858 - mae: 1620.2858 - mse: 19776180.0000 - val_loss: 1710.4120 - val_mae: 1710.4120 - val_mse: 19708972.0000\n",
            "Epoch 790/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1649.1375 - mae: 1649.1375 - mse: 19901102.0000 - val_loss: 1758.6322 - val_mae: 1758.6322 - val_mse: 19284538.0000\n",
            "Epoch 791/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1658.5488 - mae: 1658.5488 - mse: 19750642.0000 - val_loss: 1643.8763 - val_mae: 1643.8763 - val_mse: 19891222.0000\n",
            "Epoch 792/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1632.7985 - mae: 1632.7985 - mse: 19650660.0000 - val_loss: 1648.6799 - val_mae: 1648.6799 - val_mse: 19656340.0000\n",
            "Epoch 793/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1633.7328 - mae: 1633.7328 - mse: 19581370.0000 - val_loss: 2331.9888 - val_mae: 2331.9888 - val_mse: 25773092.0000\n",
            "Epoch 794/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1641.7949 - mae: 1641.7949 - mse: 19903632.0000 - val_loss: 1791.9049 - val_mae: 1791.9049 - val_mse: 19333802.0000\n",
            "Epoch 795/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1637.7997 - mae: 1637.7997 - mse: 19522208.0000 - val_loss: 1663.3201 - val_mae: 1663.3201 - val_mse: 19506538.0000\n",
            "Epoch 796/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1641.0322 - mae: 1641.0322 - mse: 19669196.0000 - val_loss: 1738.4945 - val_mae: 1738.4945 - val_mse: 19976764.0000\n",
            "Epoch 797/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1605.4537 - mae: 1605.4537 - mse: 19566662.0000 - val_loss: 1802.7523 - val_mae: 1802.7523 - val_mse: 21142086.0000\n",
            "Epoch 798/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1650.4954 - mae: 1650.4954 - mse: 19910046.0000 - val_loss: 1736.7704 - val_mae: 1736.7704 - val_mse: 20295610.0000\n",
            "Epoch 799/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1640.3464 - mae: 1640.3464 - mse: 19689994.0000 - val_loss: 1852.9198 - val_mae: 1852.9198 - val_mse: 21946248.0000\n",
            "Epoch 800/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1631.7919 - mae: 1631.7919 - mse: 19650468.0000 - val_loss: 1731.9553 - val_mae: 1731.9553 - val_mse: 21065110.0000\n",
            "Epoch 801/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1570.5037 - mae: 1570.5037 - mse: 19321680.0000 - val_loss: 2056.2639 - val_mae: 2056.2639 - val_mse: 24575686.0000\n",
            "Epoch 802/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1702.6925 - mae: 1702.6925 - mse: 20136874.0000 - val_loss: 1707.4830 - val_mae: 1707.4830 - val_mse: 20838668.0000\n",
            "Epoch 803/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1582.8829 - mae: 1582.8829 - mse: 19414518.0000 - val_loss: 1760.5238 - val_mae: 1760.5238 - val_mse: 19802120.0000\n",
            "Epoch 804/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1627.6310 - mae: 1627.6310 - mse: 19741082.0000 - val_loss: 2011.5378 - val_mae: 2011.5378 - val_mse: 19555664.0000\n",
            "Epoch 805/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1597.5646 - mae: 1597.5646 - mse: 19401208.0000 - val_loss: 2024.2031 - val_mae: 2024.2031 - val_mse: 20564442.0000\n",
            "Epoch 806/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1642.0474 - mae: 1642.0474 - mse: 19630480.0000 - val_loss: 1751.0250 - val_mae: 1751.0250 - val_mse: 19634704.0000\n",
            "Epoch 807/1000\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1702.5563 - mae: 1702.5563 - mse: 21362412.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 53ms/step - loss: 1623.3137 - mae: 1623.3137 - mse: 19481814.0000 - val_loss: 1595.9716 - val_mae: 1595.9716 - val_mse: 19755610.0000\n",
            "Epoch 808/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1602.2822 - mae: 1602.2822 - mse: 19542056.0000 - val_loss: 1606.2211 - val_mae: 1606.2211 - val_mse: 19931944.0000\n",
            "Epoch 809/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1606.7391 - mae: 1606.7391 - mse: 19358584.0000 - val_loss: 1690.1501 - val_mae: 1690.1501 - val_mse: 19595074.0000\n",
            "Epoch 810/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1639.1178 - mae: 1639.1178 - mse: 19723792.0000 - val_loss: 1698.4080 - val_mae: 1698.4080 - val_mse: 21288122.0000\n",
            "Epoch 811/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1615.2955 - mae: 1615.2955 - mse: 19750502.0000 - val_loss: 1682.7354 - val_mae: 1682.7354 - val_mse: 20566832.0000\n",
            "Epoch 812/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1651.5791 - mae: 1651.5791 - mse: 19762494.0000 - val_loss: 1714.5199 - val_mae: 1714.5199 - val_mse: 20599648.0000\n",
            "Epoch 813/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1609.1526 - mae: 1609.1526 - mse: 19346582.0000 - val_loss: 1796.9769 - val_mae: 1796.9769 - val_mse: 21604656.0000\n",
            "Epoch 814/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1626.6118 - mae: 1626.6118 - mse: 19515142.0000 - val_loss: 1849.7275 - val_mae: 1849.7275 - val_mse: 22104170.0000\n",
            "Epoch 815/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1617.8313 - mae: 1617.8313 - mse: 19582246.0000 - val_loss: 1945.7411 - val_mae: 1945.7411 - val_mse: 19584106.0000\n",
            "Epoch 816/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1608.9397 - mae: 1608.9397 - mse: 19392378.0000 - val_loss: 1701.6309 - val_mae: 1701.6309 - val_mse: 20813628.0000\n",
            "Epoch 817/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1601.3245 - mae: 1601.3245 - mse: 19477168.0000 - val_loss: 1619.4419 - val_mae: 1619.4419 - val_mse: 19900170.0000\n",
            "Epoch 818/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1616.1610 - mae: 1616.1610 - mse: 19576560.0000 - val_loss: 1960.1503 - val_mae: 1960.1503 - val_mse: 22033586.0000\n",
            "Epoch 819/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1622.5634 - mae: 1622.5634 - mse: 19764222.0000 - val_loss: 1725.1980 - val_mae: 1725.1980 - val_mse: 20904244.0000\n",
            "Epoch 820/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1624.9807 - mae: 1624.9807 - mse: 19576168.0000 - val_loss: 1618.6895 - val_mae: 1618.6895 - val_mse: 19830394.0000\n",
            "Epoch 821/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1618.6166 - mae: 1618.6166 - mse: 19675574.0000 - val_loss: 2121.5356 - val_mae: 2121.5356 - val_mse: 23140070.0000\n",
            "Epoch 822/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1598.9841 - mae: 1598.9841 - mse: 19420676.0000 - val_loss: 1622.3798 - val_mae: 1622.3798 - val_mse: 20308568.0000\n",
            "Epoch 823/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1643.6541 - mae: 1643.6541 - mse: 19783374.0000 - val_loss: 1883.1211 - val_mae: 1883.1211 - val_mse: 19543538.0000\n",
            "Epoch 824/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1582.7655 - mae: 1582.7655 - mse: 19156406.0000 - val_loss: 1665.2383 - val_mae: 1665.2383 - val_mse: 20775838.0000\n",
            "Epoch 825/1000\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1609.5836 - mae: 1609.5836 - mse: 19414338.0000 - val_loss: 1794.4121 - val_mae: 1794.4121 - val_mse: 22510804.0000\n",
            "Epoch 826/1000\n",
            "27/27 [==============================] - ETA: 0s - loss: 1592.6958 - mae: 1592.6958 - mse: 19280904.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 55ms/step - loss: 1592.6958 - mae: 1592.6958 - mse: 19280904.0000 - val_loss: 1578.9012 - val_mae: 1578.9012 - val_mse: 19945304.0000\n",
            "Epoch 827/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1592.5891 - mae: 1592.5891 - mse: 19461522.0000 - val_loss: 1705.1482 - val_mae: 1705.1482 - val_mse: 21604462.0000\n",
            "Epoch 828/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1599.1934 - mae: 1599.1934 - mse: 19472562.0000 - val_loss: 1673.7567 - val_mae: 1673.7567 - val_mse: 20496868.0000\n",
            "Epoch 829/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1593.9172 - mae: 1593.9172 - mse: 19319414.0000 - val_loss: 1697.9023 - val_mae: 1697.9023 - val_mse: 19587392.0000\n",
            "Epoch 830/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1575.4448 - mae: 1575.4448 - mse: 19145792.0000 - val_loss: 1653.2277 - val_mae: 1653.2277 - val_mse: 20773306.0000\n",
            "Epoch 831/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1605.1898 - mae: 1605.1898 - mse: 19494422.0000 - val_loss: 1823.8209 - val_mae: 1823.8209 - val_mse: 21297212.0000\n",
            "Epoch 832/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1629.7225 - mae: 1629.7225 - mse: 19506392.0000 - val_loss: 1657.3038 - val_mae: 1657.3038 - val_mse: 20076678.0000\n",
            "Epoch 833/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1587.0050 - mae: 1587.0050 - mse: 19493516.0000 - val_loss: 1712.8809 - val_mae: 1712.8809 - val_mse: 20703788.0000\n",
            "Epoch 834/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1605.3378 - mae: 1605.3378 - mse: 19560042.0000 - val_loss: 1709.4183 - val_mae: 1709.4183 - val_mse: 20824150.0000\n",
            "Epoch 835/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1608.5283 - mae: 1608.5283 - mse: 19382764.0000 - val_loss: 1680.9828 - val_mae: 1680.9828 - val_mse: 20225236.0000\n",
            "Epoch 836/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1586.3604 - mae: 1586.3604 - mse: 19659664.0000 - val_loss: 2027.1449 - val_mae: 2027.1449 - val_mse: 20206408.0000\n",
            "Epoch 837/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1595.1176 - mae: 1595.1176 - mse: 19645530.0000 - val_loss: 1660.8423 - val_mae: 1660.8423 - val_mse: 19602356.0000\n",
            "Epoch 838/1000\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1593.2158 - mae: 1593.2158 - mse: 19416890.0000 - val_loss: 1718.3564 - val_mae: 1718.3564 - val_mse: 21150840.0000\n",
            "Epoch 839/1000\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1666.7108 - mae: 1666.7108 - mse: 21124116.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 54ms/step - loss: 1589.2754 - mae: 1589.2754 - mse: 19309814.0000 - val_loss: 1578.4792 - val_mae: 1578.4792 - val_mse: 20288858.0000\n",
            "Epoch 840/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1594.6167 - mae: 1594.6167 - mse: 19688116.0000 - val_loss: 1669.7524 - val_mae: 1669.7524 - val_mse: 20657936.0000\n",
            "Epoch 841/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1590.3785 - mae: 1590.3785 - mse: 19439188.0000 - val_loss: 1821.8464 - val_mae: 1821.8464 - val_mse: 21510408.0000\n",
            "Epoch 842/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1607.8782 - mae: 1607.8782 - mse: 19332988.0000 - val_loss: 1840.5438 - val_mae: 1840.5438 - val_mse: 19647966.0000\n",
            "Epoch 843/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1594.0321 - mae: 1594.0321 - mse: 19572946.0000 - val_loss: 1847.8137 - val_mae: 1847.8137 - val_mse: 20594978.0000\n",
            "Epoch 844/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1590.9410 - mae: 1590.9410 - mse: 19311784.0000 - val_loss: 1993.2548 - val_mae: 1993.2548 - val_mse: 20540762.0000\n",
            "Epoch 845/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1621.9708 - mae: 1621.9708 - mse: 19675894.0000 - val_loss: 1915.6379 - val_mae: 1915.6379 - val_mse: 22023530.0000\n",
            "Epoch 846/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1596.1368 - mae: 1596.1368 - mse: 19339102.0000 - val_loss: 1670.7673 - val_mae: 1670.7673 - val_mse: 19821600.0000\n",
            "Epoch 847/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1565.9850 - mae: 1565.9850 - mse: 19354186.0000 - val_loss: 1797.5745 - val_mae: 1797.5745 - val_mse: 21006212.0000\n",
            "Epoch 848/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1586.9315 - mae: 1586.9315 - mse: 19429368.0000 - val_loss: 1744.7212 - val_mae: 1744.7212 - val_mse: 21680958.0000\n",
            "Epoch 849/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1567.3743 - mae: 1567.3743 - mse: 19221542.0000 - val_loss: 2068.3242 - val_mae: 2068.3242 - val_mse: 23964456.0000\n",
            "Epoch 850/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1594.7477 - mae: 1594.7477 - mse: 19353870.0000 - val_loss: 1589.1829 - val_mae: 1589.1829 - val_mse: 20256540.0000\n",
            "Epoch 851/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1583.2661 - mae: 1583.2661 - mse: 19474282.0000 - val_loss: 1730.4437 - val_mae: 1730.4437 - val_mse: 21574928.0000\n",
            "Epoch 852/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1630.0918 - mae: 1630.0918 - mse: 19696830.0000 - val_loss: 1673.3735 - val_mae: 1673.3735 - val_mse: 19833688.0000\n",
            "Epoch 853/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1545.7939 - mae: 1545.7939 - mse: 19022188.0000 - val_loss: 1798.3943 - val_mae: 1798.3943 - val_mse: 19777294.0000\n",
            "Epoch 854/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1594.4484 - mae: 1594.4484 - mse: 19710394.0000 - val_loss: 1767.7262 - val_mae: 1767.7262 - val_mse: 19434546.0000\n",
            "Epoch 855/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1602.6675 - mae: 1602.6675 - mse: 19570942.0000 - val_loss: 1717.6647 - val_mae: 1717.6647 - val_mse: 20198524.0000\n",
            "Epoch 856/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1586.1460 - mae: 1586.1460 - mse: 19284914.0000 - val_loss: 1677.5929 - val_mae: 1677.5929 - val_mse: 20150768.0000\n",
            "Epoch 857/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1580.6082 - mae: 1580.6082 - mse: 19422054.0000 - val_loss: 1649.5742 - val_mae: 1649.5742 - val_mse: 19715880.0000\n",
            "Epoch 858/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1580.3729 - mae: 1580.3729 - mse: 19192142.0000 - val_loss: 1795.5447 - val_mae: 1795.5447 - val_mse: 22180756.0000\n",
            "Epoch 859/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1586.3965 - mae: 1586.3965 - mse: 19445586.0000 - val_loss: 1814.4106 - val_mae: 1814.4106 - val_mse: 19556246.0000\n",
            "Epoch 860/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1601.9752 - mae: 1601.9752 - mse: 19422264.0000 - val_loss: 1592.3630 - val_mae: 1592.3630 - val_mse: 19931646.0000\n",
            "Epoch 861/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1544.7618 - mae: 1544.7618 - mse: 19020690.0000 - val_loss: 1686.1934 - val_mae: 1686.1934 - val_mse: 20655060.0000\n",
            "Epoch 862/1000\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1590.9423 - mae: 1590.9423 - mse: 19015772.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 55ms/step - loss: 1577.5973 - mae: 1577.5973 - mse: 19191096.0000 - val_loss: 1577.3624 - val_mae: 1577.3624 - val_mse: 20207632.0000\n",
            "Epoch 863/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1564.8513 - mae: 1564.8513 - mse: 19318980.0000 - val_loss: 1805.1057 - val_mae: 1805.1057 - val_mse: 22058314.0000\n",
            "Epoch 864/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1581.2557 - mae: 1581.2557 - mse: 19274086.0000 - val_loss: 1630.5627 - val_mae: 1630.5627 - val_mse: 20712926.0000\n",
            "Epoch 865/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1564.6600 - mae: 1564.6600 - mse: 19404716.0000 - val_loss: 1732.9486 - val_mae: 1732.9486 - val_mse: 19550642.0000\n",
            "Epoch 866/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1590.4801 - mae: 1590.4801 - mse: 19394698.0000 - val_loss: 1962.6196 - val_mae: 1962.6196 - val_mse: 19733014.0000\n",
            "Epoch 867/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1596.0959 - mae: 1596.0959 - mse: 19400788.0000 - val_loss: 1578.8243 - val_mae: 1578.8243 - val_mse: 19887358.0000\n",
            "Epoch 868/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1571.1230 - mae: 1571.1230 - mse: 19246428.0000 - val_loss: 1648.8752 - val_mae: 1648.8752 - val_mse: 19839882.0000\n",
            "Epoch 869/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1544.6456 - mae: 1544.6456 - mse: 19003776.0000 - val_loss: 1631.0891 - val_mae: 1631.0891 - val_mse: 21009344.0000\n",
            "Epoch 870/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1589.5021 - mae: 1589.5021 - mse: 19610578.0000 - val_loss: 1804.6725 - val_mae: 1804.6725 - val_mse: 20000918.0000\n",
            "Epoch 871/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1556.0481 - mae: 1556.0481 - mse: 19097082.0000 - val_loss: 1695.0782 - val_mae: 1695.0782 - val_mse: 20831072.0000\n",
            "Epoch 872/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1583.4093 - mae: 1583.4093 - mse: 19322634.0000 - val_loss: 1692.0183 - val_mae: 1692.0183 - val_mse: 21032280.0000\n",
            "Epoch 873/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1593.1802 - mae: 1593.1802 - mse: 19588256.0000 - val_loss: 1655.1969 - val_mae: 1655.1969 - val_mse: 20400698.0000\n",
            "Epoch 874/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1549.2338 - mae: 1549.2338 - mse: 19047152.0000 - val_loss: 1733.9180 - val_mae: 1733.9180 - val_mse: 20653212.0000\n",
            "Epoch 875/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1562.8414 - mae: 1562.8414 - mse: 19634774.0000 - val_loss: 1784.0164 - val_mae: 1784.0164 - val_mse: 19437016.0000\n",
            "Epoch 876/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1564.5035 - mae: 1564.5035 - mse: 19281448.0000 - val_loss: 1610.5284 - val_mae: 1610.5284 - val_mse: 20448638.0000\n",
            "Epoch 877/1000\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1594.6887 - mae: 1594.6887 - mse: 19995890.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 2s 64ms/step - loss: 1548.2175 - mae: 1548.2175 - mse: 19287052.0000 - val_loss: 1556.9789 - val_mae: 1556.9789 - val_mse: 20050088.0000\n",
            "Epoch 878/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1570.6772 - mae: 1570.6772 - mse: 19314856.0000 - val_loss: 1585.7662 - val_mae: 1585.7662 - val_mse: 19759692.0000\n",
            "Epoch 879/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1603.1807 - mae: 1603.1807 - mse: 19319116.0000 - val_loss: 1813.0468 - val_mae: 1813.0468 - val_mse: 22326052.0000\n",
            "Epoch 880/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1605.0731 - mae: 1605.0731 - mse: 19614636.0000 - val_loss: 1703.2172 - val_mae: 1703.2172 - val_mse: 19296740.0000\n",
            "Epoch 881/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1559.6682 - mae: 1559.6682 - mse: 19391700.0000 - val_loss: 1677.1422 - val_mae: 1677.1422 - val_mse: 19652442.0000\n",
            "Epoch 882/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1574.2684 - mae: 1574.2684 - mse: 19405786.0000 - val_loss: 1687.9728 - val_mae: 1687.9728 - val_mse: 21437158.0000\n",
            "Epoch 883/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1540.9127 - mae: 1540.9127 - mse: 19335212.0000 - val_loss: 1746.6256 - val_mae: 1746.6256 - val_mse: 20481680.0000\n",
            "Epoch 884/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1604.3378 - mae: 1604.3378 - mse: 19919046.0000 - val_loss: 1820.2832 - val_mae: 1820.2832 - val_mse: 22189230.0000\n",
            "Epoch 885/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1556.0032 - mae: 1556.0032 - mse: 19239694.0000 - val_loss: 1824.2842 - val_mae: 1824.2843 - val_mse: 20880150.0000\n",
            "Epoch 886/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1594.2701 - mae: 1594.2701 - mse: 19479840.0000 - val_loss: 1656.6454 - val_mae: 1656.6454 - val_mse: 20204944.0000\n",
            "Epoch 887/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1575.3630 - mae: 1575.3630 - mse: 19252336.0000 - val_loss: 1820.7618 - val_mae: 1820.7618 - val_mse: 21171258.0000\n",
            "Epoch 888/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1589.6013 - mae: 1589.6013 - mse: 19687348.0000 - val_loss: 1639.5431 - val_mae: 1639.5431 - val_mse: 19784030.0000\n",
            "Epoch 889/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1589.2047 - mae: 1589.2047 - mse: 19736422.0000 - val_loss: 1700.7405 - val_mae: 1700.7405 - val_mse: 19717178.0000\n",
            "Epoch 890/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1548.5490 - mae: 1548.5490 - mse: 19328498.0000 - val_loss: 1881.3142 - val_mae: 1881.3142 - val_mse: 22002956.0000\n",
            "Epoch 891/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1592.4556 - mae: 1592.4556 - mse: 19390882.0000 - val_loss: 1585.4004 - val_mae: 1585.4004 - val_mse: 20035220.0000\n",
            "Epoch 892/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1537.2970 - mae: 1537.2970 - mse: 18957172.0000 - val_loss: 2060.9780 - val_mae: 2060.9780 - val_mse: 23743516.0000\n",
            "Epoch 893/1000\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1664.6838 - mae: 1664.6838 - mse: 19944714.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 55ms/step - loss: 1570.8737 - mae: 1570.8737 - mse: 19259294.0000 - val_loss: 1548.9680 - val_mae: 1548.9680 - val_mse: 19730518.0000\n",
            "Epoch 894/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1568.9852 - mae: 1568.9852 - mse: 19468370.0000 - val_loss: 1671.6538 - val_mae: 1671.6538 - val_mse: 20479492.0000\n",
            "Epoch 895/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1563.8031 - mae: 1563.8031 - mse: 19227026.0000 - val_loss: 1671.3623 - val_mae: 1671.3623 - val_mse: 19426224.0000\n",
            "Epoch 896/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1514.3781 - mae: 1514.3781 - mse: 18825552.0000 - val_loss: 1907.1371 - val_mae: 1907.1371 - val_mse: 19418620.0000\n",
            "Epoch 897/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1543.8987 - mae: 1543.8987 - mse: 19075388.0000 - val_loss: 1833.9423 - val_mae: 1833.9423 - val_mse: 22877614.0000\n",
            "Epoch 898/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1579.0092 - mae: 1579.0092 - mse: 19350554.0000 - val_loss: 1625.9197 - val_mae: 1625.9197 - val_mse: 20300900.0000\n",
            "Epoch 899/1000\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1530.2665 - mae: 1530.2665 - mse: 19321474.0000 - val_loss: 1976.1534 - val_mae: 1976.1534 - val_mse: 23156516.0000\n",
            "Epoch 900/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1581.5704 - mae: 1581.5704 - mse: 19666418.0000 - val_loss: 1758.1554 - val_mae: 1758.1554 - val_mse: 19255828.0000\n",
            "Epoch 901/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1561.8344 - mae: 1561.8344 - mse: 19248754.0000 - val_loss: 1820.6943 - val_mae: 1820.6943 - val_mse: 21453084.0000\n",
            "Epoch 902/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1581.1234 - mae: 1581.1234 - mse: 19451142.0000 - val_loss: 1638.8964 - val_mae: 1638.8964 - val_mse: 19436050.0000\n",
            "Epoch 903/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1565.7471 - mae: 1565.7471 - mse: 19262260.0000 - val_loss: 1775.1095 - val_mae: 1775.1095 - val_mse: 22437448.0000\n",
            "Epoch 904/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1567.6116 - mae: 1567.6116 - mse: 19105564.0000 - val_loss: 1621.9835 - val_mae: 1621.9835 - val_mse: 20064204.0000\n",
            "Epoch 905/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1512.7814 - mae: 1512.7814 - mse: 18971542.0000 - val_loss: 1885.3954 - val_mae: 1885.3954 - val_mse: 22130066.0000\n",
            "Epoch 906/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1564.4972 - mae: 1564.4972 - mse: 19196452.0000 - val_loss: 1928.2440 - val_mae: 1928.2440 - val_mse: 23224254.0000\n",
            "Epoch 907/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1582.1809 - mae: 1582.1809 - mse: 19477568.0000 - val_loss: 1591.0663 - val_mae: 1591.0663 - val_mse: 20674472.0000\n",
            "Epoch 908/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1575.5631 - mae: 1575.5631 - mse: 19629446.0000 - val_loss: 1892.7679 - val_mae: 1892.7679 - val_mse: 20147542.0000\n",
            "Epoch 909/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1557.6364 - mae: 1557.6364 - mse: 19107898.0000 - val_loss: 1580.5389 - val_mae: 1580.5389 - val_mse: 19954582.0000\n",
            "Epoch 910/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1561.2240 - mae: 1561.2240 - mse: 19583188.0000 - val_loss: 1694.0508 - val_mae: 1694.0508 - val_mse: 19798964.0000\n",
            "Epoch 911/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1562.3889 - mae: 1562.3889 - mse: 19467566.0000 - val_loss: 1562.4038 - val_mae: 1562.4038 - val_mse: 20365572.0000\n",
            "Epoch 912/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1537.6909 - mae: 1537.6909 - mse: 19192586.0000 - val_loss: 1624.1742 - val_mae: 1624.1742 - val_mse: 19556128.0000\n",
            "Epoch 913/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1582.9058 - mae: 1582.9058 - mse: 19388594.0000 - val_loss: 1602.8051 - val_mae: 1602.8051 - val_mse: 20091408.0000\n",
            "Epoch 914/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1585.2856 - mae: 1585.2856 - mse: 19895008.0000 - val_loss: 1658.6180 - val_mae: 1658.6180 - val_mse: 20644900.0000\n",
            "Epoch 915/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1567.9481 - mae: 1567.9481 - mse: 19361888.0000 - val_loss: 1573.9661 - val_mae: 1573.9661 - val_mse: 20342736.0000\n",
            "Epoch 916/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1532.6389 - mae: 1532.6389 - mse: 19221616.0000 - val_loss: 1571.2576 - val_mae: 1571.2574 - val_mse: 20484116.0000\n",
            "Epoch 917/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1538.3433 - mae: 1538.3433 - mse: 19372750.0000 - val_loss: 1701.1503 - val_mae: 1701.1503 - val_mse: 20972908.0000\n",
            "Epoch 918/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1599.4249 - mae: 1599.4249 - mse: 19216372.0000 - val_loss: 1767.2998 - val_mae: 1767.2998 - val_mse: 19638506.0000\n",
            "Epoch 919/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1560.0955 - mae: 1560.0955 - mse: 19444330.0000 - val_loss: 1641.9778 - val_mae: 1641.9778 - val_mse: 21004756.0000\n",
            "Epoch 920/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1514.2772 - mae: 1514.2772 - mse: 18892584.0000 - val_loss: 1950.0642 - val_mae: 1950.0645 - val_mse: 23166000.0000\n",
            "Epoch 921/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1583.4965 - mae: 1583.4965 - mse: 19353238.0000 - val_loss: 1781.3271 - val_mae: 1781.3271 - val_mse: 19581212.0000\n",
            "Epoch 922/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1521.6185 - mae: 1521.6185 - mse: 18910182.0000 - val_loss: 2036.7588 - val_mae: 2036.7588 - val_mse: 23275644.0000\n",
            "Epoch 923/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1549.5486 - mae: 1549.5486 - mse: 19024626.0000 - val_loss: 1682.8102 - val_mae: 1682.8102 - val_mse: 20386626.0000\n",
            "Epoch 924/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1577.3090 - mae: 1577.3090 - mse: 19423840.0000 - val_loss: 1752.0690 - val_mae: 1752.0690 - val_mse: 21412624.0000\n",
            "Epoch 925/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1539.5111 - mae: 1539.5111 - mse: 18982540.0000 - val_loss: 1730.8566 - val_mae: 1730.8566 - val_mse: 21459470.0000\n",
            "Epoch 926/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1589.1591 - mae: 1589.1591 - mse: 19514796.0000 - val_loss: 1737.1215 - val_mae: 1737.1215 - val_mse: 21389054.0000\n",
            "Epoch 927/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1527.4034 - mae: 1527.4034 - mse: 19281252.0000 - val_loss: 2065.5068 - val_mae: 2065.5068 - val_mse: 24628354.0000\n",
            "Epoch 928/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1552.0092 - mae: 1552.0092 - mse: 19101122.0000 - val_loss: 1615.5850 - val_mae: 1615.5850 - val_mse: 20605168.0000\n",
            "Epoch 929/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1532.2278 - mae: 1532.2278 - mse: 19125526.0000 - val_loss: 1674.0544 - val_mae: 1674.0544 - val_mse: 20845792.0000\n",
            "Epoch 930/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1566.7532 - mae: 1566.7532 - mse: 19228532.0000 - val_loss: 1629.3691 - val_mae: 1629.3691 - val_mse: 19894212.0000\n",
            "Epoch 931/1000\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1524.3604 - mae: 1524.3604 - mse: 19041534.0000 - val_loss: 1614.2460 - val_mae: 1614.2460 - val_mse: 20284062.0000\n",
            "Epoch 932/1000\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1630.8850 - mae: 1630.8850 - mse: 20266466.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 55ms/step - loss: 1565.9130 - mae: 1565.9130 - mse: 19064038.0000 - val_loss: 1544.6163 - val_mae: 1544.6163 - val_mse: 20092698.0000\n",
            "Epoch 933/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1522.4817 - mae: 1522.4817 - mse: 19013616.0000 - val_loss: 1772.5565 - val_mae: 1772.5565 - val_mse: 19508842.0000\n",
            "Epoch 934/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1570.7677 - mae: 1570.7677 - mse: 19268734.0000 - val_loss: 1865.0366 - val_mae: 1865.0366 - val_mse: 21811392.0000\n",
            "Epoch 935/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1555.0806 - mae: 1555.0806 - mse: 19307900.0000 - val_loss: 1565.8793 - val_mae: 1565.8793 - val_mse: 19966122.0000\n",
            "Epoch 936/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1516.6913 - mae: 1516.6913 - mse: 18937716.0000 - val_loss: 1569.7666 - val_mae: 1569.7666 - val_mse: 20221160.0000\n",
            "Epoch 937/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1507.4656 - mae: 1507.4656 - mse: 19175164.0000 - val_loss: 1898.9409 - val_mae: 1898.9409 - val_mse: 19626332.0000\n",
            "Epoch 938/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1567.5337 - mae: 1567.5337 - mse: 19343186.0000 - val_loss: 1791.3765 - val_mae: 1791.3765 - val_mse: 21471422.0000\n",
            "Epoch 939/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1541.4507 - mae: 1541.4507 - mse: 18868478.0000 - val_loss: 1771.7026 - val_mae: 1771.7026 - val_mse: 19672382.0000\n",
            "Epoch 940/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1509.5641 - mae: 1509.5641 - mse: 18726726.0000 - val_loss: 1715.2363 - val_mae: 1715.2363 - val_mse: 21583838.0000\n",
            "Epoch 941/1000\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1532.5367 - mae: 1532.5367 - mse: 18871582.0000 - val_loss: 1623.2383 - val_mae: 1623.2383 - val_mse: 20606550.0000\n",
            "Epoch 942/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1560.1687 - mae: 1560.1687 - mse: 19357280.0000 - val_loss: 1740.3296 - val_mae: 1740.3296 - val_mse: 21368172.0000\n",
            "Epoch 943/1000\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1526.3750 - mae: 1526.3750 - mse: 18987774.0000 - val_loss: 1750.3466 - val_mae: 1750.3466 - val_mse: 20034034.0000\n",
            "Epoch 944/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1552.9347 - mae: 1552.9347 - mse: 19397642.0000 - val_loss: 1573.7664 - val_mae: 1573.7664 - val_mse: 20544540.0000\n",
            "Epoch 945/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1556.9574 - mae: 1556.9574 - mse: 19186830.0000 - val_loss: 1848.1101 - val_mae: 1848.1101 - val_mse: 21976194.0000\n",
            "Epoch 946/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1512.5385 - mae: 1512.5385 - mse: 19043966.0000 - val_loss: 2032.3956 - val_mae: 2032.3956 - val_mse: 23904922.0000\n",
            "Epoch 947/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1550.2911 - mae: 1550.2911 - mse: 19351538.0000 - val_loss: 1674.8260 - val_mae: 1674.8260 - val_mse: 20268812.0000\n",
            "Epoch 948/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1521.3699 - mae: 1521.3699 - mse: 18930396.0000 - val_loss: 1784.2338 - val_mae: 1784.2338 - val_mse: 19597822.0000\n",
            "Epoch 949/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1555.4091 - mae: 1555.4091 - mse: 19357608.0000 - val_loss: 1788.8534 - val_mae: 1788.8534 - val_mse: 22936966.0000\n",
            "Epoch 950/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1572.3577 - mae: 1572.3577 - mse: 19538616.0000 - val_loss: 1669.7659 - val_mae: 1669.7659 - val_mse: 20625656.0000\n",
            "Epoch 951/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1518.7986 - mae: 1518.7986 - mse: 18978436.0000 - val_loss: 1642.3334 - val_mae: 1642.3334 - val_mse: 20940408.0000\n",
            "Epoch 952/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1515.2803 - mae: 1515.2803 - mse: 19016422.0000 - val_loss: 1804.4650 - val_mae: 1804.4650 - val_mse: 20020256.0000\n",
            "Epoch 953/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1555.1411 - mae: 1555.1411 - mse: 19396318.0000 - val_loss: 1842.7656 - val_mae: 1842.7656 - val_mse: 21682676.0000\n",
            "Epoch 954/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1576.7982 - mae: 1576.7982 - mse: 19209522.0000 - val_loss: 1733.9153 - val_mae: 1733.9153 - val_mse: 20194588.0000\n",
            "Epoch 955/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1524.0171 - mae: 1524.0171 - mse: 18947214.0000 - val_loss: 1582.7985 - val_mae: 1582.7985 - val_mse: 20057682.0000\n",
            "Epoch 956/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1505.4630 - mae: 1505.4630 - mse: 18763254.0000 - val_loss: 1720.1716 - val_mae: 1720.1716 - val_mse: 22203600.0000\n",
            "Epoch 957/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1561.7168 - mae: 1561.7168 - mse: 19385268.0000 - val_loss: 1582.8262 - val_mae: 1582.8262 - val_mse: 19875546.0000\n",
            "Epoch 958/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1517.6865 - mae: 1517.6865 - mse: 19085944.0000 - val_loss: 1751.7079 - val_mae: 1751.7079 - val_mse: 19573514.0000\n",
            "Epoch 959/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1538.4132 - mae: 1538.4132 - mse: 19264870.0000 - val_loss: 1759.7384 - val_mae: 1759.7384 - val_mse: 22377416.0000\n",
            "Epoch 960/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1546.3304 - mae: 1546.3304 - mse: 19310128.0000 - val_loss: 1566.4871 - val_mae: 1566.4871 - val_mse: 20531612.0000\n",
            "Epoch 961/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1533.6235 - mae: 1533.6235 - mse: 19088702.0000 - val_loss: 1887.7079 - val_mae: 1887.7079 - val_mse: 19387514.0000\n",
            "Epoch 962/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1524.5952 - mae: 1524.5952 - mse: 18909884.0000 - val_loss: 1602.9966 - val_mae: 1602.9966 - val_mse: 20001068.0000\n",
            "Epoch 963/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1517.8094 - mae: 1517.8094 - mse: 19115334.0000 - val_loss: 1719.4692 - val_mae: 1719.4692 - val_mse: 20045614.0000\n",
            "Epoch 964/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1550.0519 - mae: 1550.0519 - mse: 19089754.0000 - val_loss: 1549.5149 - val_mae: 1549.5149 - val_mse: 20292256.0000\n",
            "Epoch 965/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1539.3293 - mae: 1539.3293 - mse: 19254336.0000 - val_loss: 1836.1041 - val_mae: 1836.1041 - val_mse: 19925154.0000\n",
            "Epoch 966/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1492.9819 - mae: 1492.9819 - mse: 18741538.0000 - val_loss: 1624.0594 - val_mae: 1624.0594 - val_mse: 21321150.0000\n",
            "Epoch 967/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1520.1821 - mae: 1520.1821 - mse: 18954974.0000 - val_loss: 1589.9694 - val_mae: 1589.9694 - val_mse: 20458486.0000\n",
            "Epoch 968/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1534.9301 - mae: 1534.9301 - mse: 19059726.0000 - val_loss: 1653.4724 - val_mae: 1653.4724 - val_mse: 20012046.0000\n",
            "Epoch 969/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1534.6841 - mae: 1534.6841 - mse: 19193402.0000 - val_loss: 1648.8704 - val_mae: 1648.8704 - val_mse: 21286592.0000\n",
            "Epoch 970/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1539.1443 - mae: 1539.1443 - mse: 19006370.0000 - val_loss: 1593.9259 - val_mae: 1593.9259 - val_mse: 20791110.0000\n",
            "Epoch 971/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1534.5159 - mae: 1534.5159 - mse: 19351298.0000 - val_loss: 1847.4276 - val_mae: 1847.4276 - val_mse: 22372586.0000\n",
            "Epoch 972/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1527.9219 - mae: 1527.9219 - mse: 18996264.0000 - val_loss: 1573.5953 - val_mae: 1573.5953 - val_mse: 20240250.0000\n",
            "Epoch 973/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1521.5283 - mae: 1521.5283 - mse: 18893944.0000 - val_loss: 1685.0488 - val_mae: 1685.0488 - val_mse: 20138152.0000\n",
            "Epoch 974/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1509.4359 - mae: 1509.4359 - mse: 18888244.0000 - val_loss: 1728.1614 - val_mae: 1728.1614 - val_mse: 20523328.0000\n",
            "Epoch 975/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1537.8569 - mae: 1537.8569 - mse: 19158080.0000 - val_loss: 1707.7491 - val_mae: 1707.7491 - val_mse: 21499624.0000\n",
            "Epoch 976/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1500.3403 - mae: 1500.3403 - mse: 18824554.0000 - val_loss: 1675.5935 - val_mae: 1675.5935 - val_mse: 21149332.0000\n",
            "Epoch 977/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1506.2129 - mae: 1506.2129 - mse: 19051932.0000 - val_loss: 1574.3676 - val_mae: 1574.3676 - val_mse: 20600842.0000\n",
            "Epoch 978/1000\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1462.2878 - mae: 1462.2878 - mse: 17777200.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 55ms/step - loss: 1535.4202 - mae: 1535.4202 - mse: 19064588.0000 - val_loss: 1543.1698 - val_mae: 1543.1698 - val_mse: 20245976.0000\n",
            "Epoch 979/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1511.3927 - mae: 1511.3927 - mse: 19037542.0000 - val_loss: 1774.8353 - val_mae: 1774.8353 - val_mse: 19977926.0000\n",
            "Epoch 980/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1537.0730 - mae: 1537.0730 - mse: 19033830.0000 - val_loss: 1608.7372 - val_mae: 1608.7372 - val_mse: 19831438.0000\n",
            "Epoch 981/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1532.7019 - mae: 1532.7019 - mse: 19025520.0000 - val_loss: 1942.7457 - val_mae: 1942.7457 - val_mse: 19809782.0000\n",
            "Epoch 982/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1512.5187 - mae: 1512.5187 - mse: 19007398.0000 - val_loss: 1714.0549 - val_mae: 1714.0549 - val_mse: 19503724.0000\n",
            "Epoch 983/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1556.8964 - mae: 1556.8964 - mse: 19296900.0000 - val_loss: 1610.2926 - val_mae: 1610.2926 - val_mse: 20653814.0000\n",
            "Epoch 984/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1495.4448 - mae: 1495.4448 - mse: 18705668.0000 - val_loss: 1691.5239 - val_mae: 1691.5239 - val_mse: 20975418.0000\n",
            "Epoch 985/1000\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1496.4701 - mae: 1496.4701 - mse: 18536102.0000INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "27/27 [==============================] - 1s 54ms/step - loss: 1527.2478 - mae: 1527.2478 - mse: 18978468.0000 - val_loss: 1534.2633 - val_mae: 1534.2633 - val_mse: 20278350.0000\n",
            "Epoch 986/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1508.2368 - mae: 1508.2368 - mse: 19059752.0000 - val_loss: 1559.2706 - val_mae: 1559.2706 - val_mse: 20133878.0000\n",
            "Epoch 987/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1541.2197 - mae: 1541.2197 - mse: 19043518.0000 - val_loss: 1628.7643 - val_mae: 1628.7643 - val_mse: 19704514.0000\n",
            "Epoch 988/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1532.9556 - mae: 1532.9556 - mse: 19162622.0000 - val_loss: 1874.3904 - val_mae: 1874.3904 - val_mse: 19887560.0000\n",
            "Epoch 989/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1519.5381 - mae: 1519.5381 - mse: 18952364.0000 - val_loss: 1779.0447 - val_mae: 1779.0447 - val_mse: 19408380.0000\n",
            "Epoch 990/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1513.9369 - mae: 1513.9369 - mse: 18751324.0000 - val_loss: 1879.8325 - val_mae: 1879.8325 - val_mse: 19695816.0000\n",
            "Epoch 991/1000\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1518.4213 - mae: 1518.4213 - mse: 19210348.0000 - val_loss: 1627.6809 - val_mae: 1627.6809 - val_mse: 20189760.0000\n",
            "Epoch 992/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1540.6262 - mae: 1540.6262 - mse: 19295674.0000 - val_loss: 1748.4410 - val_mae: 1748.4410 - val_mse: 21331770.0000\n",
            "Epoch 993/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1485.4109 - mae: 1485.4109 - mse: 18616000.0000 - val_loss: 1869.7584 - val_mae: 1869.7584 - val_mse: 23155444.0000\n",
            "Epoch 994/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1545.0392 - mae: 1545.0392 - mse: 19430822.0000 - val_loss: 1671.1207 - val_mae: 1671.1207 - val_mse: 21606544.0000\n",
            "Epoch 995/1000\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1507.1643 - mae: 1507.1643 - mse: 19008626.0000 - val_loss: 1549.5488 - val_mae: 1549.5488 - val_mse: 20312774.0000\n",
            "Epoch 996/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1526.7185 - mae: 1526.7185 - mse: 18939474.0000 - val_loss: 1702.8469 - val_mae: 1702.8469 - val_mse: 20984378.0000\n",
            "Epoch 997/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1504.5353 - mae: 1504.5353 - mse: 19042396.0000 - val_loss: 1634.5537 - val_mae: 1634.5537 - val_mse: 20327852.0000\n",
            "Epoch 998/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1507.2570 - mae: 1507.2570 - mse: 18853722.0000 - val_loss: 1758.6609 - val_mae: 1758.6609 - val_mse: 20480702.0000\n",
            "Epoch 999/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1507.5760 - mae: 1507.5760 - mse: 19082178.0000 - val_loss: 1791.5990 - val_mae: 1791.5990 - val_mse: 19862872.0000\n",
            "Epoch 1000/1000\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1507.4427 - mae: 1507.4427 - mse: 18874218.0000 - val_loss: 1776.8488 - val_mae: 1776.8488 - val_mse: 21348388.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe7RXH3N3CWU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "0174fdf1-ad8e-4e07-b79e-1d68c5c2344f"
      },
      "source": [
        "# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.\n",
        "# Test model by checking how well the model generalizes using the test set.\n",
        "loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} expenses\".format(mae))\n",
        "\n",
        "if mae < 3500:\n",
        "  print(\"You passed the challenge. Great job!\")\n",
        "else:\n",
        "  print(\"The Mean Abs Error must be less than 3500. Keep trying.\")\n",
        "\n",
        "# Plot predictions.\n",
        "test_predictions = model.predict(test_dataset).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True values (expenses)')\n",
        "plt.ylabel('Predictions (expenses)')\n",
        "lims = [0, 50000]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims,lims)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 2351.5876 - mae: 2351.5876 - mse: 34612100.0000 - 42ms/epoch - 5ms/step\n",
            "Testing set Mean Abs Error: 2351.59 expenses\n",
            "You passed the challenge. Great job!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}